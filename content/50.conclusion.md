## Conclusion

Reiterate work done and thesis

Final sentence: however, will DL models still have only limited effect in the future?

### The scale of data

Biological data (or at least transcriptomic data) isn't actually that big.
The largest uniformly processed compendia of bulk human expression data are on the order of hundreds of thousands of samples.
Meanwhile in machine learning, even before deep learning took off ImageNet already have more than three million images [@doi:10.1109/CVPR.2009.5206848].

Worse, many biological domains have strict upper bounds on the amount of data available.
Even if you somehow recruited the entire world for a study you'd still only be able to collect around eight billion human genomes.
Given the complexity of biology it seems unlikely that "only" eight billion geneomes would be sufficient to effectively sample the space of plausible relevant mutations in the human genome.
Based on recent research into neural network scaling laws [@arxiv:2203.15556] and machine learning intuition, it seems likely that Rich Sutton's "Bitter Lesson" (http://www.incompleteideas.net/IncIdeas/BitterLesson.html) would break down in a domain where there is a hard cap on the available data.

This isn't true of all domains though; expression is more variable, so you can get a much larger sample size
Maybe talk about automation/Recursion model

While we've shown that deep learning hasn't lead to a paradigm shift in computational biology so far, will that always be true? 
As with many scientific questions, the answer is probably "it depends".
While there may be caps on individual aspects of biological data, there are always more angles of attack.

The promise of multiomics has always been that multiple views of the same system may reveal something that no single view picks up.
The challenge is that the data types are different, their relationships are not well-characterized, and the methods for working in such a system haven't been fully developed yet.
Transformer architectures, and more specifically their self-attention mechanism seem like a good fit for learning relationships between different 'omes.
Such models are data hungry though, and self-attention gets expensive in problems with high dimensionality.
Perhaps one day we'll have the data and compute to train multiomic biological transformers.
Maybe by that point the state of the art in machine learning will have moved along rendering that point moot.

### Deep learning's impact is application-specific

DL has already had a big impact on imaging, and seems poised to do so in protein structure

These were likely successful because of their similarity to well-researched fields in that they can be framed as similar problems
Biomedical images ~ camera images
Protein sequence ~ sequences of tokens in language models

One big question is what good representations for biological problems are

### To what extent is biology limited by challenges in looking at the data

An important first step when working with data is to look at it.
In images of generated text, a human can make a judgement on how good generated data is.
In the classification world, a human labeler can look at an image and say "that is a dog" or a sentence and say "that is grammatically correct english."
While these labels are somewhat fuzzy, a group of humans can at least look at the label and say "that is reasonable" or "that is mislabeled."
A human looking at a gene expression microarray, or a table of RNA-seq counts is unable to do the same.

Our brains are built to recognize objects, not parse gene expression perturbations corresponding to septic shock.
This issue isn't insurmountable; scientists are able to do research in quantum physics after all.
It simply serves as hinderence on our ability to sanity check data.
Because we can't see whether the relevant signals are distorted by batch effect normalization or a preprocessing step.
Perhaps in the future, as we understand more about the relevant biology, scientists will be able to create views of the data that are more human-intuitive and easier to use.

### Computer hardware
Lots of biology can be thought of as a spare network of interaction. 
For example, genes regulate each other or are coregulated, but most genes don't regulate most other genes.
Instead expression is often thought of in terms of coregulation networks or sets of genes with shared functions.
Such spare representations are poorly supported by modern hardware, which is built to paralellize dense tensor operations.
While it seems unlikely that this will change in the future, perhaps advances in how to optimize graph neural network problems will help more efficiently use hardware for biological problems.
