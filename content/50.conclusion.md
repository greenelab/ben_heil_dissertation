## Conclusion

Reiterate work done and thesis

### The scale of data

Biological data (or at least transcriptomic data) isn't actually that big.
The largest uniformly processed compendia of bulk human expression data are on the order of hundreds of thousands of samples.
Meanwhile in machine learning, even before deep learning took off ImageNet already have more than three million images [@doi:10.1109/CVPR.2009.5206848].

Worse, many biological domains have strict upper bounds on the amount of data available.
Even if you somehow recruited the entire world for a study you'd still only be able to collect around eight billion human genomes.
Given the complexity of biology it seems unlikely that "only" eight billion geneomes would be sufficient to effectively sample the space of plausible relevant mutations in the human genome.
Based on recent research into neural network scaling laws [@arxiv:2203.15556] and machine learning intuition, it seems likely that Rich Sutton's "Bitter Lesson" (http://www.incompleteideas.net/IncIdeas/BitterLesson.html) would break down in a domain where there is a hard cap on the available data.

This isn't true of all domains though; expression is more variable, so you can get a much larger sample size
Maybe talk about automation/Recursion model

While we've shown that deep learning hasn't lead to a paradigm shift in computational biology so far, will that always be true? 
As with many scientific questions, the answer is probably "it depends".
While there may be caps on individual aspects of biological data, there are always more angles of attack.

The promise of multiomics has always been that multiple views of the same system may reveal something that no single view picks up.
The challenge is that the data types are different, their relationships are not well-characterized, and the methods for working in such a system haven't been fully developed yet.
Transformer architectures, and more specifically their self-attention mechanism seem like a good fit for learning relationships between different 'omes.
Such models are data hungry though, and self-attention gets expensive in problems with high dimensionality.
Perhaps one day we'll have the data and compute to train multiomic biological transformers.
Maybe by that point the state of the art in machine learning will have moved along rendering that point moot.

