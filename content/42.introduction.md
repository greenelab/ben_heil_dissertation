## Introduction

A common way to gain knowledge from gene expression is by examining which genes are differentially expressed in an experiment [@doi:10/dcz39r; @doi:10.1186/gb-2010-11-10-r106; @doi:10.1371/journal.pone.0190152; @doi:10.1093/bioinformatics/btab327].
For example, one can find which genes' expression values change in mouse tissue samples before and after some biological perturbation.
This approach can be challenging, however, as studies analyzing gene expression tend to have few samples compared to the number of genes.
The resulting lack of statistical power can be addressed by increasing the number of samples in an experiment, which is expensive.
Alternatively, one can reduce the dimensionality or use information from outside the study.

Unsupervised learning does both.
It is a category of methods from the field of machine learning that learn the structure of data without need for any biological labels denoting which experimental conditions are present.
Such methods are well-suited for gene expression data, and are often used for tasks such as reducing the dimensionality of expression datasets [@doi:10.1037/h0071325; @tsne; @doi:10.21105/joss.00861], clustering samples [@doi:10.4137/BBI.S38316; @doi:10.1093/bioinformatics/btz769], or learning shared expression patterns across experiments [@doi:10.1128/mSystems.00025-15; @doi:10.1093/bioinformatics/btz338].
That being said, while unsupervised models are capable of using large amounts of unlabeled expression data, many of them don't explicitly encode prior biological knowledge to encourage the model to learn biological patterns over technical ones.

The Pathway-level information extractor (PLIER) models do [@doi:10.1038/s41592-019-0456-1].
They are built explicitly to work on expression data, and use matrix factorization to incorporate prior knowledge in the form of sets of genes specified by the user corresponding to biological pathways or cell type markers.
PLIER models also capable of learning diverse biological pathways from entire compendia of expression data and transferring that knowledge to smaller studies as seen in MultiPLIER [@doi:10.1016/j.cels.2019.04.003].
However, PLIER models are largely trained on a single dataset rather than a compendium [@doi:10.1038/s41598-019-57110-6; @doi:10.1038/s41586-022-05056-7; @doi:10.1016/j.celrep.2022.110467], and past MultiPLIER runs have only trained models with up to tens of thousands of samples [@doi:10.3390/genes11020226; @doi:10.1016/j.cels.2019.04.003].

In this paper we train a PLIER model on a compendium of mouse gene expression to convert the data into a series of values called "latent variables" that correspond to potentially biologically relevant combinations of genes.
In doing so we train the largest (in terms of training data) PLIER model to date and the first one trained on a mouse compendium.
We have named this model MousiPLIER, short for Mouse MultiPLIER.
We demonstrate that not only is training such a model possible, it also surfaces interesting biology in a study of mouse brain aging.
When looking at a novel view of the resulting data (k-means clusters in the latent variable space), we find that the microglia-associated latent variables from our study of interest also correspond to aging-related changes in the training data.
Finally, we build a web server to allow others to visualize the results and find patterns in the data based on their own latent variables of interest.
Going forward, this model and its associated web server will be a useful tool for better understanding mouse gene expression.
