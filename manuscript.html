<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US" xml:lang="en-US">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <meta name="author" content="Benjamin J. Heil" />
  <meta name="dcterms.date" content="2022-12-01" />
  <meta name="keywords" content="machine learning, science of science, reproducibility, citation network analysis" />
  <title>Neural Nets Are Not All You Need: Evaluating the Effects of Deep Learning on Transcriptomic Analysis</title>
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
    }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
  <!--
  Manubot generated metadata rendered from header-includes-template.html.
  Suggest improvements at https://github.com/manubot/manubot/blob/main/manubot/process/header-includes-template.html
  -->
  <meta name="dc.format" content="text/html" />
  <meta name="dc.title" content="Neural Nets Are Not All You Need: Evaluating the Effects of Deep Learning on Transcriptomic Analysis" />
  <meta name="citation_title" content="Neural Nets Are Not All You Need: Evaluating the Effects of Deep Learning on Transcriptomic Analysis" />
  <meta property="og:title" content="Neural Nets Are Not All You Need: Evaluating the Effects of Deep Learning on Transcriptomic Analysis" />
  <meta property="twitter:title" content="Neural Nets Are Not All You Need: Evaluating the Effects of Deep Learning on Transcriptomic Analysis" />
  <meta name="dc.date" content="2022-12-01" />
  <meta name="citation_publication_date" content="2022-12-01" />
  <meta name="dc.language" content="en-US" />
  <meta name="citation_language" content="en-US" />
  <meta name="dc.relation.ispartof" content="Manubot" />
  <meta name="dc.publisher" content="Manubot" />
  <meta name="citation_journal_title" content="Manubot" />
  <meta name="citation_technical_report_institution" content="Manubot" />
  <meta name="citation_author" content="Benjamin J. Heil" />
  <meta name="citation_author_institution" content="Genomics and Computational Biology Graduate Group, University of Pennsylvania" />
  <meta name="citation_author_orcid" content="0000-0002-2811-1031" />
  <meta name="twitter:creator" content="@autobencoder" />
  <link rel="canonical" href="https://greenelab.github.io/ben_heil_dissertation/" />
  <meta property="og:url" content="https://greenelab.github.io/ben_heil_dissertation/" />
  <meta property="twitter:url" content="https://greenelab.github.io/ben_heil_dissertation/" />
  <meta name="citation_fulltext_html_url" content="https://greenelab.github.io/ben_heil_dissertation/" />
  <meta name="citation_pdf_url" content="https://greenelab.github.io/ben_heil_dissertation/manuscript.pdf" />
  <link rel="alternate" type="application/pdf" href="https://greenelab.github.io/ben_heil_dissertation/manuscript.pdf" />
  <link rel="alternate" type="text/html" href="https://greenelab.github.io/ben_heil_dissertation/v/8cdf9e8f9f1efd3e7efbd1789620f5082cc17b2c/" />
  <meta name="manubot_html_url_versioned" content="https://greenelab.github.io/ben_heil_dissertation/v/8cdf9e8f9f1efd3e7efbd1789620f5082cc17b2c/" />
  <meta name="manubot_pdf_url_versioned" content="https://greenelab.github.io/ben_heil_dissertation/v/8cdf9e8f9f1efd3e7efbd1789620f5082cc17b2c/manuscript.pdf" />
  <meta property="og:type" content="article" />
  <meta property="twitter:card" content="summary_large_image" />
  <link rel="icon" type="image/png" sizes="192x192" href="https://manubot.org/favicon-192x192.png" />
  <link rel="mask-icon" href="https://manubot.org/safari-pinned-tab.svg" color="#ad1457" />
  <meta name="theme-color" content="#ad1457" />
  <!-- end Manubot generated metadata -->
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
</head>
<body>
<header id="title-block-header">
<h1 class="title">Neural Nets Are Not All You Need: Evaluating the Effects of Deep Learning on Transcriptomic Analysis</h1>
</header>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>I would not have reached this point without the support of many people.
First I would like to thank my mentor Casey Greene for helping me grow from a first-year grad student with aspirations of diagnosing all human disease with a cleverly designed model to a wisened (or maybe wizened) PhD candidate who believes that data is paramount.
I still remember reading papers as an undergrad trying to better understand what was going on at the intersection of computational biology and machine learning and wondering “What is the University of Pennsylvania and why does this Casey guy’s papers keep showing up in my searches?”
Thank you to my thesis committee: Marylyn Ritchie, Russ Altman, Konrad Kording, and Kai Wang.
Your feedback has helped keep my research from going off the rails.
Thank you as well to Greenelab members past and present.
From grilling me to help prepare for prelims, to going on adventures with me in Colorado, to giving me tips on where to find free food, you’ve all helped me to better understand science and what it means to be a scientist.
Thanks to Shuo Zhang and Liz Heller for collaborating with me on MousiPLIER, the project would not have been possible without you.
I would also like to thank John Holmes for agreeing to be my advisor at Penn when Greenelab moved west to Colorado.
In addition, I’d like to thank the GCB administration, especially Maureen Kirsch, Anne-Cara Apple, and Ben Voigt.
You all do a good job of looking after students and making sure we don’t fall through the cracks due to conditions beyond our control.</p>
<p>I’ve also been helped through grad school by many people outside of academia.
Thanks Mom, Dad, Nana, Mary, Wes, and Sujin, your support has meant a lot even if you don’t always understand what I’m talking about.
Thanks as well to Rachel Ungar, and sorry that we didn’t get an opportunity to collaborate (yet?)
If you hadn’t teamed up with me in the audacious plan to get internships at the NIH after sophomore year, I wouldn’t be where I am today.
Thanks to my friends in Philly and in Texas for convincing me to get outside the lab and have fun on occasion, and for giving conflicting advice on whether or not I should drop out of grad school.
Finally, thank you Sydney for helping me see that there is a world going on outside of the small bubble I interact with on a daily basis.
I know that living with a PhD candidate has been frustrating at times, especially as I’ve gotten closer to defending and therefore progressively less interesting.
I’m tempted to come up with something witty to write here, but you’d probably prefer sincerity, so: thank you.</p>
<h2 class="page_break_before" id="abstract">Abstract</h2>
<p>Technologies for quantifying biology have undergone significant advances in the past few decades, leading to datasets rapidly increasing in size and complexity.
At the same time, deep learning models have gone from a curiosity to a massive field of research, with their advancements spilling over into other fields.
Machine learning is not new to computational biology, as machine learning models have been used frequently in the field to account for the aforementioned size and complexity of the data.
This dissertation asks whether the paradigm shift in machine learning that has led to the rise of deep learning models is causing a paradigm shift in computational biology.
To answer this question, we begin with chapter 1, which gives background information helpful for understanding the main thesis chapters.
We then move to chapter 2, which discusses standards necessary to ensure that research done with deep learning is reproducible.
We continue to Chapter 3, where we find that deep learning models may not be helpful in analyzing expression data.
In chapters 4 and 5 we demonstrate that classical machine learning methods already allow scientists to uncover knowledge from large datasets.
Then in chapter 6 we conclude by discussing the implications of the previous chapters and their potential future directions.
Ultimately we find that while deep learning models are useful to various subfields of computational biology, they have yet to lead to a paradigm shift.</p>
<h1 id="chapter-1-background">Chapter 1: Background</h1>
<p>This chapter was prepared for this dissertation to provide background information and context for the dissertation as a whole.
Parts of the “Applications of Machine Learning in Transcriptomics” were written for the class GCB752.</p>
<p><strong>Contributions:</strong><br />
I was the sole author for this chapter.
Some of the “Applications of Machine Learning in Transcriptomics” section was edited based on feedback from Kara Maxwell.</p>
<h2 id="introduction">Introduction</h2>
<p>As computational biologists, we live in exciting times.
Beginning with the Human Genome Project <span class="citation" data-cites="14yhCmDBZ">[<a href="#ref-14yhCmDBZ" role="doc-biblioref">1</a>]</span>, advancements in technologies for biological quantification have generated data with a scale and granularity previously unimaginable <span class="citation" data-cites="11pOKbwng 7pjWPMNl 12pG2VA0G">[<a href="#ref-11pOKbwng" role="doc-biblioref">2</a>,<a href="#ref-7pjWPMNl" role="doc-biblioref">3</a>,<a href="#ref-12pG2VA0G" role="doc-biblioref">4</a>]</span>.</p>
<p>Concurrently with the skyrocketing amounts of data, the advent of deep learning has generated methods designed to make sense of large, complex datasets.
These methods have led to a paradigm shift <span class="citation" data-cites="E78joy5H">[<a href="#ref-E78joy5H" role="doc-biblioref">5</a>]</span> in machine learning, creating new possibilities in many fields and surfacing new phenomena unexplained by classical machine learning theory <span class="citation" data-cites="2gn6PKkv zJcT2HF sQO3gqho eZ5BSkaV">[<a href="#ref-2gn6PKkv" role="doc-biblioref">6</a>,<a href="#ref-zJcT2HF" role="doc-biblioref">7</a>,<a href="#ref-sQO3gqho" role="doc-biblioref">8</a>,<a href="#ref-eZ5BSkaV" role="doc-biblioref">9</a>]</span>.</p>
<p>The field of computational biology has long used machine learning methods, as they help cope with the scale of the data being generated.
Accordingly, problem domains in computational biology that map well to existing research in deep learning have adopted or developed deep learning models and seen great advances <span class="citation" data-cites="TutLhFSz yZfcMIwh">[<a href="#ref-TutLhFSz" role="doc-biblioref">10</a>,<a href="#ref-yZfcMIwh" role="doc-biblioref">11</a>]</span>.
Previous applications of classical machine learning to the field of transcriptomics have been successful.
Two of the scientists who wrote the book <span class="citation" data-cites="Od6nwLRB">[<a href="#ref-Od6nwLRB" role="doc-biblioref">12</a>]</span> on machine learning have even written papers <span class="citation" data-cites="oEfqfC18 168hoJqz4 B01HxUe8 mNsjstMp">[<a href="#ref-oEfqfC18" role="doc-biblioref">13</a>,<a href="#ref-168hoJqz4" role="doc-biblioref">14</a>,<a href="#ref-B01HxUe8" role="doc-biblioref">15</a>,<a href="#ref-mNsjstMp" role="doc-biblioref">16</a>]</span> analyzing gene expression.
However, the data itself is not well-suited to deep learning methods.</p>
<p>This dissertation explores whether the paradigm shift in machine learning will spill over to transcriptomics.
That is to say, have deep learning techniques fundamentally changed transcriptomics, or are they incremental improvements over existing methods?
Our thesis is that while deep learning provides valuable tools for analyzing biological datasets, it does not necessarily change the field on a fundamental level.</p>
<p>We begin with chapter 1, which gives background information on previous research for the other thesis chapters.
We then move to chapter 2, which discusses standards necessary to ensure that research done with deep learning is reproducible.
We continue to Chapter 3, where we find that deep learning models may not be helpful in analyzing expression data.
In chapters 4 and 5 we demonstrate that classical machine learning methods already allow scientists to uncover knowledge from large datasets.
Finally, in chapter 6 we conclude by discussing the implications of the previous chapters and their potential future directions.</p>
<h2 id="applications-of-machine-learning-in-transcriptomics">Applications of machine learning in transcriptomics</h2>
<p>The human transcriptome provides a rich source of information about both healthy and disease states.
Not only is gene expression information useful for learning novel biological phenomena, it can also be used to diagnose and predict diseases.
These predictions have become more powerful in recent years as the field of machine learning has developed more methods.
In this section we review machine learning methods applied to predict various phenotypes from gene expression,
with a focus on the challenges in the field and what is being done to overcome them.
We close the review with potential areas for future research, as well as our perspectives on the strengths and weaknesses of supervised learning for phenotype prediction in particular.</p>
<h3 id="introduction-1">Introduction</h3>
<p>Over the past few decades a number of tools for measuring gene expression have been developed.
As proteomics is currently difficult to do at a large scale, gene expression quantification methods are our best way to measure cells’ internal states.
While this wealth of information is promising, gene expression data is more difficult to work with than one might think.
The high dimensionality and instrument-driven variation require sophisticated techniques to separate the signal from the noise.</p>
<p>One such class of techniques is the set of methods from machine learning.
Machine learning methods depend on the assumption that there are patterns in data that can be learned to make predictions about future data.
Luckily, different people respond to the same disease in similar ways (for some diseases).
Learning genes that indicate an inflammatory response, for example, can help a machine learning model learn the difference between healthy and diseased expression samples.</p>
<p>There are many varieties of machine learning algorithms, so the scope of this paper is limited to analysis of supervised machine learning methods for phenotype prediction.
Supervised machine learning is a paradigm where the model attempts to predict labels.
For example, a model that predicts whether someone has lupus based on their gene expression data <span class="citation" data-cites="qs7B1fgV">[<a href="#ref-qs7B1fgV" role="doc-biblioref">17</a>]</span> is a supervised learning model.
In contrast, techniques for grouping data together without having phenotype labels are called unsupervised methods.
While these methods are also commonly used in computational biology <span class="citation" data-cites="19eIjTcxN 14mY2pXKf IRSA7yBm">[<a href="#ref-19eIjTcxN" role="doc-biblioref">18</a>,<a href="#ref-14mY2pXKf" role="doc-biblioref">19</a>,<a href="#ref-IRSA7yBm" role="doc-biblioref">20</a>]</span>, we will not be discussing them here.</p>
<p>The purpose of this review is to explain and analyze the various approaches that are used to predict phenotypes.
Each section of the review is centered around one of the challenges ubiquitous in using supervised machine learning techniques on gene expression data.
We hope to explain what has been tried and what the consensus for handling the challenge, if one exists.
The review will conclude with a section outlining promising new methods and areas where further study is needed.</p>
<p>If the field succeeds in addressing all the challenges, the payoffs will be substantial.
Being able to predict and diagnose diseases from whole blood gene expression is particularly interesting.
With sufficiently advanced analysis, invasive cancer biopsies might be able to be replaced with simple blood draws <span class="citation" data-cites="doi">[<a href="#ref-IRSA7yBm" role="doc-biblioref">20</a>]</span>.
If not, there are already diagnostics that predict various cancer aspects from biopsy gene expression <span class="citation" data-cites="7T8Uxprz">[<a href="#ref-7T8Uxprz" role="doc-biblioref">21</a>]</span>.
It may also be possible to diagnose common diseases based on blood gene expression <span class="citation" data-cites="Lphv6pyr dx78bdYB 1CNHzMFjN rJ5EpmYl">[<a href="#ref-Lphv6pyr" role="doc-biblioref">22</a>,<a href="#ref-dx78bdYB" role="doc-biblioref">23</a>,<a href="#ref-1CNHzMFjN" role="doc-biblioref">24</a>,<a href="#ref-rJ5EpmYl" role="doc-biblioref">25</a>]</span>, or even rare ones <span class="citation" data-cites="1ZboiGsF">[<a href="#ref-1ZboiGsF" role="doc-biblioref">26</a>]</span>.</p>
<p>The techniques for measuring gene expression and for analyzing it have changed dramatically over the past few decades.
This sections aims to explain what some of those changes are and how they affect phenotype prediction.</p>
<h3 id="gene-expression">Gene expression</h3>
<p>Gene expression measurement methods have three main categories.
This first to be created is the gene expression microarray.
In a microarray, RNA is reverse transcribed to cDNA, labeled with fluorescent markers, then hybridized to probes corresponding to parts of genes.
The amount of fluorescence is then quantified to give the relative amount of gene expression for each gene.
While early microarrays had fewer genes and gene probes <span class="citation" data-cites="J9zGDTW4">[<a href="#ref-J9zGDTW4" role="doc-biblioref">27</a>]</span>, more modern ones measure tens of thousands of genes <span class="citation" data-cites="XeqEIk0K">[<a href="#ref-XeqEIk0K" role="doc-biblioref">28</a>]</span>.</p>
<p>While microarrays are useful, decreases in the price of genetic sequencing have made bulk RNA sequencing (RNA-seq) more common.
In RNA-seq, cDNA molecules are sequenced directly after being reverse transcribed from mRNA.
These cDNA fragments are then aligned against a reference exome to determine which gene, if any, each fragment maps to.
The output of the bulk RNA-seq pipeline is a list of genes and their corresponding read counts.
While there is not gene probe bias like in microarrays, RNA-seq has its own patterns of bias based on gene lengths and expression levels <span class="citation" data-cites="ChQys9ED">[<a href="#ref-ChQys9ED" role="doc-biblioref">29</a>]</span>.
Bulk RNA-seq is also unable to resolve heterogeneous populations of cells, as it measures the average gene expression of all of cells in the sample.</p>
<p>Fairly recently a new method was developed called single-cell RNA sequencing.
True to its name, single-cell sequencing allows gene expression to be measured at the individual cell level.
This increase in precision is accompanied by an increase in data sparsity though, as genes expressed infrequently or at low levels may not be detected.
The sparsity of single-cell data has led to a number of interesting methods, but as we worked with bulk RNA-sequencing single-cell papers will largely be absent from this review.</p>
<h3 id="machine-learning">Machine Learning</h3>
<p>Machine learning has undergone a paradigm shift in the past decade, beginning with the publication of the AlexNet paper in 2012 <span class="citation" data-cites="fVSo2gZU">[<a href="#ref-fVSo2gZU" role="doc-biblioref">30</a>]</span>.
For decades random forests and support vector machines were the most widely used models in machine learning.
This changed dramatically when the AlexNet paper showed that neural networks could vastly outperform traditional methods in some domains <span class="citation" data-cites="fVSo2gZU">[<a href="#ref-fVSo2gZU" role="doc-biblioref">30</a>]</span>.
The deep learning revolution quickly followed, with deep neural networks becoming the state of the art in any problem with enough data <span class="citation" data-cites="c1tQ2yNq HpZqLKUe ld1EnZ6i yZfcMIwh">[<a href="#ref-yZfcMIwh" role="doc-biblioref">11</a>,<a href="#ref-c1tQ2yNq" role="doc-biblioref">31</a>,<a href="#ref-HpZqLKUe" role="doc-biblioref">32</a>,<a href="#ref-ld1EnZ6i" role="doc-biblioref">33</a>]</span>.</p>
<p>The implications of the deep learning revolution on this paper are twofold.
First, almost all papers before 2014 use traditional machine learning methods, while many papers after use deep learning methods.
Second, deep neural networks’ capacity to overfit the data and fail to generalize to outside data are vast.
We’ll show throughout the review various mistakes authors make because they don’t fully understand the failure states of neural networks and how to avoid them.</p>
<h3 id="dimensionality-reduction">Dimensionality Reduction</h3>
<p>The most obvious challenge in working with gene expression data is its high dimensionality.
That is to say that the number of features (genes) in a dataset is typically greater than the number of samples.
It is common for an analysis to have tens of thousands of genes, but only hundreds (or tens) of samples.
Because even simple models struggle under such circumstances, it is necessary to find a representation of the data that uses fewer dimensions.</p>
<p>In the traditional machine learning paradigm, this is done via manual or heuristic feature selection methods.
Such methods tend to use a criterion like mutual information to select a subset of genes for the analysis <span class="citation" data-cites="MzuxpiPn">[<a href="#ref-MzuxpiPn" role="doc-biblioref">34</a>]</span>.
In one of the earliest papers in this review, Li et al. try a eight different methods from statistics and machine learning to see if any one in particular outperformed the others <span class="citation" data-cites="Vzg9ivZU">[<a href="#ref-Vzg9ivZU" role="doc-biblioref">35</a>]</span>.
Ultimately they found that no individual method rose to the top, and that the performance of different methods varies depending on the problem.</p>
<p>A number of other papers since then have also used manual methods.
Grewal et al. chose a subset of genes from COSMIC <span class="citation" data-cites="QSJEewCc">[<a href="#ref-QSJEewCc" role="doc-biblioref">36</a>]</span> for training, but found that their model performed better when using all genes instead of just a subset <span class="citation" data-cites="ClFEdqWg">[<a href="#ref-ClFEdqWg" role="doc-biblioref">37</a>]</span>.
Chen et al. used a different gene set.
They selected the LINCS 1000 gene set <span class="citation" data-cites="F7lIlh2N">[<a href="#ref-F7lIlh2N" role="doc-biblioref">38</a>]</span> for an imputation method, as the LINCS landmark genes are highly correlated with the genes they were trying to impute <span class="citation" data-cites="12QQw9p7v">[<a href="#ref-12QQw9p7v" role="doc-biblioref">39</a>]</span>.</p>
<p>Gene subsets can be based on prior knowledge of gene regulatory networks as well <span class="citation" data-cites="J0eeAld3 g8OoyIPj">[<a href="#ref-J0eeAld3" role="doc-biblioref">40</a>,<a href="#ref-g8OoyIPj" role="doc-biblioref">41</a>]</span>.
While very interpretable, these methods do not necessarily lead to increased performance in phenotype predictions <span class="citation" data-cites="IHi1L0uN">[<a href="#ref-IHi1L0uN" role="doc-biblioref">42</a>]</span>.
However, such methods can be useful in their own right.
PLIER (and the associated MultiPLIER framework) use prior knowledge genes to guide the latent variables learned by a matrix factorization technique <span class="citation" data-cites="Ki2ij7zE 14rnBunuZ">[<a href="#ref-Ki2ij7zE" role="doc-biblioref">43</a>,<a href="#ref-14rnBunuZ" role="doc-biblioref">44</a>]</span>.
The resulting latent variables can then be used in differential expression analyses in lieu of raw gene counts, allowing dimensionality reduction while guiding the learned variables towards biological relevance.</p>
<p>Selecting gene subsets via a heuristic or a machine learning model is also popular.
Sevakula et al. use decision stumps to select features then use a stacked autoencoder-type architecture to further compress the representation <span class="citation" data-cites="2i0SZtHv">[<a href="#ref-2i0SZtHv" role="doc-biblioref">45</a>]</span>.
Xiao et al. did something similar where they reduced the data to only genes were differentially expressed between their conditions of interest, then used a stacked autoencoder architecture <span class="citation" data-cites="uXRnjUvq">[<a href="#ref-uXRnjUvq" role="doc-biblioref">46</a>]</span>.
Instead of looking at raw differential expression, Dhruba et al. used another subsetting method called ReliefF <span class="citation" data-cites="bBLm1pxP">[<a href="#ref-bBLm1pxP" role="doc-biblioref">47</a>]</span> to find the top 200 genes for their source and target dataset, then kept the intersection for use in their model <span class="citation" data-cites="17srxvYZd">[<a href="#ref-17srxvYZd" role="doc-biblioref">48</a>]</span>.
More recently, Li et al. used a genetic algorithm for feature selection <span class="citation" data-cites="jxCyAK09">[<a href="#ref-jxCyAK09" role="doc-biblioref">49</a>]</span>.</p>
<p>Not all papers use a subset of the original genes in their analysis, however.
It is fairly common in recent years for authors to transform the data into a new lower dimensional space based on various metrics.
This used to be done via principle component analysis (PCA), a method that performs a linear transformation to
maximize the variance explained by a reduced number of dimensions <span class="citation" data-cites="CD9ApROI qJXwpyvk">[<a href="#ref-CD9ApROI" role="doc-biblioref">50</a>,<a href="#ref-qJXwpyvk" role="doc-biblioref">51</a>]</span>.
Now scientists typically use different types of autoencoders, which learn a nonlinear mapping from the original space to a space with fewer dimensions.
Deepathology uses variational <span class="citation" data-cites="NLVTJ9Lj">[<a href="#ref-NLVTJ9Lj" role="doc-biblioref">52</a>]</span> and contractive <span class="citation" data-cites="14bFfy6t2">[<a href="#ref-14bFfy6t2" role="doc-biblioref">53</a>]</span> autoencoders in their model <span class="citation" data-cites="z3sjep1J">[<a href="#ref-z3sjep1J" role="doc-biblioref">54</a>]</span>, while Danaee et al. used a stacked denoising autoencoder <span class="citation" data-cites="M4V6xZ3y 11ZzdspWP">[<a href="#ref-M4V6xZ3y" role="doc-biblioref">55</a>,<a href="#ref-11ZzdspWP" role="doc-biblioref">56</a>]</span>.
Both papers compared their autoencoder dimensionality reduction to that of PCA and found that it performed better.
Danaee found that kernel PCA, a nonlinear version of PCA performed equivalently though.</p>
<p>It is also possible to use regularization methods to perform dimensionality reduction.
While they do not influence the nominal dimensionality of the data, they reduce the effective dimensionality by putting constraints on the input data or the model.
For example, SAUCIE uses an autoencoder structure, but combines it with a number of exotic regularization methods to further decrease the effective dimensionality of their data <span class="citation" data-cites="1CPSh19Mn">[<a href="#ref-1CPSh19Mn" role="doc-biblioref">57</a>]</span>.
In DeepType, Chen et al. use a more conventional elastic net regularization <span class="citation" data-cites="11cqxAool">[<a href="#ref-11cqxAool" role="doc-biblioref">58</a>]</span> to induce sparsity in the first level of their network under the assumption that most genes’ expression will not affect a cancer’s subtype <span class="citation" data-cites="IRSA7yBm">[<a href="#ref-IRSA7yBm" role="doc-biblioref">20</a>]</span>.</p>
<p>Ultimately, there is no clear consensus in which dimensionality reduction methods perform the best.
Among the methods that transform the data there is a small amount of evidence that nonlinear transformations outperform linear ones, but only a few studies have tried both.
Going forward, a systematic evaluation of gene selection and dimensionality reduction methods on a variety of problems could be a huge asset to the
field.</p>
<h3 id="evaluating-model-performance">Evaluating Model Performance</h3>
<p>Validation is another important consideration in phenotype prediction.
The gold standard of validation would be a knockout and rescue assay demonstrating that the predicted mechanism or expression relationship truly exists.
Since machine learning models make predictions of nonlinear relationships between thousands of genes, however, such validation isn’t feasible.
Instead scientists evaluate their models’ efficacy by testing their performance on data they didn’t train them on.
Test datasets can be built in different ways, assorting roughly into three tiers based on their external validity.</p>
<p>The most basic method is referred to as cross-validation.
In cross-validation, the training data is split into a training and validation dataset.
The model is trained on the training dataset, then its performance is measured on the validation dataset.
Typically this is done with a process called five-fold cross-validation, where the process is repeated five times on five different ways of splitting up the training data.
This method is common <span class="citation" data-cites="17srxvYZd jxCyAK09 11ZzdspWP">[<a href="#ref-17srxvYZd" role="doc-biblioref">48</a>,<a href="#ref-jxCyAK09" role="doc-biblioref">49</a>,<a href="#ref-11ZzdspWP" role="doc-biblioref">56</a>]</span>, but isn’t really a rigorous evaluation.
Because the same dataset is used for both selecting a model and measuring performance, the data can ’go stale’ when you test several models <span class="citation" data-cites="KE9BUIOX">[<a href="#ref-KE9BUIOX" role="doc-biblioref">59</a>]</span>.
In the extreme case, it is possible to get 100% accuracy by testing random prediction schemes on the data.</p>
<p>In order to keep data fresh, some researchers use a more rigorous method called a held out test set<span class="citation" data-cites="z3sjep1J 2i0SZtHv">[<a href="#ref-2i0SZtHv" role="doc-biblioref">45</a>,<a href="#ref-z3sjep1J" role="doc-biblioref">54</a>]</span>.
In the held out test set paradigm, a portion of the dataset is set aside and effectively put in a locked box until the end of the analysis.
Once the model architecture, hyperparameters, and dimensionality reduction decisions are all made via cross-validation on the training data, the lock box can be opened and the data within used for evaluation.
As the lock box data is only used once, it has no risk of becoming stale due to multiple testing.
The only drawback to this method is that is depends on the assumption that the data in the real world is distributed the same as the data in your training set.</p>
<p>The best (and most difficult) way to evaluate a model is by using an independent dataset.
Ideally, an independent dataset is created by a different group or on a different expression quantification platform.
For example, once their model was trained, Chen et al. evaluated their model on a dataset from GEO, a dataset from GTEx, and a cancer cell line <span class="citation" data-cites="12QQw9p7v">[<a href="#ref-12QQw9p7v" role="doc-biblioref">39</a>]</span>.
It is also possible to use combinations of validation methods.
In their paper Grewal et al. used a held-out section of their original data, then went on to evaluate their model in an independent dataset <span class="citation" data-cites="ClFEdqWg">[<a href="#ref-ClFEdqWg" role="doc-biblioref">37</a>]</span>.
Similarly, Malta et al. used cross-validation initially, but then evaluated their model on an external microarray dataset to ensure their data wasn’t stale <span class="citation" data-cites="rYMEu6oz">[<a href="#ref-rYMEu6oz" role="doc-biblioref">60</a>]</span>.
Likewise, Deng at al. initially benchmark their model on various simulated data sets, but then go on to validate their model on real data <span class="citation" data-cites="V3nGUaio">[<a href="#ref-V3nGUaio" role="doc-biblioref">61</a>]</span>.</p>
<p>Ultimately researchers work with what they have, and it’s not always possible to acquire an independent dataset.
That being said, it is always worth keeping the different tiers of external validity in mind when evaluating papers that use machine learning.</p>
<h3 id="transfer-learning">Transfer Learning</h3>
<p>Transfer learning is a field of machine learning that uses information from outside of the training dataset to improve model performance.
Techniques from the field of transfer learning are particularly useful in the domain of gene expression, because there are large databases like GEO and TCGA that contain data that may be useful in prediction tasks.
In this section we’ll focus in on two types of transfer learning that are particularly useful: multitask learning and semi-supervised learning.</p>
<p>Multitask learning involves training a model on multiple problems in order to improve the model’s performance on a problem of interest.
As gene expression patterns can be shared across diseases <span class="citation" data-cites="Uot2y2ws 7k4Mlul7">[<a href="#ref-Uot2y2ws" role="doc-biblioref">62</a>,<a href="#ref-7k4Mlul7" role="doc-biblioref">63</a>]</span>, the extra data can help increase the model’s power.
For example, instead of training a model to learn one drug response at a time, Yuan et al.
had better results predicting all the drugs in their dataset simultaneously <span class="citation" data-cites="URjcKCcA">[<a href="#ref-URjcKCcA" role="doc-biblioref">64</a>]</span>.
Similarly, Deepathology predicts tissue type, disease, and miRNA expression simultaneously <span class="citation" data-cites="z3sjep1J">[<a href="#ref-z3sjep1J" role="doc-biblioref">54</a>]</span>.
It is worth noting that multitask learning works best when using a deep learning model.
When using standard machine learning it is necessary to perform some difficult data transformation to do classification on multiple classes <span class="citation" data-cites="Vzg9ivZU">[<a href="#ref-Vzg9ivZU" role="doc-biblioref">35</a>]</span>.</p>
<p>Where supervised learning uses entirely labeled data, semi-supervised learning takes advantage of unlabeled data as well.
The most popular way of doing semi-supervised learning is to use an autoencoder structure to initialize your model’s weights.
Where most models begin training with a randomly initialized set of weights, it is possible to initially train a neural network to create a compressed representation of the input data (an encoding).
The weights that it learns in the process often turn out to be a better initialization when the labeled training data is finally brought in.
There are a number of ways to perform the autoencoding step.
Instead of training all the layers of the network simultaneously, it is possible to train one layer to create the encoding at a time <span class="citation" data-cites="2i0SZtHv uXRnjUvq">[<a href="#ref-2i0SZtHv" role="doc-biblioref">45</a>,<a href="#ref-uXRnjUvq" role="doc-biblioref">46</a>]</span>.
This is referred to as a stacked autoencoder.
One can also train the whole network at the same time, as Danaee et al do with their denoising autoencoder <span class="citation" data-cites="11ZzdspWP">[<a href="#ref-11ZzdspWP" role="doc-biblioref">56</a>]</span>.
Not all methods are autoencoder-based though.
Dhruba et al. develop their own semi-supervised learning process that teaches a model to learn a latent space between classes <span class="citation" data-cites="17srxvYZd">[<a href="#ref-17srxvYZd" role="doc-biblioref">48</a>]</span>.</p>
<h3 id="deep-learning-vs-classical-ml">Deep Learning vs Classical ML</h3>
<p>Recent years have seen a dramatic shift towards deep learning methods.
It is not immediately clear, however, whether this is a good decision for problems without giant datasets.
While some argue that deep learning is overrated and simpler models should be used instead <span class="citation" data-cites="EMrWUv3D GE6d2dOD">[<a href="#ref-EMrWUv3D" role="doc-biblioref">65</a>,<a href="#ref-GE6d2dOD" role="doc-biblioref">66</a>]</span>, others find that deep learning outperforms even domain specific models <span class="citation" data-cites="xSV2BrbO 15s31cve5">[<a href="#ref-xSV2BrbO" role="doc-biblioref">67</a>,<a href="#ref-15s31cve5" role="doc-biblioref">68</a>]</span>.</p>
<p>Because it is unclear which type of model will perform best on which dataset, it is important to try both simple and complex models.
In the Deepathology paper, Azarkahlili et al. found that their deep neural networks outperformed decision tree, KNN, random forest, logistic regression, and SVM models <span class="citation" data-cites="z3sjep1J">[<a href="#ref-z3sjep1J" role="doc-biblioref">54</a> ]</span>.
Likewise, in gene expression imputation, Chen et al. found that their neural network classifier outperformed linear regression in 99.97 percent of genes and k-nearest neighbors in all genes <span class="citation" data-cites="12QQw9p7v">[<a href="#ref-12QQw9p7v" role="doc-biblioref">39</a>]</span>.
On the other hand, Grewal et al. tried multiple methods and found they work roughly the same <span class="citation" data-cites="ClFEdqWg">[<a href="#ref-ClFEdqWg" role="doc-biblioref">37</a>]</span>.
They settled this by combining a few different models into an ensemble.</p>
<p>Due to technical considerations <span class="citation" data-cites="rYMEu6oz">[<a href="#ref-rYMEu6oz" role="doc-biblioref">60</a>]</span> or other reasons, some authors only evaluate a single model <span class="citation" data-cites="uXRnjUvq">[<a href="#ref-uXRnjUvq" role="doc-biblioref">46</a>]</span>.
While this simplifies the analysis for their papers, it makes it unclear whether they could have done better with a different model.
This is particularly important for authors who are using deep learning models, because simpler models tend to be much more interpretable.</p>
<p>In chapters 3 and 4, we apply machine learning models to transcriptomic data.
Chapter 3 has us comparing linear and deep learning models and showing that the linear models perform at least as well as the neural networks.
Chapter 4 continues the idea by demonstrating that classical machine learning can be used to great effect on gene expression data.</p>
<h2 id="citation-indices">Citation indices</h2>
<p>Over the past century quantifying the progress of science has become popular.
Even before computers made it easy to collate information about publications, work had already begun to evaluate papers based on their number of citations <span class="citation" data-cites="dmxNoeYV">[<a href="#ref-dmxNoeYV" role="doc-biblioref">69</a>]</span>.
There is even a book about it <span class="citation" data-cites="107JaW2qS">[<a href="#ref-107JaW2qS" role="doc-biblioref">70</a>]</span>.</p>
<p>Determining the relative “impact” of different authors and journals is a perennial question when measuring science.
One of the most commonly used metrics in this space is the h-index, which balances an author’s number of publications with the number of citations each receives <span class="citation" data-cites="qXsETMbA">[<a href="#ref-qXsETMbA" role="doc-biblioref">71</a>]</span>.
However, the h-index is not a perfect metric <span class="citation" data-cites="1bkadVmO">[<a href="#ref-1bkadVmO" role="doc-biblioref">72</a>]</span> and has arguably become less useful in recent years <span class="citation" data-cites="OsrIUdWt">[<a href="#ref-OsrIUdWt" role="doc-biblioref">73</a>]</span>.
Other metrics, like the g-index<span class="citation" data-cites="iDjOlq4q">[<a href="#ref-iDjOlq4q" role="doc-biblioref">74</a>]</span> and the i-10 index (https://scholar.google.com/), try to improve on the h-index by placing a higher weight on more highly cited papers.</p>
<p>There are metrics for comparing journals as well.
The Journal Impact Factor <span class="citation" data-cites="16V0td5f2">[<a href="#ref-16V0td5f2" role="doc-biblioref">75</a>]</span> is the progenitor journal metric, evaluating journals based on how many citations the average paper in that journal has received over the past few years.
Other measures use a more network-based approach to quantifying journals’ importance.
The most common are Eigenfactor <span class="citation" data-cites="4TkOo7Oy">[<a href="#ref-4TkOo7Oy" role="doc-biblioref">76</a>]</span> and the SCImago Journal Rank (https://www.scimagojr.com/), which use variations on the PageRank algorithm to evaluate the importance of various journals.</p>
<p>Academic articles are arguably the main building blocks of scientific communication, so it makes sense to try to understand which ones are the most important.
Citation count seems like an obvious choice, but differences in citation practices between fields <span class="citation" data-cites="5vaZVhmk">[<a href="#ref-5vaZVhmk" role="doc-biblioref">77</a>]</span> make it too crude a measure of impact.
Instead, many other metrics have been developed to choose which papers to read.</p>
<p>Many of these methods work by analyzing the graph formed by treating articles as nodes and citations as edges.
PageRank<span class="citation" data-cites="zeuTsDVX">[<a href="#ref-zeuTsDVX" role="doc-biblioref">78</a>]</span>, one of the most influential methods for ranking nodes’ importance in a graph, can also be applied to ranking papers <span class="citation" data-cites="ZiPXgNU5">[<a href="#ref-ZiPXgNU5" role="doc-biblioref">79</a>]</span>.
It is not the only graph-based method, though.
Other centrality calculation methods, such as betweenness centrality, would make sense to use but are prohibitively computationally expensive to run.
Instead, methods like the disruption index <span class="citation" data-cites="UTLLCTKy">[<a href="#ref-UTLLCTKy" role="doc-biblioref">80</a>]</span> and its variants <span class="citation" data-cites="PGRGcmLi">[<a href="#ref-PGRGcmLi" role="doc-biblioref">81</a>]</span> are more often used.</p>
<p>Some lines of research try to quantify other desirable characteristics of papers.
For example, Foster et al. claim to measure innovation by looking at papers that create new connections between known chemical entities <span class="citation" data-cites="qT77Z7V">[<a href="#ref-qT77Z7V" role="doc-biblioref">82</a>]</span>.
Likewise, Wang et al. define novel papers as those that cite papers from unusual combinations of journals <span class="citation" data-cites="RzTov9Er">[<a href="#ref-RzTov9Er" role="doc-biblioref">83</a>]</span>.
The Altmetric Attention Score (https://www.altmetric.com/) goes even further, measuring the attention on a paper from outside the standard academic channels.</p>
<p>These metrics do not stand alone, however.
Much work has gone into improving the various methods by shoring up their weaknesses or normalizing them to make them more comparable across fields.
The relative citation ratio makes citation counts comparable across fields by normalizing it according to other papers in its neighborhood of the citation network <span class="citation" data-cites="kZI40ZXS">[<a href="#ref-kZI40ZXS" role="doc-biblioref">84</a>]</span>.
Similarly, the source-normalized impact per paper normalizes article citation counts based on the total number of citations in the whole field <span class="citation" data-cites="11IkPxdIL">[<a href="#ref-11IkPxdIL" role="doc-biblioref">85</a>]</span>.
Several methods modify PageRank, such as Topical PageRank, which incorporates topic and journal prestige information into the PageRank calculation <span class="citation" data-cites="12CYfIcWF">[<a href="#ref-12CYfIcWF" role="doc-biblioref">86</a>]</span>, and
Vaccario et al.’s page and field rescaled PageRank, which accounts for differences between papers’ ages and fields <span class="citation" data-cites="4F5AdeXW">[<a href="#ref-4F5AdeXW" role="doc-biblioref">87</a>]</span>.
There are also several variants of the disruption index <span class="citation" data-cites="PGRGcmLi">[<a href="#ref-PGRGcmLi" role="doc-biblioref">81</a>]</span>.</p>
<p>Of course, these methods only work with data to train and evaluate them on.
We have come a long way from Garfield’s “not unreasonable” proposal to aggregate one million citations manually <span class="citation" data-cites="dmxNoeYV">[<a href="#ref-dmxNoeYV" role="doc-biblioref">69</a>]</span>.
These days we have several datasets with hundreds of millions to billions of references (https://www.webofknowledge.com, https://www.scopus.com <span class="citation" data-cites="126JIm8me">[<a href="#ref-126JIm8me" role="doc-biblioref">88</a>]</span>).</p>
<p>Quantifying science could be better, however.
In addition to the shortcomings of individual methods <span class="citation" data-cites="1CjuavV0Y DupOCXrp Qd54lMyE">[<a href="#ref-1CjuavV0Y" role="doc-biblioref">89</a>,<a href="#ref-DupOCXrp" role="doc-biblioref">90</a>,<a href="#ref-Qd54lMyE" role="doc-biblioref">91</a>]</span>, there are issues inherent to reducing the process of science to numbers.
To quote Alfred Korzybski, “the map is not the territory.”
Metrics of science truly measure quantitative relationships like mean citation counts, despite purporting to reflect “impact,” “disruption,” or “novelty.”
If we forget that, we can mistake useful tools for arbiters of ground truth.</p>
<p>In chapter 5, we dive into one such shortcoming by demonstrating differences in article PageRanks between fields.
There we argue that normalizing out field-specific differences obscures useful signal and propose new directions of research for future citation metrics.</p>
<h1 id="chapter-1-reproducibility-standards-for-machine-learning-in-the-life-sciences">Chapter 1: Reproducibility standards for machine learning in the life sciences</h1>
<p>This chapter was originally published in Nature Methods as “Reproducibility standards for machine learning in the life sciences” by Benjamin J. Heil, Michael M. Hoffman, Florian Markowetz, Su-In Lee, Casey S. Greene, and Stephanie C. Hicks (https://doi.org/10.1038/s41592-021-01256-7).</p>
<p><strong>Contributions:</strong><br />
C.S.G. was responsible for conceptualization. B.J.H. was responsible for project administration. B.J.H. and S.C.H. wrote the original draft of the manuscript; and B.J.H., S.C.H., M.M.H., S.L., F.M. and C.S.G. contributed to reviewing and editing.</p>
<h2 id="abstract-1">Abstract</h2>
<p>Establishing reproducibility expectations focused on data, models, and code will ensure that the life sciences community can trust machine learning analyses.</p>
<h2 id="introduction-2">Introduction</h2>
<p>The field of machine learning has grown tremendously within the past ten years.
In the life sciences, machine learning models are being rapidly adopted because they are well suited to cope with the scale and complexity of biological data.
There are drawbacks to using such models though.
For example, machine learning models can be harder to interpret than simpler models, and this opacity can obscure learned biases.
If we are going to use such models in the life sciences, we will need to trust them.
Ultimately all science requires trust <span class="citation" data-cites="1oH3MHiP">[<a href="#ref-1oH3MHiP" role="doc-biblioref">92</a>]</span> — no scientist can reproduce the results from every paper they read.
The question, then, is how to ensure that machine learning analyses in the life sciences can be trusted.</p>
<p>One attempt at creating trustworthy analyses with machine learning models revolves around reporting analysis details such as hyperparameter values, model architectures, and data splitting procedures.
Unfortunately, such reporting requirements are insufficient to make analyses trustworthy.
Documenting implementation details without making data, models, and code publicly available and usable by other scientists does little to help future scientists attempting the same analyses and less to uncover biases.
Authors can only report on biases they already know about, and without the data, models, and code, other scientists will be unable to discover issues post-hoc.</p>
<p>For machine learning models in the life sciences to become trusted, scientists must prioritize computational reproducibility <span class="citation" data-cites="XmeBExNd">[<a href="#ref-XmeBExNd" role="doc-biblioref">93</a>]</span>.
Specifically, using published data, models, and code, other scientists must be able to obtain the same results as the original authors.
With access to published data, models, and code, a researcher can confirm that a model functions and probe how the model functions.
This means that using the published model a third party can examine for themselves the accuracy of reported results and biases in the model.
Analyses and models that are reproducible by third parties can be examined in depth and, ultimately, become worthy of trust.
To that end, the life science community should adopt norms and standards that underlie reproducible machine learning research.</p>
<h2 id="the-menu">The menu</h2>
<p>While many regard the computational reproducibility of a work as a binary property, we prefer to think of it on a sliding scale <span class="citation" data-cites="XmeBExNd">[<a href="#ref-XmeBExNd" role="doc-biblioref">93</a>]</span> reflecting the time needed to reproduce.
Published works fall somewhere on this scale, which is bookended by “forever”, for a completely irreproducible work, and “zero”, for a work where one can automatically repeat the entire analysis with a single keystroke.
Since it makes little sense to impose a single standard dividing work into “reproducible” and “irreproducible”, we instead propose a menu of three standards with varying degrees of rigor for computational reproducibility:</p>
<p>The bronze standard: the authors make the data, models, and code used in the analysis publicly available. The bronze standard is the minimal standard for reproducibility. Without data, models, and code, it is not possible to reproduce a work.
The silver standard: in addition to meeting the bronze standard, (1) the dependencies of the analysis can be downloaded and installed in a single command, (2) key details for reproducing the work are documented, including the order in which to run the analysis scripts, the operating system used, and system resource requirements, and (3) all random components in the analysis are set to be deterministic. The silver standard is a midway point between minimal availability and full automation. Works that meet this standard will take much less time to reproduce than ones only meeting the bronze standard.
The gold standard: the work meets the silver standard, and the authors make the analysis reproducible with a single command. The gold standard for reproducibility is full automation. When a work meets this standard, it will take little to no effort for a scientist to reproduce it.</p>
<p>While reporting has become a recent area of focus <span class="citation" data-cites="AMHLAKQN lOLryKMv 1DSgCvdQb">[<a href="#ref-AMHLAKQN" role="doc-biblioref">94</a>,<a href="#ref-lOLryKMv" role="doc-biblioref">95</a>,<a href="#ref-1DSgCvdQb" role="doc-biblioref">96</a>]</span>, excellent reporting is akin to a nutrition information panel. It describes information about a work, but is insufficient for reproducing the work.
In the best case it provides a summary of what the researchers who conducted the analysis know about biases in the data, model limitations, and other elements.
It does not, however, provide enough information for someone to fully understand how the model came to be.
For these reasons, concrete standards for ensuring reproducibility should be preferred over reporting requirements.</p>
<h2 id="bronze">Bronze</h2>
<h3 id="data">Data</h3>
<p>Data are a fundamental component of analyses.
Without data, models can not be trained and analyses can not be reproduced.
Moreover, biases and artifacts in the data that were missed by the authors cannot be discovered if the data are never made available.
For the data in an analysis to be trusted, they must be published.</p>
<p>To that end, all datasets used in a publication should be made publicly available when their corresponding manuscript is first posted as a preprint or published by a peer-reviewed journal.
Specifically, the raw form of all data used for the publication must be published.
The way the bronze standard should be met depends on the data used.
Authors should deposit new data in a specialist repository designed for that kind of data <span class="citation" data-cites="DPHUSOUd">[<a href="#ref-DPHUSOUd" role="doc-biblioref">97</a>]</span>, when possible.
For example, one may deposit gene expression data in the Gene Expression Omnibus <span class="citation" data-cites="14VfbatMA">[<a href="#ref-14VfbatMA" role="doc-biblioref">98</a>]</span> or microscopy images in the BioImage Archive <span class="citation" data-cites="PjDNfyd6">[<a href="#ref-PjDNfyd6" role="doc-biblioref">99</a>]</span>.
If no specialist repository for that data type exists, one should instead use a generalist repository like Zenodo (https://zenodo.org) for datasets of up to 50 GB or Dryad (https://datadryad.org/) for datasets larger than 50GB.
When researchers use existing datasets, they must include the code required to download and preprocess the data.</p>
<h3 id="models">Models</h3>
<p>Sharing trained models is another critical component for reproducibility.
Even if the code for an analysis were perfectly reproducible and required no extra scientist-time to run, its corresponding model would still need to be made publicly available.
Requiring people who wish to use a method on their own data to re-train a model slows the progress of science, creates an unnecessary barrier to entry, and wastes the compute and effort of future researchers.
Being unable to examine a model also makes trusting it difficult.
Without access to the model it is hard to say whether the model fails to generalize to other datasets, fails to make fair decisions across demographic groups, or learns to make predictions based on artifacts in the data.</p>
<p>Because of the importance of sharing trained models, meeting the bronze standard of reproducibility requires that authors deposit trained weights for the models used to generate their results in a public repository.
However, authors do not need to publish the weights for additional models from a hyperparameter sweep if one can reproduce the results without them.
When a relevant specialist model zoo such as Kipoi <span class="citation" data-cites="tQy0rfF4">[<a href="#ref-tQy0rfF4" role="doc-biblioref">100</a>]</span> or Sfaira <span class="citation" data-cites="AHZYK6YM">[<a href="#ref-AHZYK6YM" role="doc-biblioref">101</a>]</span> exists, authors should deposit the models there.
Otherwise, authors can deposit the models in a generalist repository such as Zenodo.
Making models available solely on a non-archived website, such as a GitHub project, does not fulfill this requirement.</p>
<h3 id="source-code">Source Code</h3>
<p>From a reproducibility standpoint, a work’s source code is as critical as its methods section.
Source code contains implementation details that a future author is unlikely to replicate exactly from methods descriptions and reporting tables.
These small deviations can lead to different behavior between the original work and the reproduced one.
That is, of course, ignoring the huge burden of having to reimplement the entire analysis from scratch.
For the computational components of a study, the code is likely a better description of the work than the methods section itself.
As a result, computational papers without published code should meet similar skepticism to papers without methods sections.</p>
<p>To meet the bronze standard, authors must deposit code in a third-party, archivable repository like Zenodo.
This includes the code used in training, tuning, and testing models, creating figures, processing data, and generating the final results.
One good way of meeting the bronze standard involves creating a GitHub project and archiving it in Zenodo.
Doing so gives both the persistence of Zenodo required by scholarly literature and GitHub’s resources for further development and use, such as the user support forum provided by GitHub Issues.</p>
<h2 id="silver">Silver</h2>
<p>While it is possible to reproduce an analysis with only its data, models, and code, this task is by no means easy.
Fortunately there are best practices from the field of software engineering that can make reproducing analyses easier by simplifying package management, recording analysis details, and controlling randomness.</p>
<p>One roadblock that appears when attempting to reproduce an analysis stems from differences in behavior between versions of packages used in the analysis.
Analyses that once worked with specific dependency versions can stop working altogether with later versions.
Guessing which versions one must use to reproduce an analysis—or even to get it to run at all—can feel like playing a game of “package Battleship”.
Proper use of dependency management tools like Packrat (https://rstudio.github.io/packrat/) and Conda (https://conda.io/) can eliminate these difficulties both for the authors and others seeking to build on the work by tracking which versions of packages are used.</p>
<p>Authors may also wish to consider containerization for managing dependencies.
Container systems like Docker <span class="citation" data-cites="40QbsPCe">[<a href="#ref-40QbsPCe" role="doc-biblioref">102</a>]</span> allow authors to specify the system state in which to run their code more precisely than just versions of key software packages.
Containerization provides better guarantees of reproducing a precise software environment, but this very fact can also facilitate code that won’t tolerate even modest environment changes.
That brittleness can make it more difficult for future researchers to build on the original analysis.
Therefore, we recommend that authors using containers also ensure that their code works on the latest version of at least one operating system distribution.
Furthermore, containers do not fully insulate the running environment from the underlying hardware.
Authors expecting bit-for-bit reproducibility from their containers may find that GPU-accelerated code fails to yield identical results on other machines due to the presence of different hardware or drivers.</p>
<p>Knowing the steps to run an analysis is a crucial part of reproducing it, yet this knowledge is often not formally recorded.
It takes far less time for the original authors to document factors such as the order of analysis components or information about the computers used than for a third-party analyst attempting to reproduce the work to determine that information on their own.
Accordingly, the silver standard requires that authors record the order in which one should run their analysis components, the operating system version used to produce the work, and the time taken to run the code.
Authors must also list the system resources that yielded that time, such as the model and number of CPUs and GPUs and the amount of CPU RAM and GPU RAM required.
Authors may record the order in which one should run components (1) in a README file within the code repository, (2) by adding numbers to the beginning of each script’s name to denote their order of execution, or (3) by providing a script to run them in order.
Authors must include details on the operating system, wall clock and CPU running time, and system resources used both within the body of the manuscript and in the README.</p>
<p>The last challenge of this section, randomness, is common in machine learning analyses.
Dataset splitting, neural network initialization, and even some GPU-parallelized math used in model training all include elements of randomness.
Because models’ outputs depend heavily on these factors, the pseudorandom number generators used in analyses must be seeded to ensure consistent results.
How the seeds are set depends on the language, though authors need to take special care when working with deep learning libraries.
Current implementations often do not prioritize determinism, especially when accelerating operations on GPUs.
However, some frameworks have options to mitigate nondeterministic operation (https://pytorch.org/docs/1.8.1/notes/randomness), and future versions may have fully deterministic operation (https://github.com/NVIDIA/framework-determinism).
For now, the best way to account for this type of randomness is by publishing trained models.
This nondeterminism is another reason why the minimal standard requires model publication—reproducing the model using data and code alone may prove impossible.</p>
<p>As it is difficult to evaluate the extent to which an analysis follows best practices, we provide three requirements that must be met to achieve the silver standard in reproducibility.
First, future users must be able to download and install all software dependencies for the analysis with a single command.
Second, the order in which the analysis scripts should be run and how to run them should be documented.
Finally, any random elements within the analysis should be made deterministic.</p>
<h2 id="gold">Gold</h2>
<p>The gold standard for reproducibility requires the entire analysis to be reproducible with a single command.
Achieving this goal requires authors to automate all the steps of their analysis, including downloading data, preprocessing data, training models, producing output tables, and generating and annotating figures.
Full automation stands in addition to tracking dependencies and making their data and code available.
In short, by meeting the gold standard authors make the burden of reproducing their work as small as possible.</p>
<p>Workflow management software such as Snakemake <span class="citation" data-cites="NcYZqBux">[<a href="#ref-NcYZqBux" role="doc-biblioref">103</a>]</span> or Nextflow <span class="citation" data-cites="4XDvZWxk">[<a href="#ref-4XDvZWxk" role="doc-biblioref">104</a>]</span> streamline the work of meeting the gold standard.
They enable authors to create a series of rules that run all the components in an analysis.
While a simple shell script can also accomplish this goal, workflow management software provides a number of advantages without extra work from the authors.
For example, workflow management software can make it easy to restart analyses after errors, parallelize analyses, and track the progress of an analysis as it runs.</p>
<h2 id="caveats">Caveats</h2>
<h3 id="privacy">Privacy</h3>
<p>Not all data can be publicly released.
Some data contain personally identifiable information or are restricted by a data use agreement.
In these cases data should be stored in a controlled access repository <span class="citation" data-cites="VpgPDZxv">[<a href="#ref-VpgPDZxv" role="doc-biblioref">105</a>]</span>, but the use of controlled access should be explicitly approved by journals to prevent it from becoming another form of “data available upon request”.</p>
<p>Training models on private data also poses privacy challenges.
Models trained with standard workflows can be attacked to extract training data <span class="citation" data-cites="DsfimvK4">[<a href="#ref-DsfimvK4" role="doc-biblioref">106</a>]</span>.
Fortunately, model training methods designed to preserve privacy exist: techniques such as differential privacy <span class="citation" data-cites="LiCxcgZp">[<a href="#ref-LiCxcgZp" role="doc-biblioref">107</a>]</span> can help make models resistant to attacks seeking to uncover personally identifiable information, and can be applied with open source libraries such as Opacus (https://opacus.ai/).
Researchers working on data with privacy constraints should employ these techniques as a routine practice.</p>
<p>When data cannot be shared, models must be shared to have any hope of computational reproducibility.
If neither data nor models are published, the code is nearly useless, as it does not have anything to operate on.
Future authors could perhaps replicate the study by recollecting data and regenerating the models, but they will not be able to evaluate the original analysis based on the published materials.
When working on data with privacy restrictions, it is important for authors to use privacy preserving techniques for model training so that model release is not impeded.
Studies with only models published will not be able to be fully reproduced, but there will at least be the possibility of testing the models’ behavior on other datasets.</p>
<h3 id="compute-intensive-analyses">Compute-intensive analyses</h3>
<p>Analyses can take a long time to run.
In some cases they may take so long to run that it is infeasible for them to be reproduced by a different research group.
In those cases, authors should store and publish intermediate outputs.
Doing so allows other users to verify the final results even if they can not reproduce the entire pipeline.
Workflow management systems, as mentioned in the gold standard section, make this partial reproduction straightforward by tracking intermediate outputs and using them to reproduce the final results automatically.
Setting up a lightweight analysis demonstration, such as a web app on a small dataset or a Colab notebook (https://research.google.com/colaboratory/) running a pretrained model, can also be helpful for giving users the ability to evaluate model behavior without using large amounts of compute.</p>
<h3 id="reproducibility-of-packages-libraries-and-software-products">Reproducibility of packages, libraries, and software products</h3>
<p>The standards outlined in this paper focus on the computational reproducibility of analyses using machine learning.
Standards for software designed for reuse, such as software packages and utilities, would have a broader scope and encompass more topics.
In addition to our standards, such software should make use of unit testing, follow code style guidelines, have clear documentation <span class="citation" data-cites="1G5MoLsVr">[<a href="#ref-1G5MoLsVr" role="doc-biblioref">108</a>]</span>, and ensure compatibility across major operating systems to meet the gold standard for this type of research product.</p>
<h2 id="conclusion">Conclusion</h2>
<p>If we are to make machine learning research in the life sciences trustworthy, then we must make it computationally reproducible.
Authors who strive to meet the bronze, silver, and gold standards will increase the reproducibility of machine learning analyses in the life sciences.
These standards can also accelerate research in the field. In the status quo, there is no explicit reward for reproducible programming practices.
As a result, authors can ostensibly minimize their own programming effort by using irreproducible programming practices and leaving future authors to make up the difference.
In practice, irreproducible programming practices tend to decrease short-run effort for the authors, but increase effort in the long run on both the parts of the original authors and future reproducing authors.
Implementing the standards in a way that rewards reproducible science (Box 1) helps avoid these long-run costs.</p>
<p>Ultimately, reproducibility in computational research is comparatively easy to experimental life science research.
Computers are designed to perform the same tasks repeatedly with identical results.
If we can not make purely computational analysis reproducible, how can we ever manage to make truly reproducible work in wet lab research with such variable factors as reagents, cell lines, and environmental conditions?
If we want life science to lead the way in trustworthy, verifiable research, then setting standards for computational reproducibility is a good place to start.</p>
<h3 id="acknowledgements-1">Acknowledgements</h3>
<p>This work was supported by the Natural Sciences and Engineering Research Council of Canada (RGPIN-2015-03948 to M.M.H.); Cancer Research UK (A19274 to F.M.); and the National Institutes of Health’s National Institute of General Medical Sciences (R35 GM128638 to S.L.), the National Human Genome Research Institute (R00HG009007 to S.C.H. and R01HG010067 to C.S.G), and the National Cancer Institute of the National Institutes of Health (R01CA237170 to C.S.G.)</p>
<h3 id="author-contributions">Author contributions</h3>
<p>Conceptualization, C.S.G. Project administration, B.J.H. Writing — original draft, B.J.H., S.C.H. Writing — review &amp; editing, B.J.H., S.C.H., M.M.H., S.L., F.M., C.S.G.</p>
<h3 id="ethics-declarations">Ethics declarations</h3>
<p>Competing interests: M.M.H. received an Nvidia GPU Grant.</p>
<h2 id="box-1">Box 1</h2>
<p><strong>Journals</strong>
Journals can enforce reproducibility standards as a condition of publication.
The bronze standard should be the minimal standard, though some journals may wish to differentiate themselves by setting higher standards.
Such journals may require the silver or gold standards for all manuscripts, or for particular classes of articles such as those focused on analysis.
If journals act as the enforcing body for reproducibility standards, they can verify that the standards are met by either requiring reviewers to report which standards the work meets or by including a special reproducibility reviewer to evaluate the work.</p>
<p><strong>Badging</strong>
A badge system that indicates the trustworthiness of work could incentivize scientists to progress to higher standards of reproducibility.
Upon completing analyses, authors could submit their work to a badging organization that would then verify which standards of reproducibility their work met and assign a badge accordingly.
Such an organization would likely operate in a similar way to the Bioconductor <span class="citation" data-cites="nQNzN279">[<a href="#ref-nQNzN279" role="doc-biblioref">109</a>]</span> package review process.
Authors could then include the badge with a publication or preprint to tout the effort the authors put in to ensure their code was reproducible.
Including these badges in biosketches or CVs would make it simple to demonstrate a researcher’s track record of achieving high levels of reproducibility.
This would provide a powerful signal to funding agencies and their reviewers that a researcher’s strengths in reproducibility would maximize the results of the investment made in a project.
Universities could also promote reproducibility by explicitly requiring a track record of reproducible research in faculty hiring, annual review, and promotion.</p>
<p><strong>Reproducibility Collaborators</strong>
Adding “reproducibility collaborators” to manuscripts would also provide another means to make analyses more reproducible. We envision a reproducibility collaborator as someone outside the primary authors’ research groups who certifies that they were able to reproduce the results of the paper from only the data, models, code, and accompanying documentation. Such collaborators would currently fall under the “validation” role in the CRediT Taxonomy (https://casrai.org/credit/), though it should be made clear that the reproducibility coauthor should not also be collaborating on the design or implementation of the analysis.</p>
<h2 id="table-1">Table 1</h2>
<p>TODO COPY OVER Table 1 WHEN CONVERTING TO WORD</p>
<h1 id="chapter-3-the-effect-of-non-linear-signal-in-classification-problems-using-gene-expression">Chapter 3: The Effect of Non-Linear Signal in Classification Problems using Gene Expression</h1>
<p>This chapter has been preprinted at bioRxiv (https://www.biorxiv.org/content/10.1101/2022.06.22.497194v2), reviewed through Review Commons, and submitted for publication at PLOS Computational Biology as “The Effects of Nonlinear Signal on Expression-Based Prediction Performance” by Benjamin J. Heil, Jake Crawford, and Casey S. Greene.</p>
<p><strong>Contributions:</strong>
I designed and ran the experiments, created the figures, and wrote/edited the manuscript.
Jake Crawford acted as the primary code reviewer, gave feedback and guidance on experiments, and edited the manuscript.
Casey S. Greene gave feedback and guidance on experiments and edited the manuscript.</p>
<h2 class="page_break_before" id="abstract-2">Abstract</h2>
<p>Those building predictive models from transcriptomic data are faced with two conflicting perspectives.
The first, based on the inherent high dimensionality of biological systems, supposes that complex non-linear models such as neural networks will better match complex biological systems.
The second, imagining that complex systems will still be well predicted by simple dividing lines prefers linear models that are easier to interpret.
We compare multi-layer neural networks and logistic regression across multiple prediction tasks on GTEx and Recount3 datasets and find evidence in favor of both possibilities.
We verified the presence of non-linear signal when predicting tissue and metadata sex labels from expression data by removing the predictive linear signal with Limma, and showed the removal ablated the performance of linear methods but not non-linear ones.
However, we also found that the presence of non-linear signal was not necessarily sufficient for neural networks to outperform logistic regression.
Our results demonstrate that while multi-layer neural networks may be useful for making predictions from gene expression data, including a linear baseline model is critical because while biological systems are high-dimensional, effective dividing lines for predictive models may not be.</p>
<h2 id="introduction-3">Introduction</h2>
<p>Transcriptomic data contains a wealth of information about biology.
Gene expression-based models are already being used for subtyping cancer <span class="citation" data-cites="lnK82Ey6">[<a href="#ref-lnK82Ey6" role="doc-biblioref">110</a>]</span>, predicting transplant rejections <span class="citation" data-cites="w3jVFxUa">[<a href="#ref-w3jVFxUa" role="doc-biblioref">111</a>]</span>, and uncovering biases in public data <span class="citation" data-cites="11QqOFPV2">[<a href="#ref-11QqOFPV2" role="doc-biblioref">112</a>]</span>.
In fact, both the capability of machine learning models <span class="citation" data-cites="pT4E5exd">[<a href="#ref-pT4E5exd" role="doc-biblioref">113</a>]</span> and the amount of transcriptomic data available <span class="citation" data-cites="Nz3IMEzd 1FjFz2cPj">[<a href="#ref-Nz3IMEzd" role="doc-biblioref">114</a>,<a href="#ref-1FjFz2cPj" role="doc-biblioref">115</a>]</span> are increasing rapidly.
It makes sense, then, that neural networks are frequently being used to build predictive models from transcriptomic data <span class="citation" data-cites="z3sjep1J n1zG78a6 mfKo4pPn">[<a href="#ref-z3sjep1J" role="doc-biblioref">54</a>,<a href="#ref-n1zG78a6" role="doc-biblioref">116</a>,<a href="#ref-mfKo4pPn" role="doc-biblioref">117</a>]</span>.</p>
<p>However, there are two conflicting ideas in the literature regarding the utility of non-linear models.
One theory draws on prior biological understanding: the paths linking gene expression to phenotypes are complex <span class="citation" data-cites="9O6X3Dmj 11pMMG4s">[<a href="#ref-9O6X3Dmj" role="doc-biblioref">118</a>,<a href="#ref-11pMMG4s" role="doc-biblioref">119</a>]</span>, and non-linear models like neural networks should be more capable of learning that complexity.
Unlike purely linear models such as logistic regression, non-linear models can learn non-linear decision boundaries to differentiate phenotypes.
Accordingly, many have used non-linear models to learn representations useful for making predictions of phenotypes from gene expression <span class="citation" data-cites="1CFhfCyWN uXRnjUvq 19wuAzYvo">[<a href="#ref-uXRnjUvq" role="doc-biblioref">46</a>,<a href="#ref-1CFhfCyWN" role="doc-biblioref">120</a>,<a href="#ref-19wuAzYvo" role="doc-biblioref">121</a>]</span>.</p>
<p>The other supposes that even high-dimensional complex systems may have linear decision boundaries.
This is supported empirically: linear models seem to do as well as or better than non-linear ones in many cases <span class="citation" data-cites="1Dt8XU1y4">[<a href="#ref-1Dt8XU1y4" role="doc-biblioref">122</a>]</span>.
While papers of this sort are harder to come by — perhaps scientists do not tend to write papers about how their deep learning model was worse than logistic regression — other complex biological problems have also seen linear models prove equivalent to non-linear ones <span class="citation" data-cites="182D7GluU 1lk3HMPq">[<a href="#ref-182D7GluU" role="doc-biblioref">123</a>,<a href="#ref-1lk3HMPq" role="doc-biblioref">124</a>]</span>.</p>
<p>We design experiments to ablate linear signal and find merit to both hypotheses.
We construct a system of binary and multiclass classification problems on the GTEx and Recount3 compendia <span class="citation" data-cites="187XBwaz7 xdJRSgce">[<a href="#ref-187XBwaz7" role="doc-biblioref">125</a>,<a href="#ref-xdJRSgce" role="doc-biblioref">126</a>]</span> that shows linear and non-linear models have similar accuracy on several prediction tasks.
However, when we remove any linear separability from the data, we find non-linear models are still able to make useful predictions even when the linear models previously outperformed the non-linear ones.
Given the unexpected nature of these findings, we evaluate independent tasks, examine different problem formulations, and verify our models’ behavior with simulated data.
The models’ results are consistent across each setting, and the models themselves are comparable, as they use the same training and hyperparameter optimization processes <span class="citation" data-cites="1GHeCqbnH">[<a href="#ref-1GHeCqbnH" role="doc-biblioref">127</a>]</span>.</p>
<p>In reconciling these two ostensibly conflicting theories, we confirm the importance of implementing and optimizing a linear baseline model before deploying a complex non-linear approach.
While non-linear models may outperform simpler models at the limit of infinite data, they do not necessarily do so even when trained on the largest datasets publicly available today.</p>
<h2 id="results">Results</h2>
<h3 id="linear-and-non-linear-models-have-similar-performance-in-many-tasks">Linear and non-linear models have similar performance in many tasks</h3>
<p>We compared the performance of linear and non-linear models across multiple datasets and tasks (fig. <a href="#fig:workflow">1</a> A).
We examined using TPM-normalized RNA-seq data to predict tissue labels from GTEx <span class="citation" data-cites="187XBwaz7">[<a href="#ref-187XBwaz7" role="doc-biblioref">125</a>]</span>, tissue labels from Recount3 <span class="citation" data-cites="xdJRSgce">[<a href="#ref-xdJRSgce" role="doc-biblioref">126</a>]</span>, and metadata-derived sex labels from Flynn et al. <span class="citation" data-cites="10mtDRGf7">[<a href="#ref-10mtDRGf7" role="doc-biblioref">128</a>]</span>.
To avoid leakage between cross-validation folds, we placed entire studies into single folds (fig. <a href="#fig:workflow">1</a> B).
We evaluated models on subsampled datasets to determine the extent to which performance was affected by the amount of training data.</p>
<div id="fig:workflow" class="fignos">
<figure>
<img src="./images/workflow.svg" style="width:100.0%" alt="Figure 1: Schematic of the model analysis workflow. We evaluate three models on multiple classification problems in three datasets (A). We stratify the samples into cross-validation folds based on their study (in Recount3) or donor (in GTEx). We also evaluate the effects of sample-wise splitting and pretraining (B)." />
<figcaption aria-hidden="true"><span>Figure 1:</span> Schematic of the model analysis workflow. We evaluate three models on multiple classification problems in three datasets (A). We stratify the samples into cross-validation folds based on their study (in Recount3) or donor (in GTEx). We also evaluate the effects of sample-wise splitting and pretraining (B).</figcaption>
</figure>
</div>
<p>We used GTEx <span class="citation" data-cites="187XBwaz7">[<a href="#ref-187XBwaz7" role="doc-biblioref">125</a>]</span> to determine whether linear and non-linear models performed similarly on a well-characterized dataset with consistent experimental protocols across samples.
We first trained our models to differentiate between tissue types on pairs of the five most common tissues in the dataset.
Likely due to the clean nature of the data, all models were able to perform perfectly on these binary classification tasks (fig. <a href="#fig:signal_removed_binary">4</a> A).
Because binary classification was unable to differentiate between models, we evaluated the models on a more challenging task.
We tested the models on their ability to perform multiclass classification on all 31 tissues present in the dataset.
In the multitask setting, logistic regression slightly outperformed the five-layer neural network, which in turn slightly outperformed the three-layer net (fig. <a href="#fig:signal_removed_multiclass">2</a> A).</p>
<p>We then evaluated the same approaches in a dataset with very different characteristics: Sequence Read Archive <span class="citation" data-cites="1GBPSAJ10">[<a href="#ref-1GBPSAJ10" role="doc-biblioref">129</a>]</span> samples from Recount3 <span class="citation" data-cites="xdJRSgce">[<a href="#ref-xdJRSgce" role="doc-biblioref">126</a>]</span>.
We compared the models’ ability to differentiate between pairs of tissues (supp. fig. <a href="#fig:signal_removed_binary">4</a> B) and found their performance was roughly equivalent.
We also evaluated the models’ performance on a multiclass classification problem differentiating between the 21 most common tissues in the dataset.
As in the GTEx setting, the logistic regression model outperformed the five-layer network, which outperformed the three-layer network (fig. <a href="#fig:signal_removed_multiclass">2</a> B).</p>
<p>To examine whether these results held in a problem domain other than tissue type prediction, we tested performance on metadata-derived sex labels (fig. <a href="#fig:signal_removed_multiclass">2</a> C), a task previously studied by Flynn et al. <span class="citation" data-cites="10mtDRGf7">[<a href="#ref-10mtDRGf7" role="doc-biblioref">128</a>]</span>.
We used the same experimental setup as in our other binary prediction tasks to train the models, but rather than using tissue labels we used sex labels from Flynn et al.
In this setting we found that while the models all performed similarly, the non-linear models tended to have a slight edge over the linear one.</p>
<div id="fig:signal_removed_multiclass" class="fignos">
<figure>
<img src="./images/signal_removed_multiclass.svg" style="width:100.0%" alt="Figure 2: Performance of models across three classification tasks before and after signal removal. In each panel the loess curve and its 95% confidence interval are plotted based on points from three seeds, ten data subsets, and five folds of study-wise cross-validation (for a total of 150 points per model per panel). It is worth noting that “Sample Count” in these figures refers to the total number of RNA-seq samples, some of which share donors. As a result, the effective sample size may be lower than the sample count." />
<figcaption aria-hidden="true"><span>Figure 2:</span> Performance of models across three classification tasks before and after signal removal.
In each panel the loess curve and its 95% confidence interval are plotted based on points from three seeds, ten data subsets, and five folds of study-wise cross-validation (for a total of 150 points per model per panel).
It is worth noting that “Sample Count” in these figures refers to the total number of RNA-seq samples, some of which share donors.
As a result, the effective sample size may be lower than the sample count.</figcaption>
</figure>
</div>
<h3 id="there-is-predictive-non-linear-signal-in-transcriptomic-data">There is predictive non-linear signal in transcriptomic data</h3>
<p>Our results to this point are consistent with a world where the predictive signal present in transcriptomic data is entirely linear.
If that were the case, non-linear models like neural networks would fail to give any substantial advantage.
However, based on past results we expect there to be relevant non-linear biological signal <span class="citation" data-cites="eirYTTyk">[<a href="#ref-eirYTTyk" role="doc-biblioref">130</a>]</span>.
To get a clearer idea of what that would look like, we simulated three datasets to better understand model performance for a variety of data generating processes.
We created data with both linear and non-linear signal by generating two types of features: half of the features with a linear decision boundary between the simulated classes and half with a non-linear decision boundary (see <a href="#methods">Methods</a> for more details).
After training to classify the simulated dataset, all models effectively predicted the simulated classes.
To determine whether or not there was non-linear signal, we then used Limma <span class="citation" data-cites="PO5Xkwt3">[<a href="#ref-PO5Xkwt3" role="doc-biblioref">131</a>]</span> to remove the linear signal associated with the endpoint being predicted.
After removing the linear signal from the dataset, non-linear models correctly predicted classes, but logistic regression performed no better than random (fig. <a href="#fig:simulation">3</a> B).</p>
<p>To confirm that non-linear signal was key to the performance of non-linear methods, we generated another simulated dataset consisting solely of features with a linear decision boundary between the classes.
As before, all models were able to predict the different classes well.
However, once the linear signal was removed, all models performed no better than random guessing (fig. <a href="#fig:simulation">3</a> A).
That the non-linear models only achieved baseline accuracy also indicated that the signal removal method was not injecting non-linear signal into data where non-linear signal did not exist.</p>
<p>We also trained the models on a dataset where all features were Gaussian noise as a negative control.
As expected, the models all performed at baseline accuracy both before and after the signal removal process (fig. <a href="#fig:simulation">3</a> C).
This experiment supported our decision to perform signal removal on the training and validation sets separately.
One potential failure state when using the signal removal method would be if it induced new signal as it removed the old.
Such a state can be seen when removing the linear signal in the full dataset (supp. fig. <a href="#fig:split-signal-correction">5</a>).</p>
<div id="fig:simulation" class="fignos">
<figure>
<img src="./images/simulated_data_combined.svg" style="width:100.0%" alt="Figure 3: Performance of models in binary classification of simulated data before and after signal removal. Dotted lines indicate expected performance for a naive baseline classifier that predicts the most frequent class." />
<figcaption aria-hidden="true"><span>Figure 3:</span> Performance of models in binary classification of simulated data before and after signal removal. Dotted lines indicate expected performance for a naive baseline classifier that predicts the most frequent class.</figcaption>
</figure>
</div>
<p>We next removed linear signal from GTEx and Recount3.
We found that the neural nets performed better than the baseline while logistic regression did not (fig. <a href="#fig:signal_removed_multiclass">2</a>, fig. <a href="#fig:signal_removed_binary">4</a>).
For multiclass problems logistic regression performed poorly while the non-linear models had performance that increased with an increase in data while remaining worse than before the linear signal was removed (fig. <a href="#fig:signal_removed_multiclass">2</a> A, B)
Likewise, the sex label prediction task showed a marked difference between the neural networks and logistic regression: only the neural networks could learn from the data (fig. <a href="#fig:signal_removed_multiclass">2</a> C).
In each of the settings, the models performed less well when run on data with signal removed, indicating an increase in the problem’s difficulty.
Logistic regression, in particular, performed no better than random.</p>
<div id="fig:signal_removed_binary" class="fignos">
<figure>
<img src="./images/signal_removed_binary.svg" style="width:100.0%" alt="Figure 4: Models’ performance across binary classification tasks before and after signal removal in the Recount and GTEx datasets." />
<figcaption aria-hidden="true"><span>Figure 4:</span> Models’ performance across binary classification tasks before and after signal removal in the Recount and GTEx datasets.</figcaption>
</figure>
</div>
<p>To verify that our results were not an artifact of our decision to assign studies to cross-validation folds rather than samples, we compared the study-wise splitting that we used with an alternate method called sample-wise splitting.
Sample-wise splitting (see <a href="#methods">Methods</a>) is common in machine learning, but can leak information between the training and validation sets when samples are not independently and identically distributed among studies - a common feature of data in biology <span class="citation" data-cites="13prIHiSM">[<a href="#ref-13prIHiSM" role="doc-biblioref">132</a>]</span>.
We found that sample-wise splitting induced substantial performance inflation (supp. fig. <a href="#fig:splitting">7</a>).
The relative performance of each model stayed the same regardless of the data splitting technique, so the results observed were not dependent on the choice of splitting technique.</p>
<p>Another growing strategy in machine learning, especially on biological data where samples are limited, is training models on a general-purpose dataset and fine-tuning them on a dataset of interest.
We examined the performance of models with and without pretraining (supp. fig. <a href="#fig:pretrain">8</a>).
We split the Recount3 data into three sets: pretraining, training, and validation (fig. <a href="#fig:workflow">1</a> B), then trained two identically initialized copies of each model.
One was trained solely on the training data, while the other was trained on the pretraining data and fine-tuned on the training data.
The pretrained models showed high performance even when trained with small amounts of data from the training set.
However, the non-linear models did not have a greater performance gain from pretraining than logistic regression, and the balanced accuracy was similar across models.</p>
<h2 id="methods">Methods</h2>
<h3 id="datasets">Datasets</h3>
<h4 id="gtex">GTEx</h4>
<p>We downloaded the 17,382 TPM-normalized samples of bulk RNA-seq expression data available from version 8 of GTEx.
We zero-one standardized the data and retained the 5000 most variable genes.
The tissue labels we used for the GTEx dataset were derived from the ‘SMTS’ column of the sample metadata file.</p>
<h4 id="recount3">Recount3</h4>
<p>We downloaded RNA-seq data from the Recount3 compendium <span class="citation" data-cites="zepEBNtj">[<a href="#ref-zepEBNtj" role="doc-biblioref">133</a>]</span> during the week of March 14, 2022.
Before filtering, the dataset contained 317,258 samples, each containing 63,856 genes.
To filter out single-cell data, we removed all samples with greater than 75 percent sparsity.
We also removed all samples marked ‘scrna-seq’ by Recount3’s pattern matching method (stored in the metadata as ‘recount_pred.pattern.predict.type’).
We then converted the data to transcripts per kilobase million using gene lengths from BioMart <span class="citation" data-cites="Qgjx8811">[<a href="#ref-Qgjx8811" role="doc-biblioref">134</a>]</span> and performed standardization to scale each gene’s range from zero to one.
We kept the 5,000 most variable genes within the dataset.</p>
<p>We labeled samples with their corresponding tissues using the ‘recount_pred.curated.tissue’ field in the Recount3 metadata.
These labels were based on manual curation by the Recount3 authors.
A total of 20,324 samples in the dataset had corresponding tissue labels.
Samples were also labeled with their corresponding sex using labels from Flynn et al. <span class="citation" data-cites="11QqOFPV2">[<a href="#ref-11QqOFPV2" role="doc-biblioref">112</a>]</span>.
These labels were derived using pattern matching on metadata from the European Nucleotide Archive <span class="citation" data-cites="yLsmK3mK">[<a href="#ref-yLsmK3mK" role="doc-biblioref">135</a>]</span>.
A total of 23,525 samples in our dataset had sex labels.</p>
<h4 id="data-simulation">Data simulation</h4>
<p>We generated three simulated datasets.
The first dataset contained 1,000 samples of 5,000 features corresponding to two classes.
Of those features, 2,500 contained linear signal.
That is to say that the feature values corresponding to one class were drawn from a standard normal distribution, while the feature values corresponding to the other were drawn from a Gaussian with a mean of 6 and unit variance.</p>
<p>We generated the non-linear features similarly.
The values for the non-linear features were drawn from a standard normal distribution for one class, while the second class had values drawn from either a mean six or negative six Gaussian with equal probability.
These features are referred to as “non-linear” because two dividing lines are necessary to perfectly classify such data, while a linear classifier can only draw one such line per feature.</p>
<p>The second dataset was similar to the first dataset, but it consisted solely of 2,500 linear features.
The final dataset contained only values drawn from a standard normal distribution regardless of class label.</p>
<h3 id="model-architectures">Model architectures</h3>
<p>We used three representative models to demonstrate the performance profiles of different model classes.
The first was a linear model, ridge logistic regression, selected as a simple linear baseline to compare the non-linear models against.
The next model was a three-layer fully-connected neural network with ReLU non-linearities <span class="citation" data-cites="Xk9rmxAA">[<a href="#ref-Xk9rmxAA" role="doc-biblioref">136</a>]</span> and hidden layers of size 2500 and 1250.
This network served as a model of intermediate complexity: it was capable of learning non-linear decision boundaries, but not the more complex representations a deeper model might learn.
Finally, we built a five-layer neural network to serve as a (somewhat) deep neural net.
This model also used ReLU non-linearities, and had hidden layers of sizes 2500, 2500, 2500, and 1250.
The five-layer network, while not particularly deep compared to, e.g., state of the art computer vision models, was still in the domain where more complex representations could be learned, and vanishing gradients had to be accounted for.</p>
<h3 id="model-training">Model training</h3>
<p>We trained our models via a maximum of 50 epochs of mini-batch stochastic gradient descent in PyTorch <span class="citation" data-cites="iTP4h1rX">[<a href="#ref-iTP4h1rX" role="doc-biblioref">137</a>]</span>.
Our models minimized the cross-entropy loss using an Adam <span class="citation" data-cites="c6d3lKFX">[<a href="#ref-c6d3lKFX" role="doc-biblioref">138</a>]</span> optimizer.
They also used inverse frequency weighting to avoid giving more weight to more common classes.
To regularize the models, we used early stopping and gradient clipping during the training process.
The only training differences between the models were that the two neural nets used dropout <span class="citation" data-cites="ynNhuuuv">[<a href="#ref-ynNhuuuv" role="doc-biblioref">139</a>]</span> with a probability of 0.5, and the deeper network used batch normalization <span class="citation" data-cites="io1g9Re6">[<a href="#ref-io1g9Re6" role="doc-biblioref">140</a>]</span> to mitigate the vanishing gradient problem.</p>
<p>We ensured the results were deterministic by setting the Python, NumPy, and PyTorch random seeds for each run, as well as setting the PyTorch backends to deterministic and disabling the benchmark mode.
The learning rate and weight decay hyperparameters for each model were selected via nested cross-validation over the training folds at runtime, and we tracked and recorded our model training progress using Neptune <span class="citation" data-cites="1Dhv6WYjo">[<a href="#ref-1Dhv6WYjo" role="doc-biblioref">141</a>]</span>.</p>
<p>We also used Limma<span class="citation" data-cites="PO5Xkwt3">[<a href="#ref-PO5Xkwt3" role="doc-biblioref">131</a>]</span> to remove linear signal associated with tissues in the data.
We ran the ‘removeBatchEffect’ function on the training and validation sets separately, using the tissue labels as batch labels.
This function fits a linear model that learns to predict the training data from the batch labels, and uses that model to regress out the linear signal within the training data that is predictive of the batch labels.</p>
<h3 id="model-evaluation">Model Evaluation</h3>
<p>In our analyses we used five-fold cross-validation with study-wise data splitting.
In a study-wise split, the studies are randomly assigned to cross-validation folds such that all samples in a given study end up in a single fold (fig. <a href="#fig:workflow">1</a> B).</p>
<p><strong>Hardware</strong><br />
Our analyses were performed on an Ubuntu 18.04 machine and the Colorado Summit compute cluster.
The desktop CPU used was an AMD Ryzen 7 3800xt processor with 16 cores and access to 64 GB of RAM, and the desktop GPU used was an Nvidia RTX 3090.
The Summit cluster used Intel Xeon E5-2680 CPUs and NVidia Tesla K80 GPUs.
From initiating data download to finishing all analyses and generating all figures, the full Snakemake <span class="citation" data-cites="NcYZqBux">[<a href="#ref-NcYZqBux" role="doc-biblioref">103</a>]</span> pipeline took around one month to run.</p>
<p><strong>Recount3 tissue prediction</strong><br />
In the Recount3 setting, the multi-tissue classification analyses were trained on the 21 tissues (see Supp. Methods) that had at least ten studies in the dataset.
Each model was trained to determine which of the 21 tissues a given expression sample corresponded to.</p>
<p>To address class imbalance, our models’ performance was then measured based on the balanced accuracy across all classes.
Unlike raw accuracy, balanced accuracy (the mean across all classes of the per-class recall) isn’t predominantly determined by performance on the largest class in an imbalanced class setting.
For example, in a binary classification setting with 9 instances of class A and 1 instance of class B, successfully predicting 8 of the 9 instances of class A and none of class B yields an accuracy of 0.8 and a balanced accuracy of 0.44.</p>
<p>The binary classification setting was similar to the multiclass one.
The five tissues with the most studies (brain, blood, breast, stem cell, and cervix) were compared against each other pairwise.
The expression used in this setting was the set of samples labeled as one of the two tissues being compared.</p>
<p>The data for both settings were split in a stratified manner based on their study.</p>
<p><strong>GTEx classification</strong><br />
The multi-tissue classification analysis for GTEx used all 31 tissues.
The multiclass and binary settings were formulated and evaluated in the same way as in the Recount3 data.
However, rather than being split study-wise, the cross-validation splits were stratified according to the samples’ donors.</p>
<p><strong>Simulated data classification/sex prediction</strong><br />
The sex prediction and simulated data classification tasks were solely binary.
Both settings used balanced accuracy, as in the Recount3 and GTEx problems.</p>
<p><strong>Pretraining</strong><br />
When testing the effects of pretraining on the different model types, we split the data into three sets.
Approximately forty percent of the data went into the pretraining set, forty percent went into the training set, and twenty percent went into the validation set.
The data was split such that each study’s samples were in only one of the three sets to simulate the real-world scenario where a model is trained on publicly available data and then fine-tuned on a dataset of interest.</p>
<p>To ensure the results were comparable, we made two copies of each model with the same weight initialization.
The first copy was trained solely on the training data, while the second was trained on the pretraining data, then the training data.
Both models were then evaluated on the validation set.
This process was repeated four more times with different studies assigned to the pretraining, training, and validation sets.</p>
<h2 id="discussion-and-conclusion">Discussion and Conclusion</h2>
<p>We performed a series of analyses to determine the relative performance of linear and non-linear models across multiple tasks.
Consistent with previous papers <span class="citation" data-cites="1Dt8XU1y4 182D7GluU">[<a href="#ref-1Dt8XU1y4" role="doc-biblioref">122</a>,<a href="#ref-182D7GluU" role="doc-biblioref">123</a>]</span>, linear and non-linear models performed roughly equivalently in a number of tasks.
That is to say that there are some tasks where linear models perform better, some tasks where non-linear models have better performance, and some tasks where both model types are equivalent.</p>
<p>However, when we removed all linear signal in the data, we found that residual non-linear signal remained.
This was true in simulated data as well as GTEx and Recount3 data across several tasks.
These results also held in altered problem settings, such as using a pretraining dataset before the training dataset and using sample-wise data splitting instead of study-wise splitting.
This consistent presence of non-linear signal demonstrated that the similarity in performance across model types was not due to our problem domains having solely linear signals.</p>
<p>One limitation of our study is that the results likely do not hold in an infinite data setting.
Deep learning models have been shown to solve complex problems in biology and tend to significantly outperform linear models when given enough data.
However, we do not yet live in a world in which millions of well-annotated examples are available in many areas of biology.
Our results are generated on some of the largest labeled expression datasets in existence (Recount3 and GTEx), but our tens of thousands of samples are far from the millions or billions used in deep learning research.</p>
<p>We are also unable to make claims about all problem domains or model classes.
There are many potential transcriptomic prediction tasks and many datasets to perform them on.
While we show that non-linear signal is not always helpful in tissue or sex prediction, and others have shown the same for various disease prediction tasks, there may be problems where non-linear signal is more important.
It is also possible that other classes of models, be they simpler non-linear models or different neural network topologies, are more capable of taking advantage of the non-linear signal present in the data.</p>
<p>Ultimately, our results show that task-relevant non-linear signal in the data, which we confirm is present, does not necessarily lead non-linear models to outperform linear ones.
Additionally, our results suggest that scientists making predictions from expression data should always include simple linear models as a baseline to determine whether more complex models are warranted.</p>
<h3 id="code-and-data-availability">Code and Data Availability</h3>
<p>The code, data, and model weights to reproduce this work can be found at https://github.com/greenelab/linear_signal.
Our work meets the bronze standard of reproducibility <span class="citation" data-cites="PETW01rJ">[<a href="#ref-PETW01rJ" role="doc-biblioref">142</a>]</span> and fulfills aspects of the silver and gold standards including deterministic operation and an automated analysis pipeline.</p>
<h3 id="acknowledgements-2">Acknowledgements</h3>
<p>We would like to thank Alexandra Lee and Jake Crawford for reviewing code that went into this project.
We would also like to thank the past and present members of GreeneLab who gave feedback on this project during lab meetings.
This work utilized resources from the University of Colorado Boulder Research Computing Group, which is supported by the National Science Foundation (awards ACI-1532235 and ACI-1532236), the University of Colorado Boulder, and Colorado State University.</p>
<h4 id="funding">Funding</h4>
<p>This work was supported by grants from the National Institutes of Health’s National Human Genome Research Institute (NHGRI) under award R01 HG010067 and the Gordon and Betty Moore Foundation (GBMF 4552) to CSG.
The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
<h1 id="supplementary-materials">Supplementary Materials</h1>
<h2 id="results-1">Results</h2>
<h3 id="recount-binary-classification">Recount binary classification</h3>
<h3 id="signal-removal">Signal removal</h3>
<p>While it’s possible to remove signal in the full dataset or the train and validation sets independently, we decided to do the latter.
We made this decision because we observed potential data leakage when removing signal from the entire dataset in one go (supp. fig. <a href="#fig:split-signal-correction">5</a>).</p>
<div id="fig:split-signal-correction" class="fignos">
<figure>
<img src="./images/no_signal_sim_signal_removed.svg" alt="Figure 5:  Full dataset signal removal in a dataset without signal" />
<figcaption aria-hidden="true"><span>Figure 5:</span> <br />
Full dataset signal removal in a dataset without signal</figcaption>
</figure>
</div>
<div id="fig:recount-binary-combined" class="fignos">
<figure>
<img src="./images/recount_binary_combined.svg" alt="Figure 6:  Comparison of models’ binary classification performance before and after removing linear signal " />
<figcaption aria-hidden="true"><span>Figure 6:</span> <br />
Comparison of models’ binary classification performance before and after removing linear signal<br />
</figcaption>
</figure>
</div>
<h3 id="samplewise-splitting">Samplewise splitting</h3>
<div id="fig:splitting" class="fignos">
<figure>
<img src="./images/recount_multiclass_sample_split.svg" alt="Figure 7:  Performance of Recount3 multiclass prediction with samplewise train/val splitting" />
<figcaption aria-hidden="true"><span>Figure 7:</span> <br />
Performance of Recount3 multiclass prediction with samplewise train/val splitting</figcaption>
</figure>
</div>
<h3 id="recount3-pretraining">Recount3 Pretraining</h3>
<div id="fig:pretrain" class="fignos">
<figure>
<img src="./images/recount_pretraining.svg" alt="Figure 8:  Performance of Recount3 multiclass prediction with pretraining" />
<figcaption aria-hidden="true"><span>Figure 8:</span> <br />
Performance of Recount3 multiclass prediction with pretraining</figcaption>
</figure>
</div>
<h2 id="methods-1">Methods</h2>
<h3 id="recount3-tissues-used">Recount3 tissues used</h3>
<p>The tissues used from Recount3 were blood, breast, stem cell, cervix, brain, kidney, umbilical cord, lung, epithelium, prostate, liver, heart, skin, colon, bone marrow, muscle, tonsil, blood vessel, spinal cord, testis, and placenta.</p>
<h1 id="chapter-4-mousiplier-the-largest-and-most-murine-plier-model-ever-trained">Chapter 4: MousiPLIER, the largest and most murine PLIER model ever trained</h1>
<p>This chapter is from a manuscript in progress that is a collaboration between the Heller and Greene labs.</p>
<p><strong>Contributions</strong><br />
I am co-first author on the manuscript.
I trained the MousiPLIER model, wrote and edited the manuscript, wrote code to make the results easier to use in Python, and ran the analyses leading to figures 9, 10, 12, and 15.
Shuo Zhang is the other co-first author on the manuscript.
He edited the manuscript, provided biological expertise useful in selecting latent variables and gene sets, and ran the analyses leading to figures 11, 13, and 14.
Wayne Mao provided guidance for training PLIER in a large dataset.
Casey S. Greene gave feedback and guidance on the experiments run, and is a co-corresponding author on the manuscript.
Elizabeth A. Heller edited the manuscript, gave feedback and guidance on the experiments run, and helped interpret enriched genes in MousiPLIER latent variables.</p>
<h2 class="page_break_before" id="abstract-3">Abstract</h2>
<p>Differential expression analysis is widely used to learn from gene expression data.
However, it suffers from the curse of dimensionality — RNA-sequencing experiments tends to have tens of thousands of genes with only tens or hundreds of samples.
Many unsupervised learning models are designed to reduce dimensionality, and the PLIER model in particular fits expression data well.
In this paper we describe the training of the Mouse MultiPLIER (MousiPLIER) model, the first PLIER model trained on a mouse compendium and the PLIER model with the most training samples.
We then go on to show that the model’s latent variables contain biologically relevant information by finding enrichment for a striatally-associated latent variable in a mouse brain aging study and using the latent variable to uncover studies in the training data corresponding to mouse brain processes.
This new model can assist mouse researchers in understanding the biological processes involved in their study and finding other studies in which these processes are relevant.</p>
<h2 id="introduction-4">Introduction</h2>
<p>A common way to gain knowledge from gene expression is by examining which genes are differentially expressed in an experiment <span class="citation" data-cites="1APo3Hcx8 yk8zQJz3 qordNoBb LqrX5gU9">[<a href="#ref-1APo3Hcx8" role="doc-biblioref">143</a>,<a href="#ref-yk8zQJz3" role="doc-biblioref">144</a>,<a href="#ref-qordNoBb" role="doc-biblioref">145</a>,<a href="#ref-LqrX5gU9" role="doc-biblioref">146</a>]</span>.
For example, one can find which genes’ expression values change in mouse tissue samples before and after some biological perturbation.
This approach can be challenging, however, as studies analyzing gene expression tend to have few samples compared to the number of genes.
The resulting lack of statistical power can be addressed by increasing the number of samples in an experiment, which is expensive.
Alternatively, one can reduce the dimensionality or use information from outside the study.</p>
<p>Unsupervised learning does both.
It is a category of methods from the field of machine learning that learn the structure of data without need for any biological labels denoting which experimental conditions are present.
Such methods are well-suited for gene expression data, and are often used for tasks such as reducing the dimensionality of expression datasets <span class="citation" data-cites="EBwnauin 1D2hpyeIm piytFx3h">[<a href="#ref-EBwnauin" role="doc-biblioref">147</a>,<a href="#ref-1D2hpyeIm" role="doc-biblioref">148</a>,<a href="#ref-piytFx3h" role="doc-biblioref">149</a>]</span>, clustering samples <span class="citation" data-cites="113fm3uP2 IRSA7yBm">[<a href="#ref-IRSA7yBm" role="doc-biblioref">20</a>,<a href="#ref-113fm3uP2" role="doc-biblioref">150</a>]</span>, or learning shared expression patterns across experiments <span class="citation" data-cites="1CFhfCyWN 19eIjTcxN">[<a href="#ref-19eIjTcxN" role="doc-biblioref">18</a>,<a href="#ref-1CFhfCyWN" role="doc-biblioref">120</a>]</span>.
That being said, while unsupervised models are capable of using large amounts of unlabeled expression data, many of them don’t explicitly encode prior biological knowledge to encourage the model to learn biological patterns over technical ones.</p>
<p>The Pathway-level information extractor (PLIER) models do <span class="citation" data-cites="Ki2ij7zE">[<a href="#ref-Ki2ij7zE" role="doc-biblioref">43</a>]</span>.
They are built explicitly to work on expression data, and use matrix factorization to incorporate prior knowledge in the form of sets of genes specified by the user corresponding to biological pathways or cell type markers.
PLIER models also capable of learning diverse biological pathways from entire compendia of expression data and transferring that knowledge to smaller studies as seen in MultiPLIER <span class="citation" data-cites="14rnBunuZ">[<a href="#ref-14rnBunuZ" role="doc-biblioref">44</a>]</span>.
However, PLIER models are largely trained on a single dataset rather than a compendium <span class="citation" data-cites="ZRb1Hqb2 miWUn1Ks WZxHGrSb">[<a href="#ref-ZRb1Hqb2" role="doc-biblioref">151</a>,<a href="#ref-miWUn1Ks" role="doc-biblioref">152</a>,<a href="#ref-WZxHGrSb" role="doc-biblioref">153</a>]</span>, and past MultiPLIER runs have only trained models with up to tens of thousands of samples <span class="citation" data-cites="wv3oXzet 14rnBunuZ">[<a href="#ref-14rnBunuZ" role="doc-biblioref">44</a>,<a href="#ref-wv3oXzet" role="doc-biblioref">154</a>]</span>.</p>
<p>In this paper we train a PLIER model on a compendium of mouse gene expression to convert the data into a series of values called “latent variables” that correspond to potentially biologically relevant combinations of genes.
In doing so we train the largest (in terms of training data) PLIER model to date and the first one trained on a mouse compendium.
We have named this model MousiPLIER, short for Mouse MultiPLIER.
We demonstrate that not only is training such a model possible, it also surfaces interesting biology in a study of mouse brain aging.
When looking at a novel view of the resulting data (k-means clusters in the latent variable space), we find that the microglia-associated latent variables from our study of interest also correspond to aging-related changes in the training data.
Finally, we build a web server to allow others to visualize the results and find patterns in the data based on their own latent variables of interest.
Going forward, this model and its associated web server will be a useful tool for better understanding mouse gene expression.</p>
<h2 id="results-2">Results</h2>
<h3 id="mousiplier-learns-latent-variables-with-ideal-pathway-level-and-gene-level-sparsity">MousiPLIER learns latent variables with ideal pathway level and gene-level sparsity</h3>
<p>To determine the utility of a mouse multiPLIER model, we first trained the model.
We then examined the latent variables that our model learned and found which were significantly enriched in a mouse brain aging study.
Next, we looked deeper into the significant wild-type microglia-associated latent variables and determined that they were learning striatal signals potentially relevant to aging.
Ultimately, we found that our trained PLIER model is able to uncover relevant signal in individual studies, and will be useful going forward in uncovering the biological processes present in mouse transcriptomic experiments.
Taken together this study provides proof of concept that the mouse PLIER model can surface meaningful biological processes in mouse transcriptomic studies.</p>
<p>We trained MousiPLIER by using an on-disk PCA implementation to initialize PLIER, modifying the pipeline to work with mouse data, and using a high-mem compute node to manage the size of the matrix decomposition (see Methods for more details).
The resulting model had 196 latent variables, where the per-latent variable distribution had an average of around 65% sparsity, which is to say that the latent variables tended to use only around 35% of the genes in the training data (Fig. <a href="#fig:genesparsity">9</a>).
While many of the latent variables corresponded to no pathways, indicating signals in the training data not passed in as prior knowledge, those that remained corresponded to few pathways (Fig. <a href="#fig:pathwaysparsity">10</a>).
This pathway-level and gene-level sparsity is ideal, as it allows us to interrogate individual latent variables that correspond to a small number of biological functions.</p>
<div id="fig:genesparsity" class="fignos">
<figure>
<img src="./images/filtered_percent_genes_used_hist.png" style="width:75.0%" alt="Figure 9: The distribution of the percentage of genes from the training set which had nonzero loadings for the latent variable." />
<figcaption aria-hidden="true"><span>Figure 9:</span> The distribution of the percentage of genes from the training set which had nonzero loadings for the latent variable.</figcaption>
</figure>
</div>
<div id="fig:pathwaysparsity" class="fignos">
<figure>
<img src="./images/filtered_lv_per_pathway_hist.png" style="width:75.0%" alt="Figure 10: The distribution of the number of prior knowledge gene sets used per latent variable." />
<figcaption aria-hidden="true"><span>Figure 10:</span> The distribution of the number of prior knowledge gene sets used per latent variable.</figcaption>
</figure>
</div>
<h3 id="some-latent-variables-in-mousiplier-are-enriched-in-wild-type-microglia">Some latent variables in MousiPLIER are enriched in wild-type microglia</h3>
<p>With our model trained, we began interrogating our latent variables.
Because we were interested in brain-relevant latent variables that our model had learned from the compendium, we analyzed a study on mouse brain aging from Pan et al. <span class="citation" data-cites="k4efvKTD">[<a href="#ref-k4efvKTD" role="doc-biblioref">155</a>]</span>.
In this study, microglia and astrocytes from five ages of mice were sequenced to see how their gene expression changed over time.
To determine which (if any) latent variables were changed across developmental aging in the study, we used a linear model to find the latent variables that changed significantly as the cells aged.
We found that each condition in the study had a set of significant latent variables, but that they were largely disjoint (Fig. <a href="#fig:venn">11</a>).
To narrow down the scope of the analysis, we decided to validate the biological relevance of the latent variables associated with wild-type microglial cells.</p>
<div id="fig:venn" class="fignos">
<figure>
<img src="./images/dif_LV_venn.png" style="width:100.0%" alt="Figure 11: The overlap in significantly enriched latent variables across types and experimental conditions." />
<figcaption aria-hidden="true"><span>Figure 11:</span> The overlap in significantly enriched latent variables across types and experimental conditions.</figcaption>
</figure>
</div>
<h3 id="latent-variable-41-demonstrates-the-biological-relevance-of-mousiplier-latent-variables">Latent variable 41 demonstrates the biological relevance of mousiplier latent variables</h3>
<p>Once we had microglia-associated latent variables of interest, we set out to find which experiments in the training data responded strongly to them.
To do so, we developed a novel method of ranking experiments based on their latent variable weights.
More precisely, we performed <em>k</em>-means clustering with a <em>k</em> of two on each experiment in each latent variable space, and ranked experiments by their silhouette scores.
This procedure allowed us to uncover experiments where there were two groups of samples with distinct sets of values for our latent variables of interest.</p>
<p>We focused this approach on latent variable 41, which contains genes functionally associated with striatal cell type specificity.
Upon examining the top ranked studies, we found that several with high silhouette scores for latent variable 41 corresponded to processes ocurring in the brain (Fig. <a href="#fig:clusters">12</a>).
We dug deeper into which samples in particular were present in each clustered experiment and found our latent variable was in fact reflecting a biological process ocurring in the striatum and cortex but not the cerebellum or non-brain tissues (Fig. <a href="#fig:brain">13</a>).
For example, in study SRP070440 (https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE76872) the striatal samples clearly stand apart from the other neuronal tissues.
Similarly, we found that the two distinct groups in SRP047452 <span class="citation" data-cites="Cl90EtTf">[<a href="#ref-Cl90EtTf" role="doc-biblioref">156</a>]</span> were made up of brain samples from embryonic and adult mice, supporting the association between latent variable 41 and aging we found in the study we used to derive the latent variables (Fig. <a href="#fig:aging">14</a>).</p>
<div id="fig:clusters" class="fignos">
<figure>
<img src="./images/lv_41_studies.svg" style="width:100.0%" alt="Figure 12: Latent variable 41 expression values are higher for striatum tissue samples than other tissues in SRP070440." />
<figcaption aria-hidden="true"><span>Figure 12:</span> Latent variable 41 expression values are higher for striatum tissue samples than other tissues in SRP070440.</figcaption>
</figure>
</div>
<div id="fig:brain" class="fignos">
<figure>
<img src="./images/brain_samples.png" style="width:100.0%" alt="Figure 13: Striatal values for latent variable 41 compared to other tissues and brain regions." />
<figcaption aria-hidden="true"><span>Figure 13:</span> Striatal values for latent variable 41 compared to other tissues and brain regions.</figcaption>
</figure>
</div>
<div id="fig:aging" class="fignos">
<figure>
<img src="./images/aging_samples.png" style="width:100.0%" alt="Figure 14: The effects of aging on latent variable 41." />
<figcaption aria-hidden="true"><span>Figure 14:</span> The effects of aging on latent variable 41.</figcaption>
</figure>
</div>
<p>To allow others to look at the learned latent variables on their own, we have set up a web server at https://www.mousiplier.greenelab.com.
This server allows users to list the genes present in, visualize which experiments had high cluster scores for, and see which biological pathways participate in each latent variable (Fig. <a href="#fig:webserver">15</a>).</p>
<div id="fig:webserver" class="fignos">
<figure>
<img src="./images/webserver.png" style="width:100.0%" alt="Figure 15: An image of the webserver displaying the per-latent variable experiment ranking feature." />
<figcaption aria-hidden="true"><span>Figure 15:</span> An image of the webserver displaying the per-latent variable experiment ranking feature.</figcaption>
</figure>
</div>
<h2 id="methods-2">Methods</h2>
<h3 id="data-1">Data</h3>
<p>We began by downloading all the mouse gene expression data in Recount3, along with its corresponding metadata <span class="citation" data-cites="xdJRSgce">[<a href="#ref-xdJRSgce" role="doc-biblioref">126</a>]</span>.
We then removed the single-cell RNAseq data from the dataset to ensure our data sources were fairly consistent across samples and studies.
Next, we filtered the expression data, keeping only genes that overlapped between Recount3 and our prior-knowledge genesets.
Finally, we RPKM transformed the expression using gene lengths from the Ensembl BioMart database <span class="citation" data-cites="sckOePLr">[<a href="#ref-sckOePLr" role="doc-biblioref">157</a>]</span> and Z-scored the expression data to ensure a consistent range for the downstream PLIER model.</p>
<p>For our prior knowledge gene sets we used cell type marker genes from CellMarker <span class="citation" data-cites="9nz7bPGH">[<a href="#ref-9nz7bPGH" role="doc-biblioref">158</a>]</span>, pathway gene sets from Reactome <span class="citation" data-cites="Gout7oWo">[<a href="#ref-Gout7oWo" role="doc-biblioref">159</a>]</span>, and manually curated brain marker genes.
We selected cell type marker genes corresponding to all available mouse cell types within the CellMarker database.
For mouse biological pathways, we downloaded pathway information from the Reactome database.
More specifically, we processed the files “Ensembl2Reactome_All_Levels.txt”, “ReactomePathways.txt”, and “ReactomePathwaysRelation.txt”, selecting only pathways using mouse genes, filtering out all pathways with fewer than 5 genes present, and keeping only pathways that were leaf nodes on the pathway hierarchy.
Because we were interested in mouse brains in particular, we rounded out our set of prior information by manually selecting marker genes for the striatum, midbrain, and cerebellum.
In total, we used 1,003 prior knowledge pathways when training our model.</p>
<h3 id="plier">PLIER</h3>
<p>We began the PLIER pipeline by precomputing the initialization for PLIER with incremental PCA in scikit-learn <span class="citation" data-cites="y5jlswEM">[<a href="#ref-y5jlswEM" role="doc-biblioref">160</a>]</span>.
We then used the expression compendium, prior knowledge genesets, and PCA initializations to train a PLIER model.
The resulting task took two days to run and yielded 196 latent variables.</p>
<h3 id="latent-variable-significance">Latent variable significance</h3>
<p>To determine which latent variables were associated with experimental conditions, we used a linear model.
To correct the p-values for multiple testing, we used the Benjamani-Hochberg procedure <span class="citation" data-cites="UeFCwwR7">[<a href="#ref-UeFCwwR7" role="doc-biblioref">161</a>]</span>.</p>
<h3 id="clustering">Clustering</h3>
<p>We selected the latent variables significantly associated with aging in mouse microglia as a biological starting point.
We then used these latent variables to query the training data and see which studies seemed associated with the same biological signals.
To do so, we used <em>k</em>-means clustering with a <em>k</em> of 2, to look for experiments where there was some experimental condition that affected the latent variable.
We then ranked the top ten studies based on their silhouette scores, and looked to see which conditions were associated with relevant experimental variables.</p>
<h3 id="hardware">Hardware</h3>
<p>The PLIER model training was performed on the Penn Medicine high performance computing cluster.
The full pipeline takes around two weeks to run, with the main bottlenecks being the Recount3 data download, which takes one week to run, and training the PLIER model, which takes two days on a compute node with 250GB of RAM.</p>
<h3 id="web-server">Web Server</h3>
<p>The web server for visualizing the results was built on top of the ADAGE web app framework <span class="citation" data-cites="DngmXnbP">[<a href="#ref-DngmXnbP" role="doc-biblioref">162</a>]</span>.
The main changes we made were to substitute the latent variables and gene sets from our trained PLIER model, to use clusters’ silhouette scores for ranking experiments, and to forgo uploading the input expression data as the mouse compendium we used was much larger than the input expression for ADAGE.</p>
<h2 id="discussionconclusion">Discussion/Conclusion</h2>
<p>In this paper we demonstrate that it is possible to train large PLIER models on mouse data.
We then show that the learned latent variables map to various biological processes and cell types.
We also describe a novel approach for surfacing latent-variable relevant experiments from an expression compendium.
Namely, we cluster them based on latent variable values, allowing us to query a large compendium for experiments pertaining to mouse striatal aging.
Finally, we create a web server to make the model’s results more easily accessible to other scientists.</p>
<p>Our study is not without its limitations though.
We show how a study from outside the training data can be transformed into the latent space to see which of the learned latent variables have significant differences in the study.
However, not all studies will have significant changes in latent variables between their experimental conditions.
This may be due to lack of similar samples in training compendium, too few samples in the study of interest, or other factors.
In these cases, there isn’t a good way to select which latent variables should be used for downstream analyses.</p>
<p>Additionally, PLIER is a linear model.
If there are non-linear relationships between the genes used to train the model and the learned biological pathways, at best PLIER can approximate them.
While we do not expect this to have a large impact <span class="citation" data-cites="rKnVyOXF">[<a href="#ref-rKnVyOXF" role="doc-biblioref">163</a>]</span>, incorporating prior knowledge into non-linear models such as neural networks is an exciting field of research and a potential improvement for the MultiPLIER framework we use.</p>
<p>Going forward, our model and web server will allow scientists to explore the latent space of their own experiments and learn about relevant biological pathways and cell types.</p>
<h3 id="code-and-data-availability-1">Code and Data Availability</h3>
<p>The code, and model weights to reproduce this work can be found at https://github.com/greenelab/mousiplier.
The data used in our analyses is publicly available and can be downloaded with the code above or is already stored in the repository.
Our work meets the bronze standard of reproducibility <span class="citation" data-cites="PETW01rJ">[<a href="#ref-PETW01rJ" role="doc-biblioref">142</a>]</span>.</p>
<h3 id="acknowledgements-3">Acknowledgements</h3>
<p>We would like to thank Jake Crawford for reviewinging code that went into this project.
We would also like to thank Faisal Alquaddoomi and Vincent Rubinetti for their assistance in developing the web server accompanying this project.
This work utilized resources from the the University of Pennsylvania PMACS/DART computer cluster funded by NIH grant 1S10OD012312.</p>
<h4 id="funding-1">Funding</h4>
<p>This work was supported by grants from the National Institutes of Health’s National Human Genome Research Institute (NHGRI) under award R01 HG010067 and the Gordon and Betty Moore Foundation (GBMF 4552) to CSG.
The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
<h1 id="chapter-5---the-field-dependent-nature-of-pagerank-values-in-citation-networks">Chapter 5 - The Field-Dependent Nature of PageRank Values in Citation Networks</h1>
<p><strong>Contributions:</strong><br />
I ran the experiments, generated the figures, and wrote the manuscript for this chapter.
Casey S. Greene gave advice and feedback, helped design experiments, and edited the manuscript.</p>
<h2 class="page_break_before" id="abstract-4">Abstract</h2>
<p>There are more academic papers than any human can read in a lifetime, so several article-level and journal-level metrics have been devised to rank papers.
One challenge when creating such metrics is the differences in citation practices between fields.
To account for these differences, scientists have devised normalization schemes to make metrics more comparable across fields.
In this paper, we argue that these normalization schemes obscure useful signals about fields’ preferences for articles.
We use PageRank as an example metric and begin by demonstrating that there are, in fact, differences in journals’ PageRanks between fields.
We then show that even papers shared between fields have different PageRanks depending on which field’s citation network the metric is calculated in.
Finally, we find that some of these differences are caused by field-specific preferences by using a degree-preserving graph shuffling algorithm to generate a null distribution of similar networks.
Our results demonstrate that while differences exist between fields’ metric distributions, applying metrics in a field-aware manner rather than using normalized global metrics avoids losing important information about article preferences.</p>
<h2 id="introduction-5">Introduction</h2>
<p>There are more academic papers than any human can read in a lifetime.
Attention has been given to ranking papers, journals, or researchers by their “importance,” assessed via various metrics.
Citation count assumes the number of citations determines a paper’s importance.
The h-index and Journal Impact Factor focus on secondary factors like author or journal track records.
Graph-based methods like PageRank or disruption index use the context of the citing papers to evaluate an article’s relevance <span class="citation" data-cites="qXsETMbA 16V0td5f2 zeuTsDVX UTLLCTKy">[<a href="#ref-qXsETMbA" role="doc-biblioref">71</a>,<a href="#ref-16V0td5f2" role="doc-biblioref">75</a>,<a href="#ref-zeuTsDVX" role="doc-biblioref">78</a>,<a href="#ref-UTLLCTKy" role="doc-biblioref">80</a>]</span>.
Each of these methods has its strengths, and permutations exist that attempt to shore up specific weaknesses <span class="citation" data-cites="kZI40ZXS 11IkPxdIL 12CYfIcWF PGRGcmLi">[<a href="#ref-PGRGcmLi" role="doc-biblioref">81</a>,<a href="#ref-kZI40ZXS" role="doc-biblioref">84</a>,<a href="#ref-11IkPxdIL" role="doc-biblioref">85</a>,<a href="#ref-12CYfIcWF" role="doc-biblioref">86</a>]</span>.</p>
<p>One objection to such practices is that “importance” is subjective.
The San Francisco Declaration on Research Assessment (DORA) argues against using Journal Impact Factor, or any journal-based metric, to assess individual manuscripts or scientists <span class="citation" data-cites="62Q1rmv4">[<a href="#ref-62Q1rmv4" role="doc-biblioref">164</a>]</span>.
DORA further argues in favor of evaluating the scientific content of articles and notes that any metrics used should be article-level (https://sfdora.org/read/).
However, even article-level metrics often ignore that the importance of a specific scientific output will fundamentally differ across fields.
Even Nobel prize-winning work may be unimportant to a cancer biologist if the prize-winning article is about astrophysics.</p>
<p>Because there are differences between fields’ citation practices <span class="citation" data-cites="Hw4ZDEnz">[<a href="#ref-Hw4ZDEnz" role="doc-biblioref">165</a>]</span>, scientists have developed strategies including normalizing the number of citations based on nearby papers in a citation network, rescaling fields’ citation data to give more consistent PageRank results, and so on <span class="citation" data-cites="kZI40ZXS 7n76ZZPt 3FJspt0W 15JxaxOiR">[<a href="#ref-kZI40ZXS" role="doc-biblioref">84</a>,<a href="#ref-7n76ZZPt" role="doc-biblioref">166</a>,<a href="#ref-3FJspt0W" role="doc-biblioref">167</a>,<a href="#ref-15JxaxOiR" role="doc-biblioref">168</a>]</span>.
Such approaches normalize away field-specific effects, which might help to compare one researcher with another in a very different field.
However, they do not address the difference in the relevance of a topic between fields.
This phenomenon of field-specific importance has been observed at the level of journal metrics.
Mason and Singh recently noted that depending on the field, the journal <em>Christian Higher Education</em> is either ranked as a Q1 (top quartile) journal or a Q4 (bottom quartile) journal <span class="citation" data-cites="AkQLg7kt">[<a href="#ref-AkQLg7kt" role="doc-biblioref">169</a>]</span>.</p>
<p>It is possible that, while global journal-level metrics fail to capture field-specific importance, article-level metrics are sufficiently granular that the importance of a manuscript remains constant across fields.
We investigate the extent to which article-level metrics generalize between fields.
We examine this using MeSH terms to define fields and use field-specific citation graphs to assess their importance within the field.
While it is trivially apparent that journals or articles that do not have cross-field citations will have variable importance, we ignore these cases and include only those with citations in both fields, where we expect possible consistency.
We first replicate previous findings that journal-level metrics can differ substantially among fields.
We also find field-specific variability in importance at the article level.
We make our results explorable through a web app that shows metrics for overlapping papers between pairs of fields.</p>
<p>Our results show that even article-level metrics can differ substantially among fields.
We recommend that metrics used for assessing research outputs include field-specific, in addition to global, ones.
While qualitative assessment of the content of manuscripts remains time-consuming, our results suggest that within-field and across-field assessment remains key to assessing the importance of research outputs.</p>
<h2 id="results-3">Results</h2>
<h3 id="journal-rankings-differ-between-fields">Journal rankings differ between fields</h3>
<p>In an attempt to quantify the relative importance of journals, scientists have created rankings using metrics the Journal Impact Factor, which is essentially based on citations per article, and those that rely on more complex representations like Eigenfactor <span class="citation" data-cites="4TkOo7Oy">[<a href="#ref-4TkOo7Oy" role="doc-biblioref">76</a>]</span>.
It has previously been reported that journal rankings differ substantially between fields using metrics based on citation numbers <span class="citation" data-cites="AkQLg7kt">[<a href="#ref-AkQLg7kt" role="doc-biblioref">169</a>]</span>.
We calculated a PageRank-based score for the journal as the median PageRank of manuscripts published in that journal for that field (Fig. <a href="#fig:journal">16</a> A).
We first sought to understand the extent to which journal ranking differences replicated using PageRank.</p>
<p>To begin, we compared the differences in ranking between the top fifty journals in nanotechnology and their corresponding ranks in microscopy.
While the ranks were somewhat correlated there was a great deal of variance, especially for journals outside the top 20 in nanotechnology (Fig. <a href="#fig:journal">16</a> B).
We then made use of the scale of the data by examining the top ranked journal in each of our 45 fields to determine whether the top ranking journal would be consistent across fields (Fig. <a href="#fig:journal">16</a> C).
We found that the most common top-ranked journal was <em>Science</em>.
This was unsurprising, given that it tends to rank highly among global journal level metrics such as eigenfactor.
However, the ranking was very field-dependent, with only 20% of fields having <em>Science</em> as their top ranked journal.</p>
<p>One could argue that while general journals may have differing influence by field, specialty journals correspond to a single field so field-aware metrics are irrelevant.
That turns out to be untrue.
Of the 5,178 journals with at least 50 articles present in our dataset, the median number of fields publishing in a given journal is 15 (Fig. <a href="#fig:journal">16</a> D).
This result confirms that while useful <span class="citation" data-cites="17UkkRswc">[<a href="#ref-17UkkRswc" role="doc-biblioref">170</a>]</span>, MeSH headings reflect a different type of aggregation than journals do <span class="citation" data-cites="ErD8Jjn8">[<a href="#ref-ErD8Jjn8" role="doc-biblioref">171</a>]</span>.</p>
<div id="fig:journal" class="fignos">
<figure>
<img src="./images/journal_fig.png" style="width:100.0%" alt="Figure 16: Journals’ PageRank derived rankings differ between fields. A) A schematic showing how paired networks are derived from the full citation network. B) A comparison of the ranks of the top 50 journals by PageRank in nanotechnology and their rank in microscopy. Top-50 nanotechnology journals with no papers in microscopy have been omitted. C) The frequency with which journals in the dataset are the top journal for a field. D) The distribution of fields published per journal. The X-axis corresponds to the number of fields for which a journal has at least one paper within the field. All plots restrict the set of journals to those with at least 50 papers in the dataset." />
<figcaption aria-hidden="true"><span>Figure 16:</span> Journals’ PageRank derived rankings differ between fields.
A) A schematic showing how paired networks are derived from the full citation network.
B) A comparison of the ranks of the top 50 journals by PageRank in nanotechnology and their rank in microscopy.
Top-50 nanotechnology journals with no papers in microscopy have been omitted.
C) The frequency with which journals in the dataset are the top journal for a field.
D) The distribution of fields published per journal.
The X-axis corresponds to the number of fields for which a journal has at least one paper within the field.
All plots restrict the set of journals to those with at least 50 papers in the dataset.</figcaption>
</figure>
</div>
<h3 id="manuscript-pageranks-differ-between-fields">Manuscript PageRanks differ between fields</h3>
<p>We split the citation network into its component fields and calculated the PageRank for each article (Fig. <a href="#fig:distribution">17</a> A).
We then examined the distribution of PageRanks across fields and found that they differed greatly (Fig. <a href="#fig:distribution">17</a> B).
These differences were driven by the size and citation practices of the fields themselves, as the papers shared by pairs of fields had distributions matching the field context they were in (Fig. <a href="#fig:distribution">17</a> B, C).
Given the differences in distributions in articles shared by these fields (Fig. <a href="#fig:distribution">17</a> D), we found it difficult to determine whether correspondance between fields was random or due to different degrees of interest in certain articles (Fig. <a href="#fig:distribution">17</a> E).</p>
<div id="fig:distribution" class="fignos">
<figure>
<img src="./images/distribution_fig.png" style="width:100.0%" alt="Figure 17: Differences in the distribution of PageRanks between fields. A) A schematic showing how field pairs are split and their PageRanks are calculated. B) The distribution of article PageRanks for nanotechnology and microscopy. The distributions marked with ‘All’ contain all the papers for the given field in the dataset, while those marked ‘overlapping’ contain only articles present in both fields. C) The empirical cumulative density functions of nanotechnology and microscopy. D) The differences in distribution of the PageRanks of articles shared by nanotechnology and microscopy. E) A density plot showing the joint distribution of PageRanks for papers overlapping in nanotechnology and microscopy." />
<figcaption aria-hidden="true"><span>Figure 17:</span> Differences in the distribution of PageRanks between fields.
A) A schematic showing how field pairs are split and their PageRanks are calculated.
B) The distribution of article PageRanks for nanotechnology and microscopy.
The distributions marked with ‘All’ contain all the papers for the given field in the dataset, while those marked ‘overlapping’ contain only articles present in both fields.
C) The empirical cumulative density functions of nanotechnology and microscopy.
D) The differences in distribution of the PageRanks of articles shared by nanotechnology and microscopy.
E) A density plot showing the joint distribution of PageRanks for papers overlapping in nanotechnology and microscopy.</figcaption>
</figure>
</div>
<h3 id="fields-differences-are-not-solely-driven-by-differences-in-citation-practices">Fields’ differences are not solely driven by differences in citation practices</h3>
<p>We devised a strategy to generate an empirical null for a field pair under the assumption that the field pair represented a single, homogenous field (Fig. <a href="#fig:percentile">18</a> A).
For each field-pair intersection, we performed a degree-distribution preserving permutation.
We created 100 permuted networks for each field pair.
We then split the networks into their constituent fields and calculated a percentile using the number of permuted networks with a lower PageRank for a manuscript than the true PageRank.
A manuscript with a PageRank higher than all networks has a percentile of 100, and one lower than all permuted networks has a percentile of zero.
We used the difference in the percentile in each field as the field-specific affinity for a given paper.
This percentile score allowed us to control for the differing degree distributions between fields by comparing papers based on their expected PageRank in a random network with the same node degrees.</p>
<p>We selected field pairs with varying degrees of correlation between their PageRanks (Fig. <a href="#fig:percentile">18</a> B).
By examining the fields’ PageRank percentiles, we found that many articles had large differences in their perception between fields (Fig. <a href="#fig:percentile">18</a> C).
In nanotechnology and microscopy, papers with high nanotechnology percentiles and low microscopy percentiles tended towards applications of nanotechnology, while their counterparts with high microscopy percentiles and low nanotechnology percentiles were often papers about technological developments in microscopy (Fig. <a href="#fig:percentile">18</a> A, Table 1).
Immunochemistry-favored papers are largely applications of immunochemical methods, while anatomy-favored articles tend to focus experiments on a single anatomical region (Fig. <a href="#fig:percentile">18</a> B, Table 2).
Proteomics and metabolomics tend to use similar methods, so the fields on either end are largely (though not entirely) field-specific applications of those methods (Fig. <a href="#fig:percentile">18</a> C, Table 3).
Computational biology is similarly applications-focused, though human genetics tends towards policy papers due to its MeSH heading (H01.158.273.343.385) excluding fields like genomics, population genetics, and microbial genetics (Fig. <a href="#fig:percentile">18</a> D, Table 4).
In addition to papers with large differences between fields, each field also has papers with high PageRanks and similar percentiles in both fields.
Overall it is clear that while some papers may be influential in multiple fields, others have more field-specific import.</p>
<p>It is not possible to describe all the field-pairs and relevant differences between fields within the space of a journal article.
Instead, we have developed a web server that displays the percentiles for all pairs of fields in our dataset with at least 1000 shared articles (Fig. <a href="#fig:percentile">18</a> D), which can be accessed at https://www.indices.greenelab.com.
We hope that the availability of the web server and the reproducibility of our code will assist other scientists in uncovering new insights from this dataset.</p>
<div id="fig:percentile" class="fignos">
<figure>
<img src="./images/percentile_figure.png" style="width:100.0%" alt="Figure 18: Field-specific preferences in papers. A) A schematic showing how networks are shuffled and how articles’ percentile scores are calculated. The histograms at the bottom of the figure correspond to the distribution of PageRanks for the shuffled networks, while the red lines correspond to an article’s PageRank in the true citation network. B) The Pearson correlation of PageRanks between fields. The red points are the field pairs expanded in panel C. C) The percentile scores and PageRanks for overlapping articles in various fields. Points are colored based on the difference in percentile scores in the fields e.g. “Nanotechnology-Microscopy” corresponds to the difference between the nanotechnology and microscopy percentile scores. The numbers next to points are the reference number for the article in the bibliography. D) A screenshot of the webserver showing the percentile score difference and journal median PageRank plot functionality." />
<figcaption aria-hidden="true"><span>Figure 18:</span> Field-specific preferences in papers.
A) A schematic showing how networks are shuffled and how articles’ percentile scores are calculated.
The histograms at the bottom of the figure correspond to the distribution of PageRanks for the shuffled networks, while the red lines correspond to an article’s PageRank in the true citation network.
B) The Pearson correlation of PageRanks between fields.
The red points are the field pairs expanded in panel C.
C) The percentile scores and PageRanks for overlapping articles in various fields.
Points are colored based on the difference in percentile scores in the fields e.g. “Nanotechnology-Microscopy” corresponds to the difference between the nanotechnology and microscopy percentile scores.
The numbers next to points are the reference number for the article in the bibliography.
D) A screenshot of the webserver showing the percentile score difference and journal median PageRank plot functionality.</figcaption>
</figure>
</div>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>Nanotechnology Percentile</th>
<th>Microscopy Percentile</th>
<th>Title</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100</td>
<td>4</td>
<td>A robust DNA mechanical device controlled by hybridization topology</td>
<td><span class="citation" data-cites="1GphepDNl">[<a href="#ref-1GphepDNl" role="doc-biblioref">172</a>]</span></td>
</tr>
<tr class="even">
<td>100</td>
<td>5</td>
<td>Bioadhesive poly(methyl methacrylate) microdevices for controlled drug delivery</td>
<td><span class="citation" data-cites="NmOwHa9H">[<a href="#ref-NmOwHa9H" role="doc-biblioref">173</a>]</span></td>
</tr>
<tr class="odd">
<td>99</td>
<td>2</td>
<td>DNA-templated self-assembly of protein arrays and highly conductive nanowrires</td>
<td><span class="citation" data-cites="IkV2K836">[<a href="#ref-IkV2K836" role="doc-biblioref">174</a>]</span></td>
</tr>
<tr class="even">
<td>0</td>
<td>100</td>
<td>Photostable luminescent nanoparticles as biological label for cell recognition of system lupus erythematosus patients</td>
<td><span class="citation" data-cites="19ryujP9j">[<a href="#ref-19ryujP9j" role="doc-biblioref">175</a>]</span></td>
</tr>
<tr class="odd">
<td>5</td>
<td>90</td>
<td>WSXM: a software for scanning probe microscopy and a tool for nanotechnology</td>
<td><span class="citation" data-cites="11usgA4JE">[<a href="#ref-11usgA4JE" role="doc-biblioref">176</a>]</span></td>
</tr>
<tr class="even">
<td>0</td>
<td>77</td>
<td>Measuring Distances in Supported Bilayers by Fluorescence Interference-Contrast Microscopy: Polymer Supports and SNARE Proteins</td>
<td><span class="citation" data-cites="JJ2LW0nT">[<a href="#ref-JJ2LW0nT" role="doc-biblioref">177</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>99</td>
<td>Toward fluorescence nanoscopy</td>
<td><span class="citation" data-cites="NkJaVLEB">[<a href="#ref-NkJaVLEB" role="doc-biblioref">178</a>]</span></td>
</tr>
<tr class="even">
<td>100</td>
<td>86</td>
<td>In vivo imaging of quantum dots encapsulated in phospholipid micelles</td>
<td><span class="citation" data-cites="18Ot4SCqv">[<a href="#ref-18Ot4SCqv" role="doc-biblioref">179</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>99</td>
<td>Water-Soluble Quantum Dots for Multiphoton Fluorescence Imaging in Vivo</td>
<td><span class="citation" data-cites="dYAYQycA">[<a href="#ref-dYAYQycA" role="doc-biblioref">180</a>]</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 1</strong>: Nanotechnology/microscopy papers of interest</p>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>Immunochemistry Percentile</th>
<th>Anatomy Percentile</th>
<th>Title</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>100</td>
<td>45</td>
<td>Immunoelectron microscopic exploration of the Golgi complex</td>
<td><span class="citation" data-cites="dqAv5O5b">[<a href="#ref-dqAv5O5b" role="doc-biblioref">181</a>]</span></td>
</tr>
<tr class="even">
<td>100</td>
<td>14</td>
<td>Immunocytochemical and electrophoretic analyses of changes in myosin gene expression in cat posterior temporalis muscle during postnatal development</td>
<td><span class="citation" data-cites="nMCUqTIP">[<a href="#ref-nMCUqTIP" role="doc-biblioref">182</a>]</span></td>
</tr>
<tr class="odd">
<td>98</td>
<td>5</td>
<td>Electron microscopic demonstration of calcitonin in human medullary carcinoma of thyroid by the immuno gold staining method</td>
<td><span class="citation" data-cites="1BGliKdI9">[<a href="#ref-1BGliKdI9" role="doc-biblioref">183</a>]</span></td>
</tr>
<tr class="even">
<td>12</td>
<td>100</td>
<td>Grafting genetically modified cells into the rat brain: characteristics of E. coli β-galactosidase as a reporter gene</td>
<td><span class="citation" data-cites="sc5wklkt">[<a href="#ref-sc5wklkt" role="doc-biblioref">184</a>]</span></td>
</tr>
<tr class="odd">
<td>12</td>
<td>100</td>
<td>Vitamin-D-dependent calcium-binding-protein and parvalbumin occur in bones and teeth</td>
<td><span class="citation" data-cites="TnowewWM">[<a href="#ref-TnowewWM" role="doc-biblioref">185</a>]</span></td>
</tr>
<tr class="even">
<td>3</td>
<td>100</td>
<td>Mapping of brain areas containing RNA homologous to cDNAs encoding the alpha and beta subunits of the rat GABAA gamma-aminobutyrate receptor</td>
<td><span class="citation" data-cites="CBI8FXe4">[<a href="#ref-CBI8FXe4" role="doc-biblioref">186</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>100</td>
<td>Studies of the HER-2/neu Proto-Oncogene in Human Breast and Ovarian Cancer</td>
<td><span class="citation" data-cites="4bdivZyz">[<a href="#ref-4bdivZyz" role="doc-biblioref">187</a>]</span></td>
</tr>
<tr class="even">
<td>100</td>
<td>100</td>
<td>Expression of c-fos Protein in Brain: Metabolic Mapping at the Cellular Level</td>
<td><span class="citation" data-cites="hLSwKASj">[<a href="#ref-hLSwKASj" role="doc-biblioref">188</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>100</td>
<td>Proliferating cell nuclear antigen (PCNA) immunolocalization in paraffin sections: An index of cell proliferation with evidence of deregulated expression in some neoplasms</td>
<td><span class="citation" data-cites="hLSwKASj">[<a href="#ref-hLSwKASj" role="doc-biblioref">188</a>]</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 2</strong>: Immunochemistry/anatomy papers of interest</p>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>Proteomics Percentile</th>
<th>Metabolomics Percentile</th>
<th>Title</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>67</td>
<td>2</td>
<td>Proteomics Standards Initiative: Fifteen Years of Progress and Future Work</td>
<td><span class="citation" data-cites="qVEHb5K">[<a href="#ref-qVEHb5K" role="doc-biblioref">189</a>]</span></td>
</tr>
<tr class="even">
<td>99</td>
<td>0</td>
<td>Limited Environmental Serine and Glycine Confer Brain Metastasis Sensitivity to PHGDH Inhibition</td>
<td><span class="citation" data-cites="MVZ9xwhJ">[<a href="#ref-MVZ9xwhJ" role="doc-biblioref">190</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>0</td>
<td>A high-throughput processing service for retention time alignment of complex proteomics and metabolomics LC-MS data</td>
<td><span class="citation" data-cites="197hbKiL0">[<a href="#ref-197hbKiL0" role="doc-biblioref">191</a> ]</span></td>
</tr>
<tr class="even">
<td>0</td>
<td>100</td>
<td>MeltDB: a software platform for the analysis and integration of metabolomics experiment data</td>
<td><span class="citation" data-cites="EvwvRYzE">[<a href="#ref-EvwvRYzE" role="doc-biblioref">192</a>]</span></td>
</tr>
<tr class="odd">
<td>0</td>
<td>98</td>
<td>In silico fragmentation for computer assisted identification of metabolite mass spectra</td>
<td><span class="citation" data-cites="vNOeEVfp">[<a href="#ref-vNOeEVfp" role="doc-biblioref">193</a>]</span></td>
</tr>
<tr class="even">
<td>0</td>
<td>100</td>
<td>The Metabonomic Signature of Celiac Disease</td>
<td><span class="citation" data-cites="UQbCNqUe">[<a href="#ref-UQbCNqUe" role="doc-biblioref">194</a>]</span></td>
</tr>
<tr class="odd">
<td>91</td>
<td>70</td>
<td>Visualization of omics data for systems biology</td>
<td><span class="citation" data-cites="vNOeEVfp">[<a href="#ref-vNOeEVfp" role="doc-biblioref">193</a>]</span></td>
</tr>
<tr class="even">
<td>0</td>
<td>16</td>
<td>FunRich: An open access standalone functional enrichment and interaction network analysis tool</td>
<td><span class="citation" data-cites="vJbGwiV7">[<a href="#ref-vJbGwiV7" role="doc-biblioref">195</a>]</span></td>
</tr>
<tr class="odd">
<td>0</td>
<td>5</td>
<td>Proteomic and Metabolomic Characterization of COVID-19 Patient Sera</td>
<td><span class="citation" data-cites="sc8DMTGM">[<a href="#ref-sc8DMTGM" role="doc-biblioref">196</a>]</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 3</strong>: Proteomics/metabolomics papers of interest</p>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
<col style="width: 25%" />
</colgroup>
<thead>
<tr class="header">
<th>Computational Biology Percentile</th>
<th>Human Genetics Percentile</th>
<th>Title</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>99</td>
<td>0</td>
<td>Development of Human Protein Reference Database as an Initial Platform for Approaching Systems Biology in Humans</td>
<td><span class="citation" data-cites="VvZTjIen">[<a href="#ref-VvZTjIen" role="doc-biblioref">197</a>]</span></td>
</tr>
<tr class="even">
<td>100</td>
<td>1</td>
<td>A database for post-genome analysis</td>
<td><span class="citation" data-cites="C4NTSwn4">[<a href="#ref-C4NTSwn4" role="doc-biblioref">198</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>1</td>
<td>Use of mass spectrometry-derived data to annotate nucleotide and protein sequence databases</td>
<td><span class="citation" data-cites="G2ZiZdRY">[<a href="#ref-G2ZiZdRY" role="doc-biblioref">199</a>]</span></td>
</tr>
<tr class="even">
<td>12</td>
<td>100</td>
<td>Genetic Discrimination: Perspectives of Consumers</td>
<td><span class="citation" data-cites="mcDRypJj">[<a href="#ref-mcDRypJj" role="doc-biblioref">200</a>]</span></td>
</tr>
<tr class="odd">
<td>0</td>
<td>81</td>
<td>Committee Opinion No. 690: Carrier Screening in the Age of Genomic Medicine</td>
<td><span class="citation" data-cites="aFgNUM13">[<a href="#ref-aFgNUM13" role="doc-biblioref">201</a>]</span></td>
</tr>
<tr class="even">
<td>23</td>
<td>100</td>
<td>Public health genomics: The end of the beginning</td>
<td><span class="citation" data-cites="Msb0hwgj">[<a href="#ref-Msb0hwgj" role="doc-biblioref">202</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>99</td>
<td>Initial sequencing and analysis of the human genome</td>
<td><span class="citation" data-cites="14yhCmDBZ">[<a href="#ref-14yhCmDBZ" role="doc-biblioref">1</a>]</span></td>
</tr>
<tr class="even">
<td>100</td>
<td>100</td>
<td>An STS-Based Map of the Human Genome</td>
<td><span class="citation" data-cites="7ZlRSgYT">[<a href="#ref-7ZlRSgYT" role="doc-biblioref">203</a>]</span></td>
</tr>
<tr class="odd">
<td>100</td>
<td>100</td>
<td>A New Five-Year Plan for the U.S. Human Genome Project</td>
<td><span class="citation" data-cites="153eZYSdV">[<a href="#ref-153eZYSdV" role="doc-biblioref">204</a>]</span></td>
</tr>
</tbody>
</table>
<p><strong>Table 4</strong>: Computational biology/human genetics papers of interest</p>
<h2 id="methods-3">Methods</h2>
<h4 id="coci">COCI</h4>
<p>We used the March 2022 version of the COCI citation index <span class="citation" data-cites="126JIm8me">[<a href="#ref-126JIm8me" role="doc-biblioref">88</a>]</span> as the source of our citation data.
This dataset contains around 1.3 billion citations from ~73 million bibliographic resources.</p>
<h4 id="selecting-fields">Selecting fields</h4>
<p>To differentiate between scientific fields, we needed a way to map papers to fields.
Fortunately, all the papers in Pubmed Central (https://www.ncbi.nlm.nih.gov/pmc/) have corresponding Medical Subject Headings (MeSH) terms.
While MeSH terms are varied and numerous, the subheadings of the Natural Science Disciplines (H01) category fit our needs.
However, MeSH terms are hierarchical, and vary greatly in their size and specificity.
To extract a balanced set of terms we recursively traversed the tree and selected headings that have least 10000 DOIs and don’t have multiple children that also meet the cutoff.
Our resulting set of headings contained 45 terms, from “Acoustics” to “Water Microbiology”.</p>
<h4 id="handling-citation-networks">Handling citation networks</h4>
<p>The COCI dataset consists of pairs of Digital Object Identifiers (DOIs).
To change these pairs into a form we could run calculations on, we needed to convert them into networks.
To do so, we created 45 empty networks, one for each MeSH term we selected previously.
We then iterated over each pair of DOIs in COCI, and added them to a network if the DOIs corresponded to two journal articles written in english, both of which were tagged with the corresponding MeSH heading.</p>
<p>Because we were interested in the differences between fields, we also needed to build networks from pairs of MeSH headings.
These networks were built via the same process, except that instead of keeping articles corresponding to a single DOI we added a citation to the network if both articles were in the pair of fields, even if the citation occurred across fields.
Running this network-building process yielded 990 two-heading networks.</p>
<p>Sampling a graph from the degree distribution while preserving the distribution of degrees in the network turned out to be challenging.
Because citation graphs are directed, it’s not possible to simply swap pairs of edges and end up with a graph that is uniformly sampled from the space.
Instead, a more sophisticated three-edge swap method must be used <span class="citation" data-cites="To1WoeSQ">[<a href="#ref-To1WoeSQ" role="doc-biblioref">205</a>]</span>.
Because this algorithm had not been implemented yet in NetworkX <span class="citation" data-cites="15wNo6JtP">[<a href="#ref-15wNo6JtP" role="doc-biblioref">206</a>]</span>, we wrote the code to perform shuffles and submitted our change to the library.
With the shuffling code implemented, we created 100 shuffled versions of each of our combined networks to act as a background distribution to compare metrics against.</p>
<p>Once we had a collection of shuffled networks, we needed to split them into their constituent fields.
To do so, we reduced the network to solely the nodes that were present in the single heading citation network, and kept only citations between these nodes.</p>
<h4 id="metrics">Metrics</h4>
<p>We used the NetworkX implementation of PageRank with default parameters to evaluate paper importance within fields.
To determine the degree to which the papers’ PageRank values were higher or lower than expected, we compared the PageRank values calculated for the true citation networks to the values in the shuffled networks for each paper.
We then recorded the fraction of shuffled networks where the paper had a lower PageRank than in the true network to derive a single number that described these values.
For example, if a paper had a higher PageRank in the true network than in all the shuffled networks it received a score of 1.
Likewise, if it had a lower PageRank in the true network than in all the shuffled networks it received a score of 0.
Papers in between the two extremes had fractional values, like .5 (a paper that fell in the middle of the pack) and so on.</p>
<p>A convenient feature of the percentile scores is that they’re directly comparable between fields.
If a paper is present in two fields, the difference in scores between the two fields can be used to estimate its relative importance.
For example, if a paper has a score of 1 in field A (indicating a higher PageRank in the field than expected given its number of citations and the network structure) and a score of 0 in field B (indicating a lower than expected PageRank), then the large difference in scores indicates the paper is more highly valued in field A than field B.
If the paper has similar scores in both fields, it indicates that the paper is similarly valued in the two fields.</p>
<h4 id="hardwareruntime">Hardware/runtime</h4>
<p>The analysis pipeline was run on the RMACC Summit cluster.
The full pipeline, from downloading the data to analyzing it to vizualizing it took about a week to run.
However, that number is heavily dependent on details such as the number of CPU nodes available and the network speed.</p>
<p>Our webserver is built by visualizing our data in Plotly (https://plotly.com/python/plotly-express/) on the Streamlit platform (https://streamlit.io/).
The field pairs made available by the frontend are those with at least 1000 shared papers after filtering out papers with more than a 5% missingness level of their PageRanks after shuffling.
The journals available for visualization are those with at least 25 papers for the given field pair.</p>
<h2 id="discussionconclusion-1">Discussion/Conclusion</h2>
<p>We analyze hundreds of field-pair citation networks to examine the extent to which article-level importance metrics vary between fields.
As previously reported, we find systematic differences in PageRanks between fields <span class="citation" data-cites="12CYfIcWF hJ4Xxryu">[<a href="#ref-12CYfIcWF" role="doc-biblioref">86</a>,<a href="#ref-hJ4Xxryu" role="doc-biblioref">207</a>]</span> that would warrant some form of normalization when making cross-field comparisons with global statistics.
However, we also find that field-specific differences are not driven solely by differences in citation practices.
Instead, the importance of individual papers appears to differ meaningfully between fields.
Global rankings or efforts to normalize out field-specific effects obscure meaningful differences in manuscript importance between communities.</p>
<p>As with any study, this research has certain limitations.
One example is our selection of MeSH terms to represent fields.
We used MeSH because it is a widely-annotated set of subjects in biomedicine and thresholded MeSH term sizes to balance having enough observations to calculate appropriate statistics with having sufficient granularity to capture fields.
This selection process resulted in fields at the granularity of “biophysics” and “ecology.”
We also have to select a number of swaps to generate a background distribution of PageRanks for each field pair.
We selected three times as many swaps as edges, where each swap modifies three edges, but certain network structures may require a different number.</p>
<p>We also note that there are inherent issues with the premise of ranking manuscripts’ importance.
We sought to understand the extent to which such rankings were stable between fields after correcting for field-specific citation practices.
We found limited stability between fields, mostly between closely-related fields, suggesting that the concept of a universal ranking of importance is difficult to justify.
In the way that reducing a distribution to a Journal Impact Factor distorts assessment, attempting to use a single universal score to represent importance across fields poses similar challenges at the level of individual manuscripts.
Furthermore, this work’s natural progression would extend to estimating the importance of individual manuscripts to individual researchers.
Thus, a holistic measure of importance would need to include a distribution of scores not only across fields but across researchers.
It may ultimately be impossible to calculate a meaningful importance score.
The lack of ground truth for importance is an inherent feature, not a bug, of science’s step-wide progression.</p>
<p>Shifting from the perspective of evaluation to discovery can reveal more appropriate uses for these types of statistics.
Field-pair calculations for such metrics may help with self-directed learning of new fields.
An expert in one field, e.g., computational biology, who aims to learn more about genetics may find manuscripts with high importance in genetics and low importance in computational biology to be important reads.
These represent manuscripts not currently widely cited in one’s field but highly influential in a target field.
Our application can reveal these manuscripts for MeSH field pairs, and our source code allows others to perform our analysis with different granularity.</p>
<h3 id="code-and-data-availability-2">Code and Data Availability</h3>
<p>The code to reproduce this work can be found at https://github.com/greenelab/indices.
The data used for this project is publicly available and can be downloaded with the code provided above.
Our work meets the bronze standard of reproducibility <span class="citation" data-cites="PETW01rJ">[<a href="#ref-PETW01rJ" role="doc-biblioref">142</a>]</span> and fulfills aspects of the silver and gold standards including deterministic operation.</p>
<h3 id="acknowledgements-4">Acknowledgements</h3>
<p>We would like to thank Jake Crawford for reviewing code that went into this project and Faisal Alquaddoomi for figuring out the web server hosting.
We would also like to thank the past and present members of GreeneLab who gave feedback on this project during lab meetings.
This work utilized resources from the University of Colorado Boulder Research Computing Group, which is supported by the National Science Foundation (awards ACI-1532235 and ACI-1532236).</p>
<h4 id="funding-2">Funding</h4>
<p>This work was supported by grants from the National Institutes of Health’s National Human Genome Research Institute (NHGRI) under award R01 HG010067 and the Gordon and Betty Moore Foundation (GBMF 4552) to CSG.
The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
<h1 id="chapter-6---future-directions">Chapter 6 - Future Directions</h1>
<p><strong>Contributions:</strong>
I wrote and edited this chapter for the purpose of being included in this dissertation.</p>
<h2 id="introduction-6">Introduction</h2>
<p>In this dissertation, we have examined whether deep learning has led to a paradigm shift in computational biology.
We established standards for reproducible research when using deep learning models in chapter 2, showed that deep learning is not always preferable to other techniques in chapter 3, then demonstrated the effectiveness of classical ml methods in chapters 4 and 5.
Ultimately we concluded that while deep learning has been a useful tool in some areas, it has yet to lead to a paradigm shift in computational biology.
However, deep learning models’ impact may grow as the fields develop, so we would like to discuss future areas where we expect interesting developments.</p>
<h2 id="deep-learning-representations-of-biology">Deep learning representations of biology</h2>
<p>Different areas of computational biology research have seen different effects from deep learning.
Deep learning has already had a significant impact on biomedical imaging <span class="citation" data-cites="o78W9pGh">[<a href="#ref-o78W9pGh" role="doc-biblioref">208</a>]</span>, and seems poised to do so in protein structure <span class="citation" data-cites="yZfcMIwh">[<a href="#ref-yZfcMIwh" role="doc-biblioref">11</a>]</span>.
These advances were likely successful because of their similarity to well-researched fields in that they can be framed as similar problems.
Biomedical images are not the same as those from a standard camera, but the inductive bias of translational equivariance and various image augmentation methods are still applicable.
Similarly, while protein sequences may not seem to share much with written language, models like RNNs and transformers that look at their input as a sequence of tokens do not care whether those tokens are words or amino acids.</p>
<p>Not all subfields of computational biology have convenient ways to represent their data, though.
Gene expression, in particular, is difficult because of its high dimensionality.
Expression data does not have spatial locality to take advantage of, so convolutional networks cannot be used to ignore it.
It is not a series of tokens either; the genes in an expression dataset are listed lexicographically, so their order does not have meaning.
Self-attention seems well-suited for gene expression since learning which subsets of genes interact with others would be useful.
The high dimensionality makes vanilla self-attention infeasible though, due to the quadratic scaling.
This issue cannot even be sidestepped with standard dimensionality reduction methods without losing predictive performance.</p>
<p>Do any deep learning representations work for gene expression, then?
Fully-connected networks work, though they do not tend to be the best way to accomplish most tasks.
An interesting potential research direction would be to apply sparse self-attention methods to gene expression data and reduce the number of comparisons made by only attending within prior knowledge gene sets.
Alternatively, because expression is often thought of in terms of coregulation networks or sets of genes with shared functions, a graph representation may be more suitable.
It is also possible that someone will develop a representation specifically for gene expression that will work better than anything we know about today.</p>
<h2 id="to-what-extent-is-biology-limited-by-challenges-in-looking-at-the-data">To what extent is biology limited by challenges in looking at the data</h2>
<p>An essential first step when working with data is to look at it.
In images or generated text, a human can judge how good generated data is.
In the classification world, a human labeler can look at an image and say, “that is a dog,” or a sentence and say, “that is grammatically correct English.”
While these labels are somewhat fuzzy, a group of humans can at least look at the label and say, “that is reasonable” or “that is mislabeled.”
A human looking at a gene expression microarray or a table of RNA-seq counts is cannot do the same.</p>
<p>Our brains are built to recognize objects, not parse gene expression perturbations corresponding to septic shock.
This issue is not insurmountable; scientists can do research in quantum physics, after all.
It simply serves as a hindrance to our ability to sanity-check data.
Because we cannot see whether the relevant signals are distorted by batch effect normalization or a preprocessing step, we must be more careful and try more options.
Perhaps in the future, as we understand more about the relevant biology, scientists will be able to create views of the data that are more human-intuitive and easier to use.</p>
<h2 id="the-scale-of-biological-data">The scale of biological data</h2>
<p>Biological data (or at least transcriptomic data) is not actually that big.
The largest uniformly processed compendia of bulk human expression data contain hundreds of thousands of samples.
Meanwhile in machine learning, even before deep learning took off ImageNet already had more than three million images <span class="citation" data-cites="lt4BNUoG">[<a href="#ref-lt4BNUoG" role="doc-biblioref">209</a>]</span>.</p>
<p>Worse, many biological domains have strict upper bounds on the amount of data available.
Even if one somehow recruited the entire world for a study, they would only be able to collect around eight billion human genomes.
Given the complexity of biology, it seems unlikely that “only” eight billion genomes would be sufficient to effectively sample the space of plausible relevant mutations in the human genome.
Based on recent research into neural network scaling laws <span class="citation" data-cites="XVMFUrSt">[<a href="#ref-XVMFUrSt" role="doc-biblioref">210</a>]</span> and machine learning intuition, it seems likely that Rich Sutton’s “Bitter Lesson” (http://www.incompleteideas.net/IncIdeas/BitterLesson.html) would break down in a domain where there is a hard cap on the available data.
This data cap probably is not true of all domains in computational biology, though.
Gene expression changes with variables like cell type, time, and biological state, so the space of transcriptomic data that could be measured is much larger.</p>
<p>While we have shown that deep learning has not led to a paradigm shift in computational biology so far, will that always be true?
As with many scientific questions, the answer is probably “it depends.”
While there may be caps on individual aspects of biological data, there are always more angles of attack.</p>
<p>The promise of multiomics has always been that multiple views of the same system may reveal something that no single view picks up.
The challenge is that the data types are different, their relationships are not well-characterized, and the methods for working in such a system have not been fully developed yet.
Transformer architectures, and more specifically their self-attention mechanism, seem like a good fit for learning relationships between different ’omes.
Such models are data-hungry, though, and self-attention gets expensive in problems with high dimensionality.
Perhaps one day we will have the data and compute to train multiomic biological transformers.
Or maybe by then the state of the art in machine learning will have moved along, rendering them irrelevant.</p>
<h2 id="conclusion-1">Conclusion</h2>
<p>Whether deep learning takes over or simply becomes another tool in our toolbelt, the future of computational biology looks bright.
These are exciting times indeed.</p>
<h2 class="page_break_before" id="references">References</h2>
<!-- Explicitly insert bibliography here -->
<div id="refs" class="references csl-bib-body" role="doc-bibliography">
<div id="ref-14yhCmDBZ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline"><strong>Initial sequencing and analysis of the human genome</strong> <div class="csl-block">Eric S Lander, Lauren M Linton, Bruce Birren, Chad Nusbaum, Michael C Zody, Jennifer Baldwin, Keri Devon, Ken Dewar, Michael Doyle, William FitzHugh, … Michael J Morgan</div> <em>Nature</em> (2001-02-15) <a href="https://doi.org/bfpgjh">https://doi.org/bfpgjh</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/35057062">10.1038/35057062</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11237011">11237011</a></div></div>
</div>
<div id="ref-11pOKbwng" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline"><strong>Highly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets</strong> <div class="csl-block">Evan Z Macosko, Anindita Basu, Rahul Satija, James Nemesh, Karthik Shekhar, Melissa Goldman, Itay Tirosh, Allison R Bialas, Nolan Kamitaki, Emily M Martersteck, … Steven A McCarroll</div> <em>Cell</em> (2015-05) <a href="https://doi.org/f7dkxv">https://doi.org/f7dkxv</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cell.2015.05.002">10.1016/j.cell.2015.05.002</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26000488">26000488</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4481139">PMC4481139</a></div></div>
</div>
<div id="ref-7pjWPMNl" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline"><strong>An efficient targeted nuclease strategy for high-resolution mapping of DNA binding sites</strong> <div class="csl-block">Peter J Skene, Steven Henikoff</div> <em>eLife</em> (2017-01-16) <a href="https://doi.org/gfkh8w">https://doi.org/gfkh8w</a> <div class="csl-block">DOI: <a href="https://doi.org/10.7554/elife.21856">10.7554/elife.21856</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28079019">28079019</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5310842">PMC5310842</a></div></div>
</div>
<div id="ref-12pG2VA0G" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline"><strong>The second decade of 3C technologies: detailed insights into nuclear organization</strong> <div class="csl-block">Annette Denker, Wouter de Laat</div> <em>Genes &amp;amp; Development</em> (2016-06-15) <a href="https://doi.org/gdcfmg">https://doi.org/gdcfmg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/gad.281964.116">10.1101/gad.281964.116</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27340173">27340173</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4926860">PMC4926860</a></div></div>
</div>
<div id="ref-E78joy5H" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline"><strong>The structure of scientific revolutions</strong> <div class="csl-block">Thomas S Kuhn, Ian Hacking</div> <em>The University of Chicago Press</em> (2012) <div class="csl-block">ISBN: 9780226458113</div></div>
</div>
<div id="ref-2gn6PKkv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline"><strong>Mastering the game of Go with deep neural networks and tree search</strong> <div class="csl-block">David Silver, Aja Huang, Chris J Maddison, Arthur Guez, Laurent Sifre, George van den Driessche, Julian Schrittwieser, Ioannis Antonoglou, Veda Panneershelvam, Marc Lanctot, … Demis Hassabis</div> <em>Nature</em> (2016-01-27) <a href="https://doi.org/f77tw6">https://doi.org/f77tw6</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nature16961">10.1038/nature16961</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26819042">26819042</a></div></div>
</div>
<div id="ref-zJcT2HF" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline"><strong>High-Resolution Image Synthesis with Latent Diffusion Models</strong> <div class="csl-block">Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Björn Ommer</div> <em>arXiv</em> (2022-04-14) <a href="https://arxiv.org/abs/2112.10752">https://arxiv.org/abs/2112.10752</a></div>
</div>
<div id="ref-sQO3gqho" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline"><strong>Deep Double Descent: Where Bigger Models and More Data Hurt</strong> <div class="csl-block">Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, Ilya Sutskever</div> <em>arXiv</em> (2019-12-06) <a href="https://arxiv.org/abs/1912.02292">https://arxiv.org/abs/1912.02292</a></div>
</div>
<div id="ref-eZ5BSkaV" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline"><strong>Grokking: Generalization Beyond Overfitting on Small Algorithmic Datasets</strong> <div class="csl-block">Alethea Power, Yuri Burda, Harri Edwards, Igor Babuschkin, Vedant Misra</div> <em>arXiv</em> (2022-01-07) <a href="https://arxiv.org/abs/2201.02177">https://arxiv.org/abs/2201.02177</a></div>
</div>
<div id="ref-TutLhFSz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline"><strong>U-Net: Convolutional Networks for Biomedical Image Segmentation</strong> <div class="csl-block">Olaf Ronneberger, Philipp Fischer, Thomas Brox</div> <em>Lecture Notes in Computer Science</em> (2015) <a href="https://doi.org/gcgk7j">https://doi.org/gcgk7j</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/978-3-319-24574-4_28">10.1007/978-3-319-24574-4_28</a></div></div>
</div>
<div id="ref-yZfcMIwh" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline"><strong>Highly accurate protein structure prediction with AlphaFold</strong> <div class="csl-block">John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, … Demis Hassabis</div> <em>Nature</em> (2021-07-15) <a href="https://doi.org/gk7nfp">https://doi.org/gk7nfp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41586-021-03819-2">10.1038/s41586-021-03819-2</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34265844">34265844</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8371605">PMC8371605</a></div></div>
</div>
<div id="ref-Od6nwLRB" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">12. </div><div class="csl-right-inline"><strong>The elements of statistical learning: data mining, inference, and prediction</strong> <div class="csl-block">Trevor Hastie, Robert Tibshirani, JH Friedman</div> <em>Springer</em> (2009) <div class="csl-block">ISBN: 9780387848570</div></div>
</div>
<div id="ref-oEfqfC18" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">13. </div><div class="csl-right-inline"><strong>Diagnosis of multiple cancer types by shrunken centroids of gene expression</strong> <div class="csl-block">Robert Tibshirani, Trevor Hastie, Balasubramanian Narasimhan, Gilbert Chu</div> <em>Proceedings of the National Academy of Sciences</em> (2002-05-14) <a href="https://doi.org/d2h5n3">https://doi.org/d2h5n3</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1073/pnas.082099299">10.1073/pnas.082099299</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12011421">12011421</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC124443">PMC124443</a></div></div>
</div>
<div id="ref-168hoJqz4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">14. </div><div class="csl-right-inline"><strong>Averaged gene expressions for regression</strong> <div class="csl-block">MY Park, T Hastie, R Tibshirani</div> <em>Biostatistics</em> (2006-05-11) <a href="https://doi.org/czxtxj">https://doi.org/czxtxj</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/biostatistics/kxl002">10.1093/biostatistics/kxl002</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16698769">16698769</a></div></div>
</div>
<div id="ref-B01HxUe8" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">15. </div><div class="csl-right-inline"><div class="csl-block">Trevor Hastie, Robert Tibshirani, Michael B Eisen, Ash Alizadeh, Ronald Levy, Louis Staudt, Wing C Chan, David Botstein, Patrick Brown</div> <em>Genome Biology</em> (2000) <a href="https://doi.org/fsmp4p">https://doi.org/fsmp4p</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/gb-2000-1-2-research0003">10.1186/gb-2000-1-2-research0003</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11178228">11178228</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC15015">PMC15015</a></div></div>
</div>
<div id="ref-mNsjstMp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">16. </div><div class="csl-right-inline"><strong>Outlier sums for differential gene expression analysis</strong> <div class="csl-block">R Tibshirani, T Hastie</div> <em>Biostatistics</em> (2006-05-15) <a href="https://doi.org/cn72qh">https://doi.org/cn72qh</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/biostatistics/kxl005">10.1093/biostatistics/kxl005</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16702229">16702229</a></div></div>
</div>
<div id="ref-qs7B1fgV" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">17. </div><div class="csl-right-inline"><strong>Machine learning approaches to predict lupus disease activity from gene expression data</strong> <div class="csl-block">Brian Kegerreis, Michelle D Catalina, Prathyusha Bachali, Nicholas S Geraci, Adam C Labonte, Chen Zeng, Nathaniel Stearrett, Keith A Crandall, Peter E Lipsky, Amrie C Grammer</div> <em>Scientific Reports</em> (2019-07-03) <a href="https://doi.org/gh33ng">https://doi.org/gh33ng</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41598-019-45989-0">10.1038/s41598-019-45989-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31270349">31270349</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6610624">PMC6610624</a></div></div>
</div>
<div id="ref-19eIjTcxN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">18. </div><div class="csl-right-inline"><strong>Weighted elastic net for unsupervised domain adaptation with application to age prediction from DNA methylation data</strong> <div class="csl-block">Lisa Handl, Adrin Jalali, Michael Scherer, Ralf Eggeling, Nico Pfeifer</div> <em>Bioinformatics</em> (2019-07) <a href="https://doi.org/gf5d8b">https://doi.org/gf5d8b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btz338">10.1093/bioinformatics/btz338</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31510704">31510704</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6612879">PMC6612879</a></div></div>
</div>
<div id="ref-14mY2pXKf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">19. </div><div class="csl-right-inline"><strong>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</strong> <div class="csl-block">Leland McInnes, John Healy, James Melville</div> <em>arXiv</em> (2018) <a href="https://doi.org/gqzqzn">https://doi.org/gqzqzn</a> <div class="csl-block">DOI: <a href="https://doi.org/10.48550/arxiv.1802.03426">10.48550/arxiv.1802.03426</a></div></div>
</div>
<div id="ref-IRSA7yBm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">20. </div><div class="csl-right-inline"><strong>Deep-learning approach to identifying cancer subtypes using high-dimensional genomic data</strong> <div class="csl-block">Runpu Chen, Le Yang, Steve Goodison, Yijun Sun</div> <em>Bioinformatics</em> (2019-10-11) <a href="https://doi.org/gpfzxm">https://doi.org/gpfzxm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btz769">10.1093/bioinformatics/btz769</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31603461">31603461</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8215925">PMC8215925</a></div></div>
</div>
<div id="ref-7T8Uxprz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">21. </div><div class="csl-right-inline"><strong>Applications of liquid biopsies for cancer</strong> <div class="csl-block">Austin K Mattox, Chetan Bettegowda, Shibin Zhou, Nickolas Papadopoulos, Kenneth W Kinzler, Bert Vogelstein</div> <em>Science Translational Medicine</em> (2019-08-28) <a href="https://doi.org/gjsfw9">https://doi.org/gjsfw9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/scitranslmed.aay1984">10.1126/scitranslmed.aay1984</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31462507">31462507</a></div></div>
</div>
<div id="ref-Lphv6pyr" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">22. </div><div class="csl-right-inline"><strong>Histopathologic variables predict Oncotype DX™ Recurrence Score</strong> <div class="csl-block">Melina B Flanagan, David J Dabbs, Adam M Brufsky, Sushil Beriwal, Rohit Bhargava</div> <em>Modern Pathology</em> (2008-03-21) <a href="https://doi.org/d27rv3">https://doi.org/d27rv3</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/modpathol.2008.54">10.1038/modpathol.2008.54</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18360352">18360352</a></div></div>
</div>
<div id="ref-dx78bdYB" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">23. </div><div class="csl-right-inline"><strong>Analysis of blood-based gene expression in idiopathic Parkinson disease</strong> <div class="csl-block">Ron Shamir, Christine Klein, David Amar, Eva-Juliane Vollstedt, Michael Bonin, Marija Usenovic, Yvette C Wong, Ales Maver, Sven Poths, Hershel Safer, … Dimitri Krainc</div> <em>Neurology</em> (2017-09-15) <a href="https://doi.org/gcnb67">https://doi.org/gcnb67</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1212/wnl.0000000000004516">10.1212/wnl.0000000000004516</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28916538">28916538</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5644465">PMC5644465</a></div></div>
</div>
<div id="ref-1CNHzMFjN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">24. </div><div class="csl-right-inline"><strong>Blood Transcriptional Biomarkers for Active Tuberculosis among Patients in the United States: a Case-Control Study with Systematic Cross-Classifier Evaluation</strong> <div class="csl-block">Nicholas D Walter, Mikaela A Miller, Joshua Vasquez, Marc Weiner, Adam Chapman, Melissa Engle, Michael Higgins, Amy M Quinones, Vanessa Rosselli, Elizabeth Canono, … Mark W Geraci</div> <em>Journal of Clinical Microbiology</em> (2016-02) <a href="https://doi.org/gqzq2r">https://doi.org/gqzq2r</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1128/jcm.01990-15">10.1128/jcm.01990-15</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26582831">26582831</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4733166">PMC4733166</a></div></div>
</div>
<div id="ref-rJ5EpmYl" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">25. </div><div class="csl-right-inline"><strong>A Transcriptomic Biomarker to Quantify Systemic Inflammation in Sepsis — A Prospective Multicenter Phase II Diagnostic Study</strong> <div class="csl-block">Michael Bauer, Evangelos J Giamarellos-Bourboulis, Andreas Kortgen, Eva Möller, Karen Felsmann, Jean Marc Cavaillon, Orlando Guntinas-Lichius, Olivier Rutschmann, Andriy Ruryk, Matthias Kohl, … Konrad Reinhart</div> <em>EBioMedicine</em> (2016-04) <a href="https://doi.org/gqzq2q">https://doi.org/gqzq2q</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.ebiom.2016.03.006">10.1016/j.ebiom.2016.03.006</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27211554">27211554</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4856796">PMC4856796</a></div></div>
</div>
<div id="ref-1ZboiGsF" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">26. </div><div class="csl-right-inline"><strong>Gene expression profiling of peripheral blood from patients with untreated new-onset systemic juvenile idiopathic arthritis reveals molecular heterogeneity that may predict macrophage activation syndrome</strong> <div class="csl-block">Ndate Fall, Michael Barnes, Sherry Thornton, Lorie Luyrink, Judyann Olson, Norman T Ilowite, Beth S Gottlieb, Thomas Griffin, David D Sherry, Susan Thompson, … Alexei A Grom</div> <em>Arthritis &amp;amp; Rheumatism</em> (2007) <a href="https://doi.org/chxcfh">https://doi.org/chxcfh</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/art.22981">10.1002/art.22981</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/17968951">17968951</a></div></div>
</div>
<div id="ref-J9zGDTW4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">27. </div><div class="csl-right-inline"><strong>Light-Directed, Spatially Addressable Parallel Chemical Synthesis</strong> <div class="csl-block">Stephen PA Fodor, JLeighton Read, Michael C Pirrung, Lubert Stryer, Amy Tsai Lu, Dennis Solas</div> <em>Science</em> (1991-02-15) <a href="https://doi.org/dw6f5b">https://doi.org/dw6f5b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.1990438">10.1126/science.1990438</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/1990438">1990438</a></div></div>
</div>
<div id="ref-XeqEIk0K" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">28. </div><div class="csl-right-inline"><strong>Expression monitoring by hybridization to high-density oligonucleotide arrays</strong> <div class="csl-block">David J Lockhart, Helin Dong, Michael C Byrne, Maximillian T Follettie, Michael V Gallo, Mark S Chee, Michael Mittmann, Chunwei Wang, Michiko Kobayashi, Heidi Norton, Eugene L Brown</div> <em>Nature Biotechnology</em> (1996-12) <a href="https://doi.org/bpmwzt">https://doi.org/bpmwzt</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nbt1296-1675">10.1038/nbt1296-1675</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/9634850">9634850</a></div></div>
</div>
<div id="ref-ChQys9ED" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">29. </div><div class="csl-right-inline"><strong>Comparison of RNA-Seq and Microarray in Transcriptome Profiling of Activated T Cells</strong> <div class="csl-block">Shanrong Zhao, Wai-Ping Fung-Leung, Anton Bittner, Karen Ngo, Xuejun Liu</div> <em>PLoS ONE</em> (2014-01-16) <a href="https://doi.org/f5tvg3">https://doi.org/f5tvg3</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0078644">10.1371/journal.pone.0078644</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24454679">24454679</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3894192">PMC3894192</a></div></div>
</div>
<div id="ref-fVSo2gZU" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">30. </div><div class="csl-right-inline"><strong>ImageNet classification with deep convolutional neural networks</strong> <div class="csl-block">Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton</div> <em>Communications of the ACM</em> (2017-05-24) <a href="https://doi.org/gbhhxs">https://doi.org/gbhhxs</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1145/3065386">10.1145/3065386</a></div></div>
</div>
<div id="ref-c1tQ2yNq" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">31. </div><div class="csl-right-inline"><strong>Understanding Back-Translation at Scale</strong> <div class="csl-block">Sergey Edunov, Myle Ott, Michael Auli, David Grangier</div> <em>arXiv</em> (2018) <a href="https://doi.org/gqzq2v">https://doi.org/gqzq2v</a> <div class="csl-block">DOI: <a href="https://doi.org/10.48550/arxiv.1808.09381">10.48550/arxiv.1808.09381</a></div></div>
</div>
<div id="ref-HpZqLKUe" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">32. </div><div class="csl-right-inline"><strong>Exploring the Limits of Transfer Learning with a Unified Text-to-Text
Transformer</strong> <div class="csl-block">Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J. Liu</div> <em>arXiv</em> (2019-10-23) <a href="https://arxiv.org/abs/1910.10683v3">https://arxiv.org/abs/1910.10683v3</a></div>
</div>
<div id="ref-ld1EnZ6i" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">33. </div><div class="csl-right-inline"><strong>U-Net: Convolutional Networks for Biomedical Image Segmentation</strong> <div class="csl-block">Olaf Ronneberger, Philipp Fischer, Thomas Brox</div> <em>arXiv</em> (2015-05-19) <a href="https://arxiv.org/abs/1505.04597">https://arxiv.org/abs/1505.04597</a></div>
</div>
<div id="ref-MzuxpiPn" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">34. </div><div class="csl-right-inline"><strong>A review of feature selection methods based on mutual information</strong> <div class="csl-block">Jorge R Vergara, Pablo A Estévez</div> <em>Neural Computing and Applications</em> (2013-03-13) <a href="https://doi.org/gj7fzd">https://doi.org/gj7fzd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s00521-013-1368-0">10.1007/s00521-013-1368-0</a></div></div>
</div>
<div id="ref-Vzg9ivZU" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">35. </div><div class="csl-right-inline"><strong>A comparative study of feature selection and multiclass classification methods for tissue classification based on gene expression</strong> <div class="csl-block">T Li, C Zhang, M Ogihara</div> <em>Bioinformatics</em> (2004-04-15) <a href="https://doi.org/b3kzzp">https://doi.org/b3kzzp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/bth267">10.1093/bioinformatics/bth267</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/15087314">15087314</a></div></div>
</div>
<div id="ref-QSJEewCc" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">36. </div><div class="csl-right-inline"><strong>COSMIC (the Catalogue of Somatic Mutations in Cancer): a resource to investigate acquired mutations in human cancer</strong> <div class="csl-block">Simon A Forbes, Gurpreet Tang, Nidhi Bindal, Sally Bamford, Elisabeth Dawson, Charlotte Cole, Chai Yin Kok, Mingming Jia, Rebecca Ewing, Andrew Menzies, … PAndrew Futreal</div> <em>Nucleic Acids Research</em> (2009-11-10) <a href="https://doi.org/fhkk8s">https://doi.org/fhkk8s</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkp995">10.1093/nar/gkp995</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19906727">19906727</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2808858">PMC2808858</a></div></div>
</div>
<div id="ref-ClFEdqWg" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">37. </div><div class="csl-right-inline"><strong>Application of a Neural Network Whole Transcriptome–Based Pan-Cancer Method for Diagnosis of Primary and Metastatic Cancers</strong> <div class="csl-block">Jasleen K Grewal, Basile Tessier-Cloutier, Martin Jones, Sitanshu Gakkhar, Yussanne Ma, Richard Moore, Andrew J Mungall, Yongjun Zhao, Michael D Taylor, Karen Gelmon, … Steven JM Jones</div> <em>JAMA Network Open</em> (2019-04-26) <a href="https://doi.org/gf84h2">https://doi.org/gf84h2</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1001/jamanetworkopen.2019.2597">10.1001/jamanetworkopen.2019.2597</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31026023">31026023</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6487574">PMC6487574</a></div></div>
</div>
<div id="ref-F7lIlh2N" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">38. </div><div class="csl-right-inline"><strong>A Next Generation Connectivity Map: L1000 Platform and the First 1,000,000 Profiles</strong> <div class="csl-block">Aravind Subramanian, Rajiv Narayan, Steven M Corsello, David D Peck, Ted E Natoli, Xiaodong Lu, Joshua Gould, John F Davis, Andrew A Tubelli, Jacob K Asiedu, … Todd R Golub</div> <em>Cell</em> (2017-11) <a href="https://doi.org/cgwt">https://doi.org/cgwt</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cell.2017.10.049">10.1016/j.cell.2017.10.049</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29195078">29195078</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5990023">PMC5990023</a></div></div>
</div>
<div id="ref-12QQw9p7v" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">39. </div><div class="csl-right-inline"><strong>Gene expression inference with deep learning</strong> <div class="csl-block">Yifei Chen, Yi Li, Rajiv Narayan, Aravind Subramanian, Xiaohui Xie</div> <em>Bioinformatics</em> (2016-02-11) <a href="https://doi.org/f8vmtt">https://doi.org/f8vmtt</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btw074">10.1093/bioinformatics/btw074</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26873929">26873929</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4908320">PMC4908320</a></div></div>
</div>
<div id="ref-J0eeAld3" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">40. </div><div class="csl-right-inline"><strong>Robust clinical outcome prediction based on Bayesian analysis of transcriptional profiles and prior causal networks</strong> <div class="csl-block">Kourosh Zarringhalam, Ahmed Enayetallah, Padmalatha Reddy, Daniel Ziemek</div> <em>Bioinformatics</em> (2014-06-11) <a href="https://doi.org/f58bp2">https://doi.org/f58bp2</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btu272">10.1093/bioinformatics/btu272</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/24932007">24932007</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4058945">PMC4058945</a></div></div>
</div>
<div id="ref-g8OoyIPj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">41. </div><div class="csl-right-inline"><strong>Robust phenotype prediction from gene expression data using differential shrinkage of co-regulated genes</strong> <div class="csl-block">Kourosh Zarringhalam, David Degras, Christoph Brockel, Daniel Ziemek</div> <em>Scientific Reports</em> (2018-01-19) <a href="https://doi.org/gcwzdn">https://doi.org/gcwzdn</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41598-018-19635-0">10.1038/s41598-018-19635-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29352257">29352257</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5775343">PMC5775343</a></div></div>
</div>
<div id="ref-IHi1L0uN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">42. </div><div class="csl-right-inline"><strong>Prognostic gene signatures for patient stratification in breast cancer - accuracy, stability and interpretability of gene selection approaches using prior knowledge on protein-protein interactions</strong> <div class="csl-block">Yupeng Cun, Holger Fröhlich</div> <em>BMC Bioinformatics</em> (2012-05-01) <a href="https://doi.org/f4cb5r">https://doi.org/f4cb5r</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1471-2105-13-69">10.1186/1471-2105-13-69</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22548963">22548963</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3436770">PMC3436770</a></div></div>
</div>
<div id="ref-Ki2ij7zE" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">43. </div><div class="csl-right-inline"><strong>Pathway-level information extractor (PLIER) for gene expression data</strong> <div class="csl-block">Weiguang Mao, Elena Zaslavsky, Boris M Hartmann, Stuart C Sealfon, Maria Chikina</div> <em>Nature Methods</em> (2019-06-27) <a href="https://doi.org/gf75g6">https://doi.org/gf75g6</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-019-0456-1">10.1038/s41592-019-0456-1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31249421">31249421</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7262669">PMC7262669</a></div></div>
</div>
<div id="ref-14rnBunuZ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">44. </div><div class="csl-right-inline"><strong>MultiPLIER: A Transfer Learning Framework for Transcriptomics Reveals Systemic Features of Rare Disease</strong> <div class="csl-block">Jaclyn N Taroni, Peter C Grayson, Qiwen Hu, Sean Eddy, Matthias Kretzler, Peter A Merkel, Casey S Greene</div> <em>Cell Systems</em> (2019-05) <a href="https://doi.org/gf75g5">https://doi.org/gf75g5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cels.2019.04.003">10.1016/j.cels.2019.04.003</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31121115">31121115</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6538307">PMC6538307</a></div></div>
</div>
<div id="ref-2i0SZtHv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">45. </div><div class="csl-right-inline"><strong>Transfer Learning for Molecular Cancer Classification Using Deep Neural Networks</strong> <div class="csl-block">Rahul K Sevakula, Vikas Singh, Nishchal K Verma, Chandan Kumar, Yan Cui</div> <em>IEEE/ACM Transactions on Computational Biology and Bioinformatics</em> (2019-11-01) <a href="https://doi.org/gqzq3p">https://doi.org/gqzq3p</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1109/tcbb.2018.2822803">10.1109/tcbb.2018.2822803</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29993662">29993662</a></div></div>
</div>
<div id="ref-uXRnjUvq" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">46. </div><div class="csl-right-inline"><strong>A semi-supervised deep learning method based on stacked sparse auto-encoder for cancer prediction using RNA-seq data</strong> <div class="csl-block">Yawen Xiao, Jun Wu, Zongli Lin, Xiaodong Zhao</div> <em>Computer Methods and Programs in Biomedicine</em> (2018-11) <a href="https://doi.org/gfnm5c">https://doi.org/gfnm5c</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cmpb.2018.10.004">10.1016/j.cmpb.2018.10.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30415723">30415723</a></div></div>
</div>
<div id="ref-bBLm1pxP" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">47. </div><div class="csl-right-inline"><div class="csl-block">Igor Kononenko, Edvard Šimec, Marko Robnik-Šikonja</div> <em>Applied Intelligence</em> (1997) <a href="https://doi.org/fdm4r3">https://doi.org/fdm4r3</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1023/a:1008280620621">10.1023/a:1008280620621</a></div></div>
</div>
<div id="ref-17srxvYZd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">48. </div><div class="csl-right-inline"><strong>Application of transfer learning for cancer drug sensitivity prediction</strong> <div class="csl-block">Saugato Rahman Dhruba, Raziur Rahman, Kevin Matlock, Souparno Ghosh, Ranadip Pal</div> <em>BMC Bioinformatics</em> (2018-12) <a href="https://doi.org/gh4mnw">https://doi.org/gh4mnw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-018-2465-y">10.1186/s12859-018-2465-y</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30591023">30591023</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6309077">PMC6309077</a></div></div>
</div>
<div id="ref-jxCyAK09" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">49. </div><div class="csl-right-inline"><strong>A comprehensive genomic pan-cancer classification using The Cancer Genome Atlas gene expression data</strong> <div class="csl-block">Yuanyuan Li, Kai Kang, Juno M Krahn, Nicole Croutwater, Kevin Lee, David M Umbach, Leping Li</div> <em>BMC Genomics</em> (2017-07-03) <a href="https://doi.org/gfv37q">https://doi.org/gfv37q</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12864-017-3906-0">10.1186/s12864-017-3906-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28673244">28673244</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5496318">PMC5496318</a></div></div>
</div>
<div id="ref-CD9ApROI" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">50. </div><div class="csl-right-inline"><strong>Gene expression microarray classification using PCA–BEL</strong> <div class="csl-block">Ehsan Lotfi, Azita Keshavarz</div> <em>Computers in Biology and Medicine</em> (2014-11) <a href="https://doi.org/gqzq5p">https://doi.org/gqzq5p</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.compbiomed.2014.09.008">10.1016/j.compbiomed.2014.09.008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25282708">25282708</a></div></div>
</div>
<div id="ref-qJXwpyvk" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">51. </div><div class="csl-right-inline"><strong>Using deep learning to enhance cancer diagnosis and classification</strong> <div class="csl-block">Rasool Fakoor, Faisal Ladhak, Azade Nazi, Manfred Huber</div> <em>Proceedings of the international conference on machine learning</em> (2013)</div>
</div>
<div id="ref-NLVTJ9Lj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">52. </div><div class="csl-right-inline"><strong>Auto-Encoding Variational Bayes</strong> <div class="csl-block">Diederik P Kingma, Max Welling</div> <em>arXiv</em> (2014-05-02) <a href="https://arxiv.org/abs/1312.6114">https://arxiv.org/abs/1312.6114</a></div>
</div>
<div id="ref-14bFfy6t2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">53. </div><div class="csl-right-inline"><strong>Higher Order Contractive Auto-Encoder</strong> <div class="csl-block">Salah Rifai, Grégoire Mesnil, Pascal Vincent, Xavier Muller, Yoshua Bengio, Yann Dauphin, Xavier Glorot</div> <em>Machine Learning and Knowledge Discovery in Databases</em> (2011) <a href="https://doi.org/bfpkgr">https://doi.org/bfpkgr</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/978-3-642-23783-6_41">10.1007/978-3-642-23783-6_41</a></div></div>
</div>
<div id="ref-z3sjep1J" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">54. </div><div class="csl-right-inline"><strong>DeePathology: Deep Multi-Task Learning for Inferring Molecular Pathology from Cancer Transcriptome</strong> <div class="csl-block">Behrooz Azarkhalili, Ali Saberi, Hamidreza Chitsaz, Ali Sharifi-Zarchi</div> <em>Scientific Reports</em> (2019-11-11) <a href="https://doi.org/gpg7vc">https://doi.org/gpg7vc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41598-019-52937-5">10.1038/s41598-019-52937-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31712594">31712594</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6848155">PMC6848155</a></div></div>
</div>
<div id="ref-M4V6xZ3y" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">55. </div><div class="csl-right-inline"><strong>Stacked Denoising Autoencoders: Learning Useful Representations in a Deep Network with a Local Denoising Criterion</strong> <div class="csl-block">Pascal Vincent, Hugo Larochelle, Isabelle Lajoie, Yoshua Bengio, Pierre-Antoine Manzagol</div> <em>Journal of Machine Learning Research</em> (2010)</div>
</div>
<div id="ref-11ZzdspWP" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">56. </div><div class="csl-right-inline"><strong>A DEEP LEARNING APPROACH FOR CANCER DETECTION AND RELEVANT GENE IDENTIFICATION</strong> <div class="csl-block">PADIDEH DANAEE, REZA GHAEINI, DAVID A HENDRIX</div> <em>Biocomputing 2017</em> (2016-11-22) <a href="https://doi.org/gqzq5q">https://doi.org/gqzq5q</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1142/9789813207813_0022">10.1142/9789813207813_0022</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27896977">27896977</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5177447">PMC5177447</a></div></div>
</div>
<div id="ref-1CPSh19Mn" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">57. </div><div class="csl-right-inline"><strong>Exploring single-cell data with deep multitasking neural networks</strong> <div class="csl-block">Matthew Amodio, David van Dijk, Krishnan Srinivasan, William S Chen, Hussein Mohsen, Kevin R Moon, Allison Campbell, Yujiao Zhao, Xiaomei Wang, Manjunatha Venkataswamy, … Smita Krishnaswamy</div> <em>Nature Methods</em> (2019-10-07) <a href="https://doi.org/gf9rsg">https://doi.org/gf9rsg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-019-0576-7">10.1038/s41592-019-0576-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31591579">31591579</a></div></div>
</div>
<div id="ref-11cqxAool" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">58. </div><div class="csl-right-inline"><strong>Regularization and variable selection via the elastic net</strong> <div class="csl-block">Hui Zou, Trevor Hastie</div> <em>Journal of the royal statistical society: series B (statistical methodology)</em> (2005)</div>
</div>
<div id="ref-KE9BUIOX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">59. </div><div class="csl-right-inline"><strong>I tried a bunch of things: The dangers of unexpected overfitting in classification of brain data</strong> <div class="csl-block">Mahan Hosseini, Michael Powell, John Collins, Chloe Callahan-Flintoft, William Jones, Howard Bowman, Brad Wyble</div> <em>Neuroscience &amp;amp; Biobehavioral Reviews</em> (2020-12) <a href="https://doi.org/ghkskv">https://doi.org/ghkskv</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.neubiorev.2020.09.036">10.1016/j.neubiorev.2020.09.036</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33035522">33035522</a></div></div>
</div>
<div id="ref-rYMEu6oz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">60. </div><div class="csl-right-inline"><strong>Machine Learning Identifies Stemness Features Associated with Oncogenic Dedifferentiation</strong> <div class="csl-block">Tathiane M Malta, Artem Sokolov, Andrew J Gentles, Tomasz Burzykowski, Laila Poisson, John N Weinstein, Bożena Kamińska, Joerg Huelsken, Larsson Omberg, Olivier Gevaert, … Armaz Mariamidze</div> <em>Cell</em> (2018-04) <a href="https://doi.org/gc93hh">https://doi.org/gc93hh</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cell.2018.03.034">10.1016/j.cell.2018.03.034</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29625051">29625051</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5902191">PMC5902191</a></div></div>
</div>
<div id="ref-V3nGUaio" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">61. </div><div class="csl-right-inline"><strong>Massive single-cell RNA-seq analysis and imputation via deep learning</strong> <div class="csl-block">Yue Deng, Feng Bao, Qionghai Dai, Lani F Wu, Steven J Altschuler</div> <em>Cold Spring Harbor Laboratory</em> (2018-05-06) <a href="https://doi.org/gfgrpm">https://doi.org/gfgrpm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/315556">10.1101/315556</a></div></div>
</div>
<div id="ref-Uot2y2ws" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">62. </div><div class="csl-right-inline"><strong>A global immune gene expression signature for human cancers</strong> <div class="csl-block">Yuexin Liu</div> <em>Oncotarget</em> (2019-03-08) <a href="https://doi.org/gqzq8j">https://doi.org/gqzq8j</a> <div class="csl-block">DOI: <a href="https://doi.org/10.18632/oncotarget.26773">10.18632/oncotarget.26773</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30956779">30956779</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6443003">PMC6443003</a></div></div>
</div>
<div id="ref-7k4Mlul7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">63. </div><div class="csl-right-inline"><strong>A Four-Biomarker Blood Signature Discriminates Systemic Inflammation Due to Viral Infection Versus Other Etiologies</strong> <div class="csl-block">DL Sampson, BA Fox, TD Yager, S Bhide, S Cermelli, LC McHugh, TA Seldon, RA Brandon, E Sullivan, JJ Zimmerman, … RB Brandon</div> <em>Scientific Reports</em> (2017-06-06) <a href="https://doi.org/gc4zdw">https://doi.org/gc4zdw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41598-017-02325-8">10.1038/s41598-017-02325-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28588308">28588308</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5460227">PMC5460227</a></div></div>
</div>
<div id="ref-URjcKCcA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">64. </div><div class="csl-right-inline"><strong>Multitask learning improves prediction of cancer drug sensitivity</strong> <div class="csl-block">Han Yuan, Ivan Paskov, Hristo Paskov, Alvaro J González, Christina S Leslie</div> <em>Scientific Reports</em> (2016-08-23) <a href="https://doi.org/f8zbhk">https://doi.org/f8zbhk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/srep31619">10.1038/srep31619</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27550087">27550087</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4994023">PMC4994023</a></div></div>
</div>
<div id="ref-EMrWUv3D" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">65. </div><div class="csl-right-inline"><strong>Don’t Rule Out Simple Models Prematurely: A Large Scale Benchmark Comparing Linear and Non-linear Classifiers in OpenML</strong> <div class="csl-block">Benjamin Strang, Peter van der Putten, Jan N van Rijn, Frank Hutter</div> <em>Advances in Intelligent Data Analysis XVII</em> (2018) <a href="https://doi.org/gqzq6q">https://doi.org/gqzq6q</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/978-3-030-01768-2_25">10.1007/978-3-030-01768-2_25</a></div></div>
</div>
<div id="ref-GE6d2dOD" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">66. </div><div class="csl-right-inline"><strong>Does deep learning always outperform simple linear regression in optical imaging?</strong> <div class="csl-block">Shuming Jiao, Yang Gao, Jun Feng, Ting Lei, Xiaocong Yuan</div> <em>arXiv</em> (2020-02-19) <a href="https://arxiv.org/abs/1911.00353">https://arxiv.org/abs/1911.00353</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1364/OE.382319">10.1364/oe.382319</a></div></div>
</div>
<div id="ref-xSV2BrbO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">67. </div><div class="csl-right-inline"><strong>Beyond the hype: deep neural networks outperform established methods using a ChEMBL bioactivity benchmark set</strong> <div class="csl-block">Eelke B Lenselink, Niels ten Dijke, Brandon Bongers, George Papadatos, Herman WT van Vlijmen, Wojtek Kowalczyk, Adriaan P IJzerman, Gerard JP van Westen</div> <em>Journal of Cheminformatics</em> (2017-08-14) <a href="https://doi.org/gbwq98">https://doi.org/gbwq98</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s13321-017-0232-0">10.1186/s13321-017-0232-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29086168">29086168</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5555960">PMC5555960</a></div></div>
</div>
<div id="ref-15s31cve5" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">68. </div><div class="csl-right-inline"><strong>Benchmarking deep learning models on large healthcare datasets</strong> <div class="csl-block">Sanjay Purushotham, Chuizheng Meng, Zhengping Che, Yan Liu</div> <em>Journal of Biomedical Informatics</em> (2018-07) <a href="https://doi.org/gd97qc">https://doi.org/gd97qc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jbi.2018.04.007">10.1016/j.jbi.2018.04.007</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29879470">29879470</a></div></div>
</div>
<div id="ref-dmxNoeYV" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">69. </div><div class="csl-right-inline"><strong>Citation Indexes for Science</strong> <div class="csl-block">Eugene Garfield</div> <em>Science</em> (1955-07-15) <a href="https://doi.org/fnkc4f">https://doi.org/fnkc4f</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.122.3159.108">10.1126/science.122.3159.108</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14385826">14385826</a></div></div>
</div>
<div id="ref-107JaW2qS" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">70. </div><div class="csl-right-inline"><strong>The science of science</strong> <div class="csl-block">Dashun Wang, Albert-László Barabási</div> <em>Cambridge University Press</em> (2021) <div class="csl-block">ISBN: 9781108492669</div></div>
</div>
<div id="ref-qXsETMbA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">71. </div><div class="csl-right-inline"><strong>An index to quantify an individual's scientific research output</strong> <div class="csl-block">JE Hirsch</div> <em>Proceedings of the National Academy of Sciences</em> (2005-11-07) <a href="https://doi.org/cbq6dz">https://doi.org/cbq6dz</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1073/pnas.0507655102">10.1073/pnas.0507655102</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/16275915">16275915</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1283832">PMC1283832</a></div></div>
</div>
<div id="ref-1bkadVmO" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">72. </div><div class="csl-right-inline"><strong>The h -index Debate: An Introduction for Librarians</strong> <div class="csl-block">Cameron Barnes</div> <em>The Journal of Academic Librarianship</em> (2017-11) <a href="https://doi.org/gcjpk2">https://doi.org/gcjpk2</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.acalib.2017.08.013">10.1016/j.acalib.2017.08.013</a></div></div>
</div>
<div id="ref-OsrIUdWt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">73. </div><div class="csl-right-inline"><strong>The h-index is no longer an effective correlate of scientific reputation</strong> <div class="csl-block">Vladlen Koltun, David Hafner</div> <em>PLOS ONE</em> (2021-06-28) <a href="https://doi.org/gkzfnr">https://doi.org/gkzfnr</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0253397">10.1371/journal.pone.0253397</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34181681">34181681</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8238192">PMC8238192</a></div></div>
</div>
<div id="ref-iDjOlq4q" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">74. </div><div class="csl-right-inline"><strong>Theory and practise of the g-index</strong> <div class="csl-block">Leo Egghe</div> <em>Scientometrics</em> (2006-10) <a href="https://doi.org/dgj3tc">https://doi.org/dgj3tc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s11192-006-0144-7">10.1007/s11192-006-0144-7</a></div></div>
</div>
<div id="ref-16V0td5f2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">75. </div><div class="csl-right-inline"><strong>New Tools for Improving and Evaluating The Effectiveness of Research</strong> <div class="csl-block">Irving H Sher, Eugene Garfield</div> <em>Research Program Effectiveness</em> (1965-06-27)</div>
</div>
<div id="ref-4TkOo7Oy" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">76. </div><div class="csl-right-inline"><strong>Eigenfactor: Measuring the value and prestige of scholarly journals</strong> <div class="csl-block">Carl Bergstrom</div> <em>College &amp; Research Libraries News</em> (2007-05-01) <a href="https://doi.org/gf24tg">https://doi.org/gf24tg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.5860/crln.68.5.7804">10.5860/crln.68.5.7804</a></div></div>
</div>
<div id="ref-5vaZVhmk" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">77. </div><div class="csl-right-inline"><strong>A systematic empirical comparison of different approaches for normalizing citation impact indicators</strong> <div class="csl-block">Ludo Waltman, Nees Jan van Eck</div> <em>Journal of Informetrics</em> (2013-10) <a href="https://doi.org/f5jdr5">https://doi.org/f5jdr5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.joi.2013.08.002">10.1016/j.joi.2013.08.002</a></div></div>
</div>
<div id="ref-zeuTsDVX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">78. </div><div class="csl-right-inline"><strong>The PageRank Citation Ranking: Bringing Order to the Web.</strong> <div class="csl-block">Lawrence Page, Sergey Brin, Rajeev Motwani, Terry Winograd</div> <em>Stanford InfoLab</em> (1999)</div>
</div>
<div id="ref-ZiPXgNU5" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">79. </div><div class="csl-right-inline"><strong>Maps of random walks on complex networks reveal community structure</strong> <div class="csl-block">Martin Rosvall, Carl T Bergstrom</div> <em>Proceedings of the National Academy of Sciences</em> (2008-01-29) <a href="https://doi.org/fw5xcm">https://doi.org/fw5xcm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1073/pnas.0706851105">10.1073/pnas.0706851105</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18216267">18216267</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2234100">PMC2234100</a></div></div>
</div>
<div id="ref-UTLLCTKy" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">80. </div><div class="csl-right-inline"><strong>Large teams develop and small teams disrupt science and technology</strong> <div class="csl-block">Lingfei Wu, Dashun Wang, James A Evans</div> <em>Nature</em> (2019-02) <a href="https://doi.org/gfvnb9">https://doi.org/gfvnb9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41586-019-0941-9">10.1038/s41586-019-0941-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30760923">30760923</a></div></div>
</div>
<div id="ref-PGRGcmLi" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">81. </div><div class="csl-right-inline"><strong>Are disruption index indicators convergently valid? The comparison of several indicator variants with assessments by peers</strong> <div class="csl-block">Lutz Bornmann, Sitaram Devarakonda, Alexander Tekles, George Chacko</div> <em>Quantitative Science Studies</em> (2020-08) <a href="https://doi.org/gq2ts5">https://doi.org/gq2ts5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1162/qss_a_00068">10.1162/qss_a_00068</a></div></div>
</div>
<div id="ref-qT77Z7V" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">82. </div><div class="csl-right-inline"><strong>Tradition and Innovation in Scientists’ Research Strategies</strong> <div class="csl-block">Jacob G Foster, Andrey Rzhetsky, James A Evans</div> <em>American Sociological Review</em> (2015-09-01) <a href="https://doi.org/f7tzm5">https://doi.org/f7tzm5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1177/0003122415601618">10.1177/0003122415601618</a></div></div>
</div>
<div id="ref-RzTov9Er" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">83. </div><div class="csl-right-inline"><strong>Bias against novelty in science: A cautionary tale for users of bibliometric indicators</strong> <div class="csl-block">Jian Wang, Reinhilde Veugelers, Paula Stephan</div> <em>Research Policy</em> (2017-10) <a href="https://doi.org/gb22vw">https://doi.org/gb22vw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.respol.2017.06.006">10.1016/j.respol.2017.06.006</a></div></div>
</div>
<div id="ref-kZI40ZXS" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">84. </div><div class="csl-right-inline"><strong>Relative Citation Ratio (RCR): A New Metric That Uses Citation Rates to Measure Influence at the Article Level</strong> <div class="csl-block">BIan Hutchins, Xin Yuan, James M Anderson, George M Santangelo</div> <em>PLOS Biology</em> (2016-09-06) <a href="https://doi.org/f88zk2">https://doi.org/f88zk2</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pbio.1002541">10.1371/journal.pbio.1002541</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27599104">27599104</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5012559">PMC5012559</a></div></div>
</div>
<div id="ref-11IkPxdIL" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">85. </div><div class="csl-right-inline"><strong>Measuring contextual citation impact of scientific journals</strong> <div class="csl-block">Henk F Moed</div> <em>Journal of Informetrics</em> (2010-07) <a href="https://doi.org/dpbgj9">https://doi.org/dpbgj9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.joi.2010.01.002">10.1016/j.joi.2010.01.002</a></div></div>
</div>
<div id="ref-12CYfIcWF" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">86. </div><div class="csl-right-inline"><strong>Collective topical PageRank: a model to evaluate the topic-dependent academic impact of scientific papers</strong> <div class="csl-block">Yongjun Zhang, Jialin Ma, Zijian Wang, Bolun Chen, Yongtao Yu</div> <em>Scientometrics</em> (2017-12-23) <a href="https://doi.org/gc4b2s">https://doi.org/gc4b2s</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s11192-017-2626-1">10.1007/s11192-017-2626-1</a></div></div>
</div>
<div id="ref-4F5AdeXW" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">87. </div><div class="csl-right-inline"><strong>Quantifying and suppressing ranking bias in a large citation network</strong> <div class="csl-block">Giacomo Vaccario, Matus Medo, Nicolas Wider, Manuel Sebastian Mariani</div> <em>arXiv</em> (2017-08-30) <a href="https://arxiv.org/abs/1703.08071">https://arxiv.org/abs/1703.08071</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.joi.2017.05.014">10.1016/j.joi.2017.05.014</a></div></div>
</div>
<div id="ref-126JIm8me" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">88. </div><div class="csl-right-inline"><strong>Software review: COCI, the OpenCitations Index of Crossref open DOI-to-DOI citations</strong> <div class="csl-block">Ivan Heibi, Silvio Peroni, David Shotton</div> <em>Scientometrics</em> (2019-09-14) <a href="https://doi.org/ggzz8b">https://doi.org/ggzz8b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s11192-019-03217-6">10.1007/s11192-019-03217-6</a></div></div>
</div>
<div id="ref-1CjuavV0Y" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">89. </div><div class="csl-right-inline"><strong>Promise and Pitfalls of Extending Google's PageRank Algorithm to Citation Networks</strong> <div class="csl-block">S Maslov, S Redner</div> <em>Journal of Neuroscience</em> (2008-10-29) <a href="https://doi.org/fsfh8w">https://doi.org/fsfh8w</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1523/jneurosci.0002-08.2008">10.1523/jneurosci.0002-08.2008</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18971452">18971452</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6671494">PMC6671494</a></div></div>
</div>
<div id="ref-DupOCXrp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">90. </div><div class="csl-right-inline"><strong>Standardizing the Evaluation of Scientific and Academic Performance in Neurosurgery—Critical Review of the “h” Index and its Variants</strong> <div class="csl-block">Salah G Aoun, Bernard R Bendok, Rudy J Rahme, Ralph G Dacey Jr., HHunt Batjer</div> <em>World Neurosurgery</em> (2013-11) <a href="https://doi.org/fxtz98">https://doi.org/fxtz98</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.wneu.2012.01.052">10.1016/j.wneu.2012.01.052</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22381859">22381859</a></div></div>
</div>
<div id="ref-Qd54lMyE" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">91. </div><div class="csl-right-inline"><strong>UNDERSTANDING THE LIMITATIONS OF THE JOURNAL IMPACT FACTOR</strong> <div class="csl-block">ANDREW P KURMIS</div> <em>The Journal of Bone and Joint Surgery-American Volume</em> (2003-12) <a href="https://doi.org/gh6fph">https://doi.org/gh6fph</a> <div class="csl-block">DOI: <a href="https://doi.org/10.2106/00004623-200312000-00028">10.2106/00004623-200312000-00028</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14668520">14668520</a></div></div>
</div>
<div id="ref-1oH3MHiP" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">92. </div><div class="csl-right-inline"><strong>Why trust science?</strong> <div class="csl-block">Naomi Oreskes</div> <em>Princeton University Press</em> (2021) <div class="csl-block">ISBN: 9780691212265</div></div>
</div>
<div id="ref-XmeBExNd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">93. </div><div class="csl-right-inline"><strong>Setting the default to reproducible</strong> <div class="csl-block">Victoria Stodden, Jonathan Borwein, David H Bailey</div> <em>ICERM Workshop on Reproducibility in Computational and Experimental Mathematics</em> (2013)</div>
</div>
<div id="ref-AMHLAKQN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">94. </div><div class="csl-right-inline"><strong>Minimum information about clinical artificial intelligence modeling: the MI-CLAIM checklist</strong> <div class="csl-block">Beau Norgeot, Giorgio Quer, Brett K Beaulieu-Jones, Ali Torkamani, Raquel Dias, Milena Gianfrancesco, Rima Arnaout, Isaac S Kohane, Suchi Saria, Eric Topol, … Atul J Butte</div> <em>Nature Medicine</em> (2020-09) <a href="https://doi.org/ghfzhk">https://doi.org/ghfzhk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41591-020-1041-y">10.1038/s41591-020-1041-y</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32908275">32908275</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7538196">PMC7538196</a></div></div>
</div>
<div id="ref-lOLryKMv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">95. </div><div class="csl-right-inline"><strong>MINIMAR (MINimum Information for Medical AI Reporting): Developing reporting standards for artificial intelligence in health care</strong> <div class="csl-block">Tina Hernandez-Boussard, Selen Bozkurt, John PA Ioannidis, Nigam H Shah</div> <em>Journal of the American Medical Informatics Association</em> (2020-06-28) <a href="https://doi.org/gmns84">https://doi.org/gmns84</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/jamia/ocaa088">10.1093/jamia/ocaa088</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32594179">32594179</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7727333">PMC7727333</a></div></div>
</div>
<div id="ref-1DSgCvdQb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">96. </div><div class="csl-right-inline"><strong>Checklist for Artificial Intelligence in Medical Imaging (CLAIM): A Guide for Authors and Reviewers</strong> <div class="csl-block">John Mongan, Linda Moy, Charles E Kahn Jr</div> <em>Radiology: Artificial Intelligence</em> (2020-03-01) <a href="https://doi.org/gg9f65">https://doi.org/gg9f65</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1148/ryai.2020200029">10.1148/ryai.2020200029</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33937821">33937821</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8017414">PMC8017414</a></div></div>
</div>
<div id="ref-DPHUSOUd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">97. </div><div class="csl-right-inline"><strong>Sharing biological data: why, when, and how</strong> <div class="csl-block">Samantha L Wilson, Gregory P Way, Wout Bittremieux, Jean‐Paul Armache, Melissa A Haendel, Michael M Hoffman</div> <em>FEBS Letters</em> (2021-04) <a href="https://doi.org/gmmq7d">https://doi.org/gmmq7d</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/1873-3468.14067">10.1002/1873-3468.14067</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33843054">33843054</a></div></div>
</div>
<div id="ref-14VfbatMA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">98. </div><div class="csl-right-inline"><strong>Gene Expression Omnibus: NCBI gene expression and hybridization array data repository</strong> <div class="csl-block">R Edgar</div> <em>Nucleic Acids Research</em> (2002-01-01) <a href="https://doi.org/fttpkn">https://doi.org/fttpkn</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/30.1.207">10.1093/nar/30.1.207</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11752295">11752295</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC99122">PMC99122</a></div></div>
</div>
<div id="ref-PjDNfyd6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">99. </div><div class="csl-right-inline"><strong>A call for public archives for biological image data</strong> <div class="csl-block">Jan Ellenberg, Jason R Swedlow, Mary Barlow, Charles E Cook, Ugis Sarkans, Ardan Patwardhan, Alvis Brazma, Ewan Birney</div> <em>Nature Methods</em> (2018-10-30) <a href="https://doi.org/gfgphs">https://doi.org/gfgphs</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-018-0195-8">10.1038/s41592-018-0195-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30377375">30377375</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6884425">PMC6884425</a></div></div>
</div>
<div id="ref-tQy0rfF4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">100. </div><div class="csl-right-inline"><strong>The Kipoi repository accelerates community exchange and reuse of predictive models for genomics</strong> <div class="csl-block">Žiga Avsec, Roman Kreuzhuber, Johnny Israeli, Nancy Xu, Jun Cheng, Avanti Shrikumar, Abhimanyu Banerjee, Daniel S Kim, Thorsten Beier, Lara Urban, … Julien Gagneur</div> <em>Nature Biotechnology</em> (2019-05-28) <a href="https://doi.org/gf3fmq">https://doi.org/gf3fmq</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41587-019-0140-0">10.1038/s41587-019-0140-0</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31138913">31138913</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6777348">PMC6777348</a></div></div>
</div>
<div id="ref-AHZYK6YM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">101. </div><div class="csl-right-inline"><strong>Sfaira accelerates data and model reuse in single cell genomics</strong> <div class="csl-block">David S Fischer, Leander Dony, Martin König, Abdul Moeed, Luke Zappia, Lukas Heumos, Sophie Tritschler, Olle Holmberg, Hananeh Aliee, Fabian J Theis</div> <em>Genome Biology</em> (2021-08-25) <a href="https://doi.org/gq8drj">https://doi.org/gq8drj</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s13059-021-02452-6">10.1186/s13059-021-02452-6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34433466">34433466</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8386039">PMC8386039</a></div></div>
</div>
<div id="ref-40QbsPCe" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">102. </div><div class="csl-right-inline"><strong>Docker: lightweight Linux containers for consistent development and deployment</strong> <div class="csl-block">Dirk Merkel</div> <em>Linux Journal</em> (2014)</div>
</div>
<div id="ref-NcYZqBux" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">103. </div><div class="csl-right-inline"><strong>Snakemake--a scalable bioinformatics workflow engine</strong> <div class="csl-block">J Koster, S Rahmann</div> <em>Bioinformatics</em> (2012-08-20) <a href="https://doi.org/gd2xzq">https://doi.org/gd2xzq</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/bts480">10.1093/bioinformatics/bts480</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22908215">22908215</a></div></div>
</div>
<div id="ref-4XDvZWxk" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">104. </div><div class="csl-right-inline"><strong>Nextflow enables reproducible computational workflows</strong> <div class="csl-block">Paolo Di Tommaso, Maria Chatzou, Evan W Floden, Pablo Prieto Barja, Emilio Palumbo, Cedric Notredame</div> <em>Nature Biotechnology</em> (2017-04) <a href="https://doi.org/gfj52z">https://doi.org/gfj52z</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nbt.3820">10.1038/nbt.3820</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28398311">28398311</a></div></div>
</div>
<div id="ref-VpgPDZxv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">105. </div><div class="csl-right-inline"><strong>Responsible, practical genomic data sharing that accelerates research</strong> <div class="csl-block">James Brian Byrd, Anna C Greene, Deepashree Venkatesh Prasad, Xiaoqian Jiang, Casey S Greene</div> <em>Nature Reviews Genetics</em> (2020-07-21) <a href="https://doi.org/gg7c57">https://doi.org/gg7c57</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41576-020-0257-5">10.1038/s41576-020-0257-5</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32694666">32694666</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7974070">PMC7974070</a></div></div>
</div>
<div id="ref-DsfimvK4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">106. </div><div class="csl-right-inline"><strong>Extracting Training Data from Large Language Models</strong> <div class="csl-block">Nicholas Carlini, Florian Tramer, Eric Wallace, Matthew Jagielski, Ariel Herbert-Voss, Katherine Lee, Adam Roberts, Tom Brown, Dawn Song, Ulfar Erlingsson, … Colin Raffel</div> <em>arXiv</em> (2021-06-16) <a href="https://arxiv.org/abs/2012.07805">https://arxiv.org/abs/2012.07805</a></div>
</div>
<div id="ref-LiCxcgZp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">107. </div><div class="csl-right-inline"><strong>Deep Learning with Differential Privacy</strong> <div class="csl-block">Martin Abadi, Andy Chu, Ian Goodfellow, HBrendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang</div> <em>Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security</em> (2016-10-24) <a href="https://doi.org/gcrnp3">https://doi.org/gcrnp3</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1145/2976749.2978318">10.1145/2976749.2978318</a></div></div>
</div>
<div id="ref-1G5MoLsVr" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">108. </div><div class="csl-right-inline"><strong>Top considerations for creating bioinformatics software documentation</strong> <div class="csl-block">Mehran Karimzadeh, Michael M Hoffman</div> <em>Briefings in Bioinformatics</em> (2017-01-14) <a href="https://doi.org/bzmp">https://doi.org/bzmp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bib/bbw134">10.1093/bib/bbw134</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28088754">28088754</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6054259">PMC6054259</a></div></div>
</div>
<div id="ref-nQNzN279" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">109. </div><div class="csl-right-inline"><strong>Bioconductor: open software development for computational biology and bioinformatics</strong> <div class="csl-block">Robert C Gentleman, Vincent J Carey, Douglas M Bates, Ben Bolstad, Marcel Dettling, Sandrine Dudoit, Byron Ellis, Laurent Gautier, Yongchao Ge, Jeff Gentry, … Jianhua Zhang</div> <em>Genome Biology</em> (2004) <a href="https://doi.org/c2xm5v">https://doi.org/c2xm5v</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/gb-2004-5-10-r80">10.1186/gb-2004-5-10-r80</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/15461798">15461798</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC545600">PMC545600</a></div></div>
</div>
<div id="ref-lnK82Ey6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">110. </div><div class="csl-right-inline"><strong>Supervised Risk Predictor of Breast Cancer Based on Intrinsic Subtypes</strong> <div class="csl-block">Joel S Parker, Michael Mullins, Maggie CU Cheang, Samuel Leung, David Voduc, Tammi Vickery, Sherri Davies, Christiane Fauron, Xiaping He, Zhiyuan Hu, … Philip S Bernard</div> <em>Journal of Clinical Oncology</em> (2009-03-10) <a href="https://doi.org/c2688w">https://doi.org/c2688w</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1200/jco.2008.18.1370">10.1200/jco.2008.18.1370</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19204204">19204204</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2667820">PMC2667820</a></div></div>
</div>
<div id="ref-w3jVFxUa" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">111. </div><div class="csl-right-inline"><strong>Gene Expression Profiling for the Identification and Classification of Antibody-Mediated Heart Rejection</strong> <div class="csl-block">Alexandre Loupy, Jean Paul Duong Van Huyen, Luis Hidalgo, Jeff Reeve, Maud Racapé, Olivier Aubert, Jeffery M Venner, Konrad Falmuski, Marie Cécile Bories, Thibaut Beuscart, … Philip F Halloran</div> <em>Circulation</em> (2017-03-07) <a href="https://doi.org/f9vfvw">https://doi.org/f9vfvw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1161/circulationaha.116.022907">10.1161/circulationaha.116.022907</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28148598">28148598</a></div></div>
</div>
<div id="ref-11QqOFPV2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">112. </div><div class="csl-right-inline"><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8011224/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8011224/</a></div>
</div>
<div id="ref-pT4E5exd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">113. </div><div class="csl-right-inline"><strong>Compute Trends Across Three Eras of Machine Learning</strong> <div class="csl-block">Jaime Sevilla, Lennart Heim, Anson Ho, Tamay Besiroglu, Marius Hobbhahn, Pablo Villalobos</div> <em>arXiv</em> (2022-03-11) <a href="https://arxiv.org/abs/2202.05924">https://arxiv.org/abs/2202.05924</a></div>
</div>
<div id="ref-Nz3IMEzd" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">114. </div><div class="csl-right-inline"><strong>Massive mining of publicly available RNA-seq data from human and mouse</strong> <div class="csl-block">Alexander Lachmann, Denis Torre, Alexandra B Keenan, Kathleen M Jagodnik, Hoyjin J Lee, Lily Wang, Moshe C Silverstein, Avi Ma’ayan</div> <em>Nature Communications</em> (2018-04-10) <a href="https://doi.org/gc92dr">https://doi.org/gc92dr</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41467-018-03751-6">10.1038/s41467-018-03751-6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29636450">29636450</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5893633">PMC5893633</a></div></div>
</div>
<div id="ref-1FjFz2cPj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">115. </div><div class="csl-right-inline"><strong>A curated database reveals trends in single-cell transcriptomics</strong> <div class="csl-block">Valentine Svensson, Eduardo da Veiga Beltrame, Lior Pachter</div> <em>Database</em> (2020) <a href="https://doi.org/gjnr3h">https://doi.org/gjnr3h</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/database/baaa073">10.1093/database/baaa073</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33247933">33247933</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7698659">PMC7698659</a></div></div>
</div>
<div id="ref-n1zG78a6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">116. </div><div class="csl-right-inline"><strong>Bias-invariant RNA-sequencing metadata annotation</strong> <div class="csl-block">Hannes Wartmann, Sven Heins, Karin Kloiber, Stefan Bonn</div> <em>GigaScience</em> (2021-09) <a href="https://doi.org/gph9xp">https://doi.org/gph9xp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/gigascience/giab064">10.1093/gigascience/giab064</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34553213">34553213</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8559615">PMC8559615</a></div></div>
</div>
<div id="ref-mfKo4pPn" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">117. </div><div class="csl-right-inline"><strong>Improved prediction of smoking status via isoform-aware RNA-seq deep learning models</strong> <div class="csl-block">Zifeng Wang, Aria Masoomi, Zhonghui Xu, Adel Boueiz, Sool Lee, Tingting Zhao, Russell Bowler, Michael Cho, Edwin K Silverman, Craig Hersh, … Peter J Castaldi</div> <em>PLOS Computational Biology</em> (2021-10-11) <a href="https://doi.org/gph9xq">https://doi.org/gph9xq</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pcbi.1009433">10.1371/journal.pcbi.1009433</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34634029">34634029</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8530282">PMC8530282</a></div></div>
</div>
<div id="ref-9O6X3Dmj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">118. </div><div class="csl-right-inline"><strong>The evolution of gene expression and the transcriptome–phenotype relationship</strong> <div class="csl-block">Peter W Harrison, Alison E Wright, Judith E Mank</div> <em>Seminars in Cell &amp;amp; Developmental Biology</em> (2012-04) <a href="https://doi.org/fxqd2g">https://doi.org/fxqd2g</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.semcdb.2011.12.004">10.1016/j.semcdb.2011.12.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/22210502">22210502</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3378502">PMC3378502</a></div></div>
</div>
<div id="ref-11pMMG4s" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">119. </div><div class="csl-right-inline"><strong>Nonlinear Dynamics in Gene Regulation Promote Robustness and Evolvability of Gene Expression Levels</strong> <div class="csl-block">Arno Steinacher, Declan G Bates, Ozgur E Akman, Orkun S Soyer</div> <em>PLOS ONE</em> (2016-04-15) <a href="https://doi.org/f8xrrq">https://doi.org/f8xrrq</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0153295">10.1371/journal.pone.0153295</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27082741">27082741</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4833316">PMC4833316</a></div></div>
</div>
<div id="ref-1CFhfCyWN" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">120. </div><div class="csl-right-inline"><strong>ADAGE-Based Integration of Publicly Available Pseudomonas aeruginosa Gene Expression Data with Denoising Autoencoders Illuminates Microbe-Host Interactions</strong> <div class="csl-block">Jie Tan, John H Hammond, Deborah A Hogan, Casey S Greene</div> <em>mSystems</em> (2016-02-23) <a href="https://doi.org/gcgmbq">https://doi.org/gcgmbq</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1128/msystems.00025-15">10.1128/msystems.00025-15</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27822512">27822512</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5069748">PMC5069748</a></div></div>
</div>
<div id="ref-19wuAzYvo" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">121. </div><div class="csl-right-inline"><strong>A biological network-based regularized artificial neural network model for robust phenotype prediction from gene expression data</strong> <div class="csl-block">Tianyu Kang, Wei Ding, Luoyan Zhang, Daniel Ziemek, Kourosh Zarringhalam</div> <em>BMC Bioinformatics</em> (2017-12) <a href="https://doi.org/gf8cm6">https://doi.org/gf8cm6</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-017-1984-2">10.1186/s12859-017-1984-2</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29258445">29258445</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5735940">PMC5735940</a></div></div>
</div>
<div id="ref-1Dt8XU1y4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">122. </div><div class="csl-right-inline"><strong>Standard machine learning approaches outperform deep representation learning on phenotype prediction from transcriptomics data</strong> <div class="csl-block">Aaron M Smith, Jonathan R Walsh, John Long, Craig B Davis, Peter Henstock, Martin R Hodge, Mateusz Maciejewski, Xinmeng Jasmine Mu, Stephen Ra, Shanrong Zhao, … Charles K Fisher</div> <em>BMC Bioinformatics</em> (2020-03-20) <a href="https://doi.org/ggpc9d">https://doi.org/ggpc9d</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-020-3427-8">10.1186/s12859-020-3427-8</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32197580">32197580</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7085143">PMC7085143</a></div></div>
</div>
<div id="ref-182D7GluU" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">123. </div><div class="csl-right-inline"><strong>A systematic review shows no performance benefit of machine learning over logistic regression for clinical prediction models</strong> <div class="csl-block">Evangelia Christodoulou, Jie Ma, Gary S Collins, Ewout W Steyerberg, Jan Y Verbakel, Ben Van Calster</div> <em>Journal of Clinical Epidemiology</em> (2019-06) <a href="https://doi.org/gfzstd">https://doi.org/gfzstd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.jclinepi.2019.02.004">10.1016/j.jclinepi.2019.02.004</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30763612">30763612</a></div></div>
</div>
<div id="ref-1lk3HMPq" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">124. </div><div class="csl-right-inline"><strong>Different scaling of linear models and deep learning in UKBiobank brain images versus machine-learning datasets</strong> <div class="csl-block">Marc-Andre Schulz, BTThomas Yeo, Joshua T Vogelstein, Janaina Mourao-Miranada, Jakob N Kather, Konrad Kording, Blake Richards, Danilo Bzdok</div> <em>Nature Communications</em> (2020-08-25) <a href="https://doi.org/gg9njw">https://doi.org/gg9njw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41467-020-18037-z">10.1038/s41467-020-18037-z</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32843633">32843633</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7447816">PMC7447816</a></div></div>
</div>
<div id="ref-187XBwaz7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">125. </div><div class="csl-right-inline"><strong>The Genotype-Tissue Expression (GTEx) project</strong> <div class="csl-block">John Lonsdale, Jeffrey Thomas, Mike Salvatore, Rebecca Phillips, Edmund Lo, Saboor Shad, Richard Hasz, Gary Walters, Fernando Garcia, Nancy Young, … Helen F Moore</div> <em>Nature Genetics</em> (2013-05-29) <a href="https://doi.org/gd5z68">https://doi.org/gd5z68</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/ng.2653">10.1038/ng.2653</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23715323">23715323</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4010069">PMC4010069</a></div></div>
</div>
<div id="ref-xdJRSgce" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">126. </div><div class="csl-right-inline"><strong>recount3: summaries and queries for large-scale RNA-seq expression and splicing</strong> <div class="csl-block">Christopher Wilks, Shijie C Zheng, Feng Yong Chen, Rone Charles, Brad Solomon, Jonathan P Ling, Eddie Luidy Imada, David Zhang, Lance Joseph, Jeffrey T Leek, … Ben Langmead</div> <em>Genome Biology</em> (2021-11-29) <a href="https://doi.org/gnm7zc">https://doi.org/gnm7zc</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s13059-021-02533-6">10.1186/s13059-021-02533-6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34844637">34844637</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8628444">PMC8628444</a></div></div>
</div>
<div id="ref-1GHeCqbnH" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">127. </div><div class="csl-right-inline"><strong>Parameter tuning is a key part of dimensionality reduction via deep variational autoencoders for single cell RNA transcriptomics</strong> <div class="csl-block">Qiwen Hu, Casey S Greene</div> <em>Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing</em> (2019) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6417816/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6417816/</a> <div class="csl-block">PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30963075">30963075</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6417816">PMC6417816</a></div></div>
</div>
<div id="ref-10mtDRGf7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">128. </div><div class="csl-right-inline"><strong>Large-scale labeling and assessment of sex bias in publicly available expression data</strong> <div class="csl-block">Emily Flynn, Annie Chang, Russ B Altman</div> <em>BMC Bioinformatics</em> (2021-03-30) <a href="https://doi.org/gpjt3n">https://doi.org/gpjt3n</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-021-04070-2">10.1186/s12859-021-04070-2</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33784977">33784977</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8011224">PMC8011224</a></div></div>
</div>
<div id="ref-1GBPSAJ10" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">129. </div><div class="csl-right-inline"><strong>The Sequence Read Archive</strong> <div class="csl-block">R Leinonen, H Sugawara, M Shumway</div> <em>Nucleic Acids Research</em> (2010-11-09) <a href="https://doi.org/c652z5">https://doi.org/c652z5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkq1019">10.1093/nar/gkq1019</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21062823">21062823</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013647">PMC3013647</a></div></div>
</div>
<div id="ref-eirYTTyk" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">130. </div><div class="csl-right-inline"><strong>An efficient not-only-linear correlation coefficient based on machine learning</strong> <div class="csl-block">Milton Pividori, Marylyn D Ritchie, Diego H Milone, Casey S Greene</div> <em>Cold Spring Harbor Laboratory</em> (2022-06-17) <a href="https://doi.org/gqcvbw">https://doi.org/gqcvbw</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/2022.06.15.496326">10.1101/2022.06.15.496326</a></div></div>
</div>
<div id="ref-PO5Xkwt3" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">131. </div><div class="csl-right-inline"><strong>limma powers differential expression analyses for RNA-sequencing and microarray studies</strong> <div class="csl-block">Matthew E Ritchie, Belinda Phipson, Di Wu, Yifang Hu, Charity W Law, Wei Shi, Gordon K Smyth</div> <em>Nucleic Acids Research</em> (2015-01-20) <a href="https://doi.org/f7c4n5">https://doi.org/f7c4n5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkv007">10.1093/nar/gkv007</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25605792">25605792</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4402510">PMC4402510</a></div></div>
</div>
<div id="ref-13prIHiSM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">132. </div><div class="csl-right-inline"><strong>Navigating the pitfalls of applying machine learning in genomics</strong> <div class="csl-block">Sean Whalen, Jacob Schreiber, William S Noble, Katherine S Pollard</div> <em>Nature Reviews Genetics</em> (2021-11-26) <a href="https://doi.org/gnm4r9">https://doi.org/gnm4r9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41576-021-00434-9">10.1038/s41576-021-00434-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34837041">34837041</a></div></div>
</div>
<div id="ref-zepEBNtj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">133. </div><div class="csl-right-inline"><strong>Phosphorylation of ETS transcription factor ER81 in a complex with its coactivators CREB-binding protein and p300</strong> <div class="csl-block">S Papoutsopoulou, R Janknecht</div> <em>Molecular and cellular biology</em> (2000-10) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC86284/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC86284/</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1128/MCB.20.19.7300-7310.2000">10.1128/mcb.20.19.7300-7310.2000</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/10982847">10982847</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC86284">PMC86284</a></div></div>
</div>
<div id="ref-Qgjx8811" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">134. </div><div class="csl-right-inline"><strong>BioMart--biological queries made easy</strong> <div class="csl-block">Damian Smedley, Syed Haider, Benoit Ballester, Richard Holland, Darin London, Gudmundur Thorisson, Arek Kasprzyk</div> <em>BMC genomics</em> (2009-01-14) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2649164/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2649164/</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1471-2164-10-22">10.1186/1471-2164-10-22</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19144180">19144180</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2649164">PMC2649164</a></div></div>
</div>
<div id="ref-yLsmK3mK" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">135. </div><div class="csl-right-inline"><strong>The European Nucleotide Archive</strong> <div class="csl-block">Rasko Leinonen, Ruth Akhtar, Ewan Birney, Lawrence Bower, Ana Cerdeno-Tárraga, Ying Cheng, Iain Cleland, Nadeem Faruque, Neil Goodgame, Richard Gibson, … Guy Cochrane</div> <em>Nucleic acids research</em> (2011-01) <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013801/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013801/</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkq967">10.1093/nar/gkq967</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20972220">20972220</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3013801">PMC3013801</a></div></div>
</div>
<div id="ref-Xk9rmxAA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">136. </div><div class="csl-right-inline"><strong>Rectified linear units improve restricted boltzmann machines</strong> <div class="csl-block">Vinod Nair, Geoffrey E Hinton</div> <em>Proceedings of the 27th International Conference on International Conference on Machine Learning</em> (2010-06-21) <a href="https://dl.acm.org/doi/10.5555/3104322.3104425">https://dl.acm.org/doi/10.5555/3104322.3104425</a> <div class="csl-block">ISBN: 9781605589077</div></div>
</div>
<div id="ref-iTP4h1rX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">137. </div><div class="csl-right-inline"><strong>PyTorch: An Imperative Style, High-Performance Deep Learning Library</strong> <div class="csl-block">Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, … Soumith Chintala</div> <em>arXiv</em> (2019-12-05) <a href="https://arxiv.org/abs/1912.01703">https://arxiv.org/abs/1912.01703</a></div>
</div>
<div id="ref-c6d3lKFX" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">138. </div><div class="csl-right-inline"><strong>Adam: A Method for Stochastic Optimization</strong> <div class="csl-block">Diederik P Kingma, Jimmy Ba</div> <em>arXiv</em> (2017-01-31) <a href="https://arxiv.org/abs/1412.6980">https://arxiv.org/abs/1412.6980</a></div>
</div>
<div id="ref-ynNhuuuv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">139. </div><div class="csl-right-inline"><strong>Dropout: A Simple Way to Prevent Neural Networks from Overfitting</strong> <div class="csl-block">Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov</div> <em>Journal of Machine Learning Research</em> (2014) <a href="http://jmlr.org/papers/v15/srivastava14a.html">http://jmlr.org/papers/v15/srivastava14a.html</a></div>
</div>
<div id="ref-io1g9Re6" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">140. </div><div class="csl-right-inline"><strong>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</strong> <div class="csl-block">Sergey Ioffe, Christian Szegedy</div> <em>Proceedings of the 32nd International Conference on Machine Learning</em> (2015-06-01) <a href="https://proceedings.mlr.press/v37/ioffe15.html">https://proceedings.mlr.press/v37/ioffe15.html</a></div>
</div>
<div id="ref-1Dhv6WYjo" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">141. </div><div class="csl-right-inline"><strong>Neptune: Experiment management and collaboration tool</strong> <div class="csl-block">neptune.ai</div> (2020) <a href="https://neptune.ai">https://neptune.ai</a></div>
</div>
<div id="ref-PETW01rJ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">142. </div><div class="csl-right-inline"><strong>Reproducibility standards for machine learning in the life sciences</strong> <div class="csl-block">Benjamin J Heil, Michael M Hoffman, Florian Markowetz, Su-In Lee, Casey S Greene, Stephanie C Hicks</div> <em>Nature Methods</em> (2021-08-30) <a href="https://doi.org/gmnnqh">https://doi.org/gmnnqh</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41592-021-01256-7">10.1038/s41592-021-01256-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34462593">34462593</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9131851">PMC9131851</a></div></div>
</div>
<div id="ref-1APo3Hcx8" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">143. </div><div class="csl-right-inline"><strong>High throughput analysis of differential gene expression</strong> <div class="csl-block">John P Carulli, Michael Artinger, Pamela M Swain, Colleen D Root, Linda Chee, Craig Tulig, Jennifer Guerin, Mark Osborne, Gary Stein, Jane Lian, Peter T Lomedico</div> <em>Journal of Cellular Biochemistry</em> (1998) <a href="https://doi.org/dcz39r">https://doi.org/dcz39r</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/(sici)1097-4644(1998)72:30/31+&lt;286::aid-jcb35&gt;3.0.co;2-d">10.1002/(sici)1097-4644(1998)72:30/31+&lt;286::aid-jcb35&gt;3.0.co;2-d</a></div></div>
</div>
<div id="ref-yk8zQJz3" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">144. </div><div class="csl-right-inline"><strong>Differential expression analysis for sequence count data</strong> <div class="csl-block">Simon Anders, Wolfgang Huber</div> <em>Genome Biology</em> (2010-10) <a href="https://doi.org/btmbk5">https://doi.org/btmbk5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/gb-2010-11-10-r106">10.1186/gb-2010-11-10-r106</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20979621">20979621</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3218662">PMC3218662</a></div></div>
</div>
<div id="ref-qordNoBb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">145. </div><div class="csl-right-inline"><strong>RNA-Seq differential expression analysis: An extended review and a software tool</strong> <div class="csl-block">Juliana Costa-Silva, Douglas Domingues, Fabricio Martins Lopes</div> <em>PLOS ONE</em> (2017-12-21) <a href="https://doi.org/gf4p49">https://doi.org/gf4p49</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1371/journal.pone.0190152">10.1371/journal.pone.0190152</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29267363">29267363</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5739479">PMC5739479</a></div></div>
</div>
<div id="ref-LqrX5gU9" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">146. </div><div class="csl-right-inline"><strong>Statistical approaches for differential expression analysis in metatranscriptomics</strong> <div class="csl-block">Yancong Zhang, Kelsey N Thompson, Curtis Huttenhower, Eric A Franzosa</div> <em>Bioinformatics</em> (2021-07-01) <a href="https://doi.org/grcgxx">https://doi.org/grcgxx</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btab327">10.1093/bioinformatics/btab327</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34252963">34252963</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8275336">PMC8275336</a></div></div>
</div>
<div id="ref-EBwnauin" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">147. </div><div class="csl-right-inline"><strong>Analysis of a complex of statistical variables into principal components.</strong> <div class="csl-block">H Hotelling</div> <em>Journal of Educational Psychology</em> (1933-09) <a href="https://doi.org/fb5435">https://doi.org/fb5435</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1037/h0071325">10.1037/h0071325</a></div></div>
</div>
<div id="ref-1D2hpyeIm" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">148. </div><div class="csl-right-inline"><strong>Visualizing data using t-SNE.</strong> <div class="csl-block">Geoffrey Hinton, Laurens Van der Maaten</div> <em>Journal of machine learning research</em> (2008)</div>
</div>
<div id="ref-piytFx3h" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">149. </div><div class="csl-right-inline"><strong>UMAP: Uniform Manifold Approximation and Projection</strong> <div class="csl-block">Leland McInnes, John Healy, Nathaniel Saul, Lukas Großberger</div> <em>Journal of Open Source Software</em> (2018-09-02) <a href="https://doi.org/gf6k3s">https://doi.org/gf6k3s</a> <div class="csl-block">DOI: <a href="https://doi.org/10.21105/joss.00861">10.21105/joss.00861</a></div></div>
</div>
<div id="ref-113fm3uP2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">150. </div><div class="csl-right-inline"><strong>Clustering Algorithms: Their Application to Gene Expression Data</strong> <div class="csl-block">Jelili Oyelade, Itunuoluwa Isewon, Funke Oladipupo, Olufemi Aromolaran, Efosa Uwoghiren, Faridah Ameh, Moses Achas, Ezekiel Adebiyi</div> <em>Bioinformatics and Biology Insights</em> (2016-01) <a href="https://doi.org/gm72kz">https://doi.org/gm72kz</a> <div class="csl-block">DOI: <a href="https://doi.org/10.4137/bbi.s38316">10.4137/bbi.s38316</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27932867">27932867</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5135122">PMC5135122</a></div></div>
</div>
<div id="ref-ZRb1Hqb2" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">151. </div><div class="csl-right-inline"><strong>Single-cell transcriptional profiles in human skeletal muscle</strong> <div class="csl-block">Aliza B Rubenstein, Gregory R Smith, Ulrika Raue, Gwénaëlle Begue, Kiril Minchev, Frederique Ruf-Zamojski, Venugopalan D Nair, Xingyu Wang, Lan Zhou, Elena Zaslavsky, … Stuart C Sealfon</div> <em>Scientific Reports</em> (2020-01-14) <a href="https://doi.org/ggr7ms">https://doi.org/ggr7ms</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41598-019-57110-6">10.1038/s41598-019-57110-6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/31937892">31937892</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6959232">PMC6959232</a></div></div>
</div>
<div id="ref-miWUn1Ks" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">152. </div><div class="csl-right-inline"><strong>Pyramidal neuron subtype diversity governs microglia states in the neocortex</strong> <div class="csl-block">Jeffrey A Stogsdill, Kwanho Kim, Loïc Binan, Samouil L Farhi, Joshua Z Levin, Paola Arlotta</div> <em>Nature</em> (2022-08-10) <a href="https://doi.org/gqpg36">https://doi.org/gqpg36</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/s41586-022-05056-7">10.1038/s41586-022-05056-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/35948630">35948630</a></div></div>
</div>
<div id="ref-WZxHGrSb" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">153. </div><div class="csl-right-inline"><strong>Single nucleus transcriptome and chromatin accessibility of postmortem human pituitaries reveal diverse stem cell regulatory mechanisms</strong> <div class="csl-block">Zidong Zhang, Michel Zamojski, Gregory R Smith, Thea L Willis, Val Yianni, Natalia Mendelev, Hanna Pincas, Nitish Seenarine, Mary Anne S Amper, Mital Vasoya, … Frederique Ruf-Zamojski</div> <em>Cell Reports</em> (2022-03) <a href="https://doi.org/grcg62">https://doi.org/grcg62</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.celrep.2022.110467">10.1016/j.celrep.2022.110467</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/35263594">35263594</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8957708">PMC8957708</a></div></div>
</div>
<div id="ref-wv3oXzet" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">154. </div><div class="csl-right-inline"><strong>Integrative Analysis Identifies Candidate Tumor Microenvironment and Intracellular Signaling Pathways that Define Tumor Heterogeneity in NF1</strong> <div class="csl-block">Jineta Banerjee, Robert J Allaway, Jaclyn N Taroni, Aaron Baker, Xiaochun Zhang, Chang In Moon, Christine A Pratilas, Jaishri O Blakeley, Justin Guinney, Angela Hirbe, … Sara JC Gosline</div> <em>Genes</em> (2020-02-21) <a href="https://doi.org/gg4rbj">https://doi.org/gg4rbj</a> <div class="csl-block">DOI: <a href="https://doi.org/10.3390/genes11020226">10.3390/genes11020226</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32098059">32098059</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7073563">PMC7073563</a></div></div>
</div>
<div id="ref-k4efvKTD" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">155. </div><div class="csl-right-inline"><strong>Transcriptomic profiling of microglia and astrocytes throughout aging</strong> <div class="csl-block">Jie Pan, Nana Ma, Bo Yu, Wei Zhang, Jun Wan</div> <em>Journal of Neuroinflammation</em> (2020-04-01) <a href="https://doi.org/gjnx7s">https://doi.org/gjnx7s</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12974-020-01774-9">10.1186/s12974-020-01774-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32238175">32238175</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7115095">PMC7115095</a></div></div>
</div>
<div id="ref-Cl90EtTf" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">156. </div><div class="csl-right-inline"><strong>Spatiotemporal expression and transcriptional perturbations by long noncoding RNAs in the mouse brain</strong> <div class="csl-block">Loyal A Goff, Abigail F Groff, Martin Sauvageau, Zachary Trayes-Gibson, Diana B Sanchez-Gomez, Michael Morse, Ryan D Martin, Lara E Elcavage, Stephen C Liapis, Meryem Gonzalez-Celeiro, … John L Rinn</div> <em>Proceedings of the National Academy of Sciences</em> (2015-06) <a href="https://doi.org/f7fzxj">https://doi.org/f7fzxj</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1073/pnas.1411263112">10.1073/pnas.1411263112</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/26034286">26034286</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4460505">PMC4460505</a></div></div>
</div>
<div id="ref-sckOePLr" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">157. </div><div class="csl-right-inline"><strong>Ensembl 2021</strong> <div class="csl-block">Kevin L Howe, Premanand Achuthan, James Allen, Jamie Allen, Jorge Alvarez-Jarreta, MRidwan Amode, Irina M Armean, Andrey G Azov, Ruth Bennett, Jyothish Bhai, … Paul Flicek</div> <em>Nucleic Acids Research</em> (2020-11-02) <a href="https://doi.org/gk68s9">https://doi.org/gk68s9</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkaa942">10.1093/nar/gkaa942</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/33137190">33137190</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7778975">PMC7778975</a></div></div>
</div>
<div id="ref-9nz7bPGH" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">158. </div><div class="csl-right-inline"><strong>CellMarker: a manually curated resource of cell markers in human and mouse</strong> <div class="csl-block">Xinxin Zhang, Yujia Lan, Jinyuan Xu, Fei Quan, Erjie Zhao, Chunyu Deng, Tao Luo, Liwen Xu, Gaoming Liao, Min Yan, … Yun Xiao</div> <em>Nucleic Acids Research</em> (2018-10-05) <a href="https://doi.org/ggnktb">https://doi.org/ggnktb</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gky900">10.1093/nar/gky900</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/30289549">30289549</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323899">PMC6323899</a></div></div>
</div>
<div id="ref-Gout7oWo" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">159. </div><div class="csl-right-inline"><strong>The reactome pathway knowledgebase 2022</strong> <div class="csl-block">Marc Gillespie, Bijay Jassal, Ralf Stephan, Marija Milacic, Karen Rothfels, Andrea Senff-Ribeiro, Johannes Griss, Cristoffer Sevilla, Lisa Matthews, Chuqiao Gong, … Peter D’Eustachio</div> <em>Nucleic Acids Research</em> (2021-11-12) <a href="https://doi.org/gpm2r5">https://doi.org/gpm2r5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/nar/gkab1028">10.1093/nar/gkab1028</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/34788843">34788843</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8689983">PMC8689983</a></div></div>
</div>
<div id="ref-y5jlswEM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">160. </div><div class="csl-right-inline"><strong>Scikit-learn: Machine learning in Python</strong> <div class="csl-block">Fabian Pendregosa, Gael Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion</div> <em>The Journal of Machine Learning Research</em> (2011)</div>
</div>
<div id="ref-UeFCwwR7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">161. </div><div class="csl-right-inline"><strong>Controlling the False Discovery Rate: A Practical and Powerful Approach to Multiple Testing</strong> <div class="csl-block">Yoav Benjamini, Yosef Hochberg</div> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> (1995-01) <a href="https://doi.org/gfpkdx">https://doi.org/gfpkdx</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1111/j.2517-6161.1995.tb02031.x">10.1111/j.2517-6161.1995.tb02031.x</a></div></div>
</div>
<div id="ref-DngmXnbP" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">162. </div><div class="csl-right-inline"><strong>ADAGE signature analysis: differential expression analysis with data-defined gene sets</strong> <div class="csl-block">Jie Tan, Matthew Huyck, Dongbo Hu, René A Zelaya, Deborah A Hogan, Casey S Greene</div> <em>BMC Bioinformatics</em> (2017-11-22) <a href="https://doi.org/gg7m57">https://doi.org/gg7m57</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/s12859-017-1905-4">10.1186/s12859-017-1905-4</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/29166858">29166858</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5700673">PMC5700673</a></div></div>
</div>
<div id="ref-rKnVyOXF" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">163. </div><div class="csl-right-inline"><strong>The Effects of Nonlinear Signal on Expression-Based Prediction Performance</strong> <div class="csl-block">Benjamin J Heil, Jake Crawford, Casey S Greene</div> <em>Cold Spring Harbor Laboratory</em> (2022-06-26) <a href="https://doi.org/gqhgwk">https://doi.org/gqhgwk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/2022.06.22.497194">10.1101/2022.06.22.497194</a></div></div>
</div>
<div id="ref-62Q1rmv4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">164. </div><div class="csl-right-inline"><strong>Impact Factor Distortions</strong> <div class="csl-block">Bruce Alberts</div> <em>Science</em> (2013-05-17) <a href="https://doi.org/mjm">https://doi.org/mjm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.1240319">10.1126/science.1240319</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/23687012">23687012</a></div></div>
</div>
<div id="ref-Hw4ZDEnz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">165. </div><div class="csl-right-inline"><strong>Citation patterns in economics and beyond</strong> <div class="csl-block">Matthias Aistleitner, Jakob Kapeller, Stefan Steinerberger</div> <em>Science in Context</em> (2019-12) <a href="https://doi.org/gq62s8">https://doi.org/gq62s8</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1017/s0269889720000022">10.1017/s0269889720000022</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32202238">32202238</a></div></div>
</div>
<div id="ref-7n76ZZPt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">166. </div><div class="csl-right-inline"><strong>Disruptive papers published in Scientometrics: meaningful results by using an improved variant of the disruption index originally proposed by Wu, Wang, and Evans (2019)</strong> <div class="csl-block">Lutz Bornmann, Sitaram Devarakonda, Alexander Tekles, George Chacko</div> <em>Scientometrics</em> (2020-03-14) <a href="https://doi.org/ggzzxd">https://doi.org/ggzzxd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s11192-020-03406-8">10.1007/s11192-020-03406-8</a></div></div>
</div>
<div id="ref-3FJspt0W" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">167. </div><div class="csl-right-inline"><strong>Quantifying and suppressing ranking bias in a large citation network</strong> <div class="csl-block">Giacomo Vaccario, Matúš Medo, Nicolas Wider, Manuel Sebastian Mariani</div> <em>Journal of Informetrics</em> (2017-08) <a href="https://doi.org/gbzjdh">https://doi.org/gbzjdh</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.joi.2017.05.014">10.1016/j.joi.2017.05.014</a></div></div>
</div>
<div id="ref-15JxaxOiR" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">168. </div><div class="csl-right-inline"><strong>Quantitative evaluation of alternative field normalization procedures</strong> <div class="csl-block">Yunrong Li, Filippo Radicchi, Claudio Castellano, Javier Ruiz-Castillo</div> <em>Journal of Informetrics</em> (2013-07) <a href="https://doi.org/f48tvt">https://doi.org/f48tvt</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.joi.2013.06.001">10.1016/j.joi.2013.06.001</a></div></div>
</div>
<div id="ref-AkQLg7kt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">169. </div><div class="csl-right-inline"><strong>When a journal is both at the ‘top’ and the ‘bottom’: the illogicality of conflating citation-based metrics with quality</strong> <div class="csl-block">Shannon Mason, Lenandlar Singh</div> <em>Scientometrics</em> (2022-05-25) <a href="https://doi.org/gq2468">https://doi.org/gq2468</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s11192-022-04402-w">10.1007/s11192-022-04402-w</a></div></div>
</div>
<div id="ref-17UkkRswc" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">170. </div><div class="csl-right-inline"><strong>Field delineation using medical subject headings (MeSH)-An alternative way to aggregate data in the web of science</strong> <div class="csl-block">Håkan Carlsson, Ed CM Noyons</div> <em>12th International Conference on Scientometrics and Informetrics</em> (2009)</div>
</div>
<div id="ref-ErD8Jjn8" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">171. </div><div class="csl-right-inline"><strong>Cited references and Medical Subject Headings (MeSH) as two different knowledge representations: clustering and mappings at the paper level</strong> <div class="csl-block">Loet Leydesdorff, Jordan A Comins, Aaron A Sorensen, Lutz Bornmann, Iina Hellsten</div> <em>Scientometrics</em> (2016-10-08) <a href="https://doi.org/gc8zk4">https://doi.org/gc8zk4</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s11192-016-2119-7">10.1007/s11192-016-2119-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/27942085">27942085</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5124055">PMC5124055</a></div></div>
</div>
<div id="ref-1GphepDNl" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">172. </div><div class="csl-right-inline"><strong>A robust DNA mechanical device controlled by hybridization topology</strong> <div class="csl-block">Hao Yan, Xiaoping Zhang, Zhiyong Shen, Nadrian C Seeman</div> <em>Nature</em> (2002-01) <a href="https://doi.org/czh8hg">https://doi.org/czh8hg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/415062a">10.1038/415062a</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11780115">11780115</a></div></div>
</div>
<div id="ref-NmOwHa9H" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">173. </div><div class="csl-right-inline"><strong>Bioadhesive poly(methyl methacrylate) microdevices for controlled drug delivery</strong> <div class="csl-block">Sarah L Tao, Michael W Lubeley, Tejal A Desai</div> <em>Journal of Controlled Release</em> (2003-03) <a href="https://doi.org/c7fpg4">https://doi.org/c7fpg4</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/s0168-3659(03)00005-1">10.1016/s0168-3659(03)00005-1</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12628329">12628329</a></div></div>
</div>
<div id="ref-IkV2K836" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">174. </div><div class="csl-right-inline"><strong>DNA-Templated Self-Assembly of Protein Arrays and Highly Conductive Nanowires</strong> <div class="csl-block">Hao Yan, Sung Ha Park, Gleb Finkelstein, John H Reif, Thomas H LaBean</div> <em>Science</em> (2003-09-26) <a href="https://doi.org/bfgvgf">https://doi.org/bfgvgf</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.1089389">10.1126/science.1089389</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14512621">14512621</a></div></div>
</div>
<div id="ref-19ryujP9j" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">175. </div><div class="csl-right-inline"><strong>Photostable Luminescent Nanoparticles as Biological Label for Cell Recognition of System Lupus Erythematosus Patients</strong> <div class="csl-block">Xiaoxiao He, Kemin Wang, Weihong Tan, Jun Li, Xiaohai Yang, Shasheng Huang, Dan Xiao</div> <em>Journal of Nanoscience and Nanotechnology</em> (2002-07-01) <a href="https://doi.org/dcj5cg">https://doi.org/dcj5cg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1166/jnn.2002.105">10.1166/jnn.2002.105</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12908257">12908257</a></div></div>
</div>
<div id="ref-11usgA4JE" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">176. </div><div class="csl-right-inline"><strong>WSXM: A software for scanning probe microscopy and a tool for nanotechnology</strong> <div class="csl-block">I Horcas, R Fernández, JM Gómez-Rodríguez, J Colchero, J Gómez-Herrero, AM Baro</div> <em>Review of Scientific Instruments</em> (2007-01) <div class="csl-block">DOI: <a href="https://doi.org/10.1063/1.2432410">10.1063/1.2432410</a></div></div>
</div>
<div id="ref-JJ2LW0nT" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">177. </div><div class="csl-right-inline"><strong>Measuring Distances in Supported Bilayers by Fluorescence Interference-Contrast Microscopy: Polymer Supports and SNARE Proteins</strong> <div class="csl-block">Volker Kiessling, Lukas K Tamm</div> <em>Biophysical Journal</em> (2003-01) <a href="https://doi.org/dqsg2c">https://doi.org/dqsg2c</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/s0006-3495(03)74861-9">10.1016/s0006-3495(03)74861-9</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12524294">12524294</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1302622">PMC1302622</a></div></div>
</div>
<div id="ref-NkJaVLEB" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">178. </div><div class="csl-right-inline"><strong>Toward fluorescence nanoscopy</strong> <div class="csl-block">Stefan W Hell</div> <em>Nature Biotechnology</em> (2003-10-31) <a href="https://doi.org/dnzt3b">https://doi.org/dnzt3b</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1038/nbt895">10.1038/nbt895</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14595362">14595362</a></div></div>
</div>
<div id="ref-18Ot4SCqv" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">179. </div><div class="csl-right-inline"><strong>In Vivo Imaging of Quantum Dots Encapsulated in Phospholipid Micelles</strong> <div class="csl-block">Benoit Dubertret, Paris Skourides, David J Norris, Vincent Noireaux, Ali H Brivanlou, Albert Libchaber</div> <em>Science</em> (2002-11-29) <a href="https://doi.org/dd6sqp">https://doi.org/dd6sqp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.1077194">10.1126/science.1077194</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12459582">12459582</a></div></div>
</div>
<div id="ref-dYAYQycA" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">180. </div><div class="csl-right-inline"><strong>Water-Soluble Quantum Dots for Multiphoton Fluorescence Imaging in Vivo</strong> <div class="csl-block">Daniel R Larson, Warren R Zipfel, Rebecca M Williams, Stephen W Clark, Marcel P Bruchez, Frank W Wise, Watt W Webb</div> <em>Science</em> (2003-05-30) <a href="https://doi.org/cn9j76">https://doi.org/cn9j76</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.1083780">10.1126/science.1083780</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/12775841">12775841</a></div></div>
</div>
<div id="ref-dqAv5O5b" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">181. </div><div class="csl-right-inline"><strong>Immunoelectron microscopic exploration of the Golgi complex.</strong> <div class="csl-block">JW Slot, HJ Geuze</div> <em>Journal of Histochemistry &amp; Cytochemistry</em> (1983-08) <a href="https://doi.org/dxxzxg">https://doi.org/dxxzxg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1177/31.8.6863900">10.1177/31.8.6863900</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/6863900">6863900</a></div></div>
</div>
<div id="ref-nMCUqTIP" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">182. </div><div class="csl-right-inline"><strong>Immunocytochemical and electrophoretic analyses of changes in myosin gene expression in cat posterior temporalis muscle during postnatal development</strong> <div class="csl-block">JFY Hoh, S Hughes, C Chow, PT Hale, RB Fitzsimons</div> <em>Journal of Muscle Research and Cell Motility</em> (1988-02) <a href="https://doi.org/d72278">https://doi.org/d72278</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/bf01682147">10.1007/bf01682147</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/3392187">3392187</a></div></div>
</div>
<div id="ref-1BGliKdI9" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">183. </div><div class="csl-right-inline"><strong>Electron microscopic demonstration of calcitonin in human medullary carcinoma of thyroid by the immuno gold staining method</strong> <div class="csl-block">J Dämmrich, W Ormanns, R Schäffer</div> <em>Histochemistry</em> (1984) <a href="https://doi.org/ct253c">https://doi.org/ct253c</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/bf00514331">10.1007/bf00514331</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/6511490">6511490</a></div></div>
</div>
<div id="ref-sc5wklkt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">184. </div><div class="csl-right-inline"><strong>Grafting genetically modified cells into the rat brain: characteristics of E. coli β-galactosidase as a reporter gene</strong> <div class="csl-block">S Shimohama, MB Rosenberg, AM Fagan, JA Wolff, MP Short, XO Breakefield, T Friedmann, FH Gage</div> <em>Molecular Brain Research</em> (1989-06) <a href="https://doi.org/dptnbm">https://doi.org/dptnbm</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/0169-328x(89)90061-2">10.1016/0169-328x(89)90061-2</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/2501628">2501628</a></div></div>
</div>
<div id="ref-TnowewWM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">185. </div><div class="csl-right-inline"><strong>Vitamin-D-dependent calcium-binding-protein and parvalbumin occur in bones and teeth</strong> <div class="csl-block">MR Celio, AW Norman, CW Heizmann</div> <em>Calcified Tissue International</em> (1984-12) <a href="https://doi.org/fdnfdg">https://doi.org/fdnfdg</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/bf02405306">10.1007/bf02405306</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/6423230">6423230</a></div></div>
</div>
<div id="ref-CBI8FXe4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">186. </div><div class="csl-right-inline"><strong>Mapping of brain areas containing RNA homologous to cDNAs encoding the alpha and beta subunits of the rat GABAA gamma-aminobutyrate receptor.</strong> <div class="csl-block">JM Séquier, JG Richards, P Malherbe, GW Price, S Mathews, H Möhler</div> <em>Proceedings of the National Academy of Sciences</em> (1988-10) <a href="https://doi.org/fv2p49">https://doi.org/fv2p49</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1073/pnas.85.20.7815">10.1073/pnas.85.20.7815</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/2845424">2845424</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC282284">PMC282284</a></div></div>
</div>
<div id="ref-4bdivZyz" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">187. </div><div class="csl-right-inline"><strong>Studies of the HER-2/neu Proto-Oncogene in Human Breast and Ovarian Cancer</strong> <div class="csl-block">Dennis J Slamon, William Godolphin, Lovell A Jones, John A Holt, Steven G Wong, Duane E Keith, Wendy J Levin, Susan G Stuart, Judy Udove, Axel Ullrich, Michael F Press</div> <em>Science</em> (1989-05-12) <a href="https://doi.org/cngtqx">https://doi.org/cngtqx</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.2470152">10.1126/science.2470152</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/2470152">2470152</a></div></div>
</div>
<div id="ref-hLSwKASj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">188. </div><div class="csl-right-inline"><strong>Expression of c-fos Protein in Brain: Metabolic Mapping at the Cellular Level</strong> <div class="csl-block">SM Sagar, FR Sharp, T Curran</div> <em>Science</em> (1988-06-03) <a href="https://doi.org/b39h2t">https://doi.org/b39h2t</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.3131879">10.1126/science.3131879</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/3131879">3131879</a></div></div>
</div>
<div id="ref-qVEHb5K" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">189. </div><div class="csl-right-inline"><strong>Proteomics Standards Initiative: Fifteen Years of Progress and Future Work</strong> <div class="csl-block">Eric W Deutsch, Sandra Orchard, Pierre-Alain Binz, Wout Bittremieux, Martin Eisenacher, Henning Hermjakob, Shin Kawano, Henry Lam, Gerhard Mayer, Gerben Menschaert, … Andrew R Jones</div> <em>Journal of Proteome Research</em> (2017-09-15) <a href="https://doi.org/gbw99d">https://doi.org/gbw99d</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1021/acs.jproteome.7b00370">10.1021/acs.jproteome.7b00370</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28849660">28849660</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5715286">PMC5715286</a></div></div>
</div>
<div id="ref-MVZ9xwhJ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">190. </div><div class="csl-right-inline"><strong>Limited Environmental Serine and Glycine Confer Brain Metastasis Sensitivity to PHGDH Inhibition</strong> <div class="csl-block">Bryan Ngo, Eugenie Kim, Victoria Osorio-Vasquez, Sophia Doll, Sophia Bustraan, Roger J Liang, Alba Luengo, Shawn M Davidson, Ahmed Ali, Gino B Ferraro, … Michael E Pacold</div> <em>Cancer Discovery</em> (2020-09-01) <a href="https://doi.org/ghf85j">https://doi.org/ghf85j</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1158/2159-8290.cd-19-1228">10.1158/2159-8290.cd-19-1228</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32571778">32571778</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7483776">PMC7483776</a></div></div>
</div>
<div id="ref-197hbKiL0" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">191. </div><div class="csl-right-inline"><strong>A high-throughput processing service for retention time alignment of complex proteomics and metabolomics LC-MS data</strong> <div class="csl-block">Isthiaq Ahmad, Frank Suits, Berend Hoekman, Morris A Swertz, Heorhiy Byelas, Martijn Dijkstra, Rob Hooft, Dmitry Katsubo, Bas van Breukelen, Rainer Bischoff, Peter Horvatovich</div> <em>Bioinformatics</em> (2011-02-23) <a href="https://doi.org/cxsszv">https://doi.org/cxsszv</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btr094">10.1093/bioinformatics/btr094</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21349866">21349866</a></div></div>
</div>
<div id="ref-EvwvRYzE" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">192. </div><div class="csl-right-inline"><strong>MeltDB: a software platform for the analysis and integration of metabolomics experiment data</strong> <div class="csl-block">Heiko Neuweger, Stefan P Albaum, Michael Dondrup, Marcus Persicke, Tony Watt, Karsten Niehaus, Jens Stoye, Alexander Goesmann</div> <em>Bioinformatics</em> (2008-09-02) <a href="https://doi.org/fds6vt">https://doi.org/fds6vt</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1093/bioinformatics/btn452">10.1093/bioinformatics/btn452</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/18765459">18765459</a></div></div>
</div>
<div id="ref-vNOeEVfp" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">193. </div><div class="csl-right-inline"><strong>In silico fragmentation for computer assisted identification of metabolite mass spectra</strong> <div class="csl-block">Sebastian Wolf, Stephan Schmidt, Matthias Müller-Hannemann, Steffen Neumann</div> <em>BMC Bioinformatics</em> (2010-03-22) <a href="https://doi.org/d7gpf5">https://doi.org/d7gpf5</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1186/1471-2105-11-148">10.1186/1471-2105-11-148</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/20307295">20307295</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2853470">PMC2853470</a></div></div>
</div>
<div id="ref-UQbCNqUe" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">194. </div><div class="csl-right-inline"><strong>The Metabonomic Signature of Celiac Disease</strong> <div class="csl-block">Ivano Bertini, Antonio Calabrò, Valeria De Carli, Claudio Luchinat, Stefano Nepi, Berardino Porfirio, Daniela Renzi, Edoardo Saccenti, Leonardo Tenori</div> <em>Journal of Proteome Research</em> (2008-12-11) <a href="https://doi.org/c6sdnp">https://doi.org/c6sdnp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1021/pr800548z">10.1021/pr800548z</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/19072164">19072164</a></div></div>
</div>
<div id="ref-vJbGwiV7" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">195. </div><div class="csl-right-inline"><strong>FunRich: An open access standalone functional enrichment and interaction network analysis tool</strong> <div class="csl-block">Mohashin Pathan, Shivakumar Keerthikumar, Ching-Seng Ang, Lahiru Gangoda, Camelia YJ Quek, Nicholas A Williamson, Dmitri Mouradov, Oliver M Sieber, Richard J Simpson, Agus Salim, … Suresh Mathivanan</div> <em>PROTEOMICS</em> (2015-06-17) <a href="https://doi.org/f278rp">https://doi.org/f278rp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1002/pmic.201400515">10.1002/pmic.201400515</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/25921073">25921073</a></div></div>
</div>
<div id="ref-sc8DMTGM" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">196. </div><div class="csl-right-inline"><strong>Proteomic and Metabolomic Characterization of COVID-19 Patient Sera</strong> <div class="csl-block">Bo Shen, Xiao Yi, Yaoting Sun, Xiaojie Bi, Juping Du, Chao Zhang, Sheng Quan, Fangfei Zhang, Rui Sun, Liujia Qian, … Tiannan Guo</div> <em>Cell</em> (2020-07) <a href="https://doi.org/gg2cck">https://doi.org/gg2cck</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.cell.2020.05.032">10.1016/j.cell.2020.05.032</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32492406">32492406</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7254001">PMC7254001</a></div></div>
</div>
<div id="ref-VvZTjIen" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">197. </div><div class="csl-right-inline"><strong>Development of Human Protein Reference Database as an Initial Platform for Approaching Systems Biology in Humans</strong> <div class="csl-block">Suraj Peri, JDaniel Navarro, Ramars Amanchy, Troels Z Kristiansen, Chandra Kiran Jonnalagadda, Vineeth Surendranath, Vidya Niranjan, Babylakshmi Muthusamy, TKB Gandhi, Mads Gronborg, … Akhilesh Pandey</div> <em>Genome Research</em> (2003-10) <a href="https://doi.org/bc8cnv">https://doi.org/bc8cnv</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1101/gr.1680803">10.1101/gr.1680803</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/14525934">14525934</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC403728">PMC403728</a></div></div>
</div>
<div id="ref-C4NTSwn4" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">198. </div><div class="csl-right-inline"><strong>A database for post-genome analysis</strong> <div class="csl-block">Minoru Kanehisa</div> <em>Trends in Genetics</em> (1997-09) <a href="https://doi.org/cfgb98">https://doi.org/cfgb98</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/s0168-9525(97)01223-7">10.1016/s0168-9525(97)01223-7</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/9287494">9287494</a></div></div>
</div>
<div id="ref-G2ZiZdRY" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">199. </div><div class="csl-right-inline"><strong>Use of mass spectrometry-derived data to annotate nucleotide and protein sequence databases</strong> <div class="csl-block">Matthias Mann, Akhilesh Pandey</div> <em>Trends in Biochemical Sciences</em> (2001-01) <a href="https://doi.org/ch565r">https://doi.org/ch565r</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/s0968-0004(00)01726-6">10.1016/s0968-0004(00)01726-6</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/11165518">11165518</a></div></div>
</div>
<div id="ref-mcDRypJj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">200. </div><div class="csl-right-inline"><strong>Genetic Discrimination: Perspectives of Consumers</strong> <div class="csl-block">EVirginia Lapham, Chahira Kozma, Joan O Weiss</div> <em>Science</em> (1996-10-25) <a href="https://doi.org/df7k88">https://doi.org/df7k88</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.274.5287.621">10.1126/science.274.5287.621</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/8849455">8849455</a></div></div>
</div>
<div id="ref-aFgNUM13" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">201. </div><div class="csl-right-inline"><strong>Committee Opinion No. 690: Carrier Screening in the Age of Genomic Medicine</strong> <div class="csl-block">Obstetrics &amp; Gynecology</div> <em>Ovid Technologies (Wolters Kluwer Health)</em> (2017-03) <a href="https://doi.org/f92g56">https://doi.org/f92g56</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1097/aog.0000000000001951">10.1097/aog.0000000000001951</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/28225425">28225425</a></div></div>
</div>
<div id="ref-Msb0hwgj" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">202. </div><div class="csl-right-inline"><strong>Public health genomics: The end of the beginning</strong> <div class="csl-block">Muin J Khoury</div> <em>Genetics in Medicine</em> (2011-03) <a href="https://doi.org/bjsxzk">https://doi.org/bjsxzk</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1097/gim.0b013e31821024ca">10.1097/gim.0b013e31821024ca</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/21311338">21311338</a></div></div>
</div>
<div id="ref-7ZlRSgYT" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">203. </div><div class="csl-right-inline"><strong>An STS-Based Map of the Human Genome</strong> <div class="csl-block">Thomas J Hudson, Lincoln D Stein, Sebastian S Gerety, Junli Ma, Andrew B Castle, James Silva, Donna K Slonim, Rafael Baptista, Leonid Kruglyak, Shu-Hua Xu, … Eric S Lander</div> <em>Science</em> (1995-12-22) <a href="https://doi.org/ftf">https://doi.org/ftf</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.270.5244.1945">10.1126/science.270.5244.1945</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/8533086">8533086</a></div></div>
</div>
<div id="ref-153eZYSdV" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">204. </div><div class="csl-right-inline"><strong>A New Five-Year Plan for the U.S. Human Genome Project</strong> <div class="csl-block">Francis Collins, David Galas</div> <em>Science</em> (1993-10) <a href="https://doi.org/fwkrnb">https://doi.org/fwkrnb</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1126/science.8211127">10.1126/science.8211127</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/8211127">8211127</a></div></div>
</div>
<div id="ref-To1WoeSQ" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">205. </div><div class="csl-right-inline"><strong>A simple Havel-Hakimi type algorithm to realize graphical degree sequences of directed graphs</strong> <div class="csl-block">Péter L Erdős, István Miklós, Zoltán Toroczkai</div> <em>arXiv</em> (2010-01-21) <a href="https://arxiv.org/abs/0905.4913">https://arxiv.org/abs/0905.4913</a></div>
</div>
<div id="ref-15wNo6JtP" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">206. </div><div class="csl-right-inline"><strong>Exploring Network Structure, Dynamics, and Function using NetworkX</strong> <div class="csl-block">Aric A Hagberg, Daniel A Schult, Pieter J Swart</div> <em>Proceedings of the 7th Python in Science conference</em> (2008)</div>
</div>
<div id="ref-hJ4Xxryu" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">207. </div><div class="csl-right-inline"><strong>Topic-based Pagerank: toward a topic-level scientific evaluation</strong> <div class="csl-block">Erjia Yan</div> <em>Scientometrics</em> (2014-05-06) <a href="https://doi.org/f6br99">https://doi.org/f6br99</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1007/s11192-014-1308-5">10.1007/s11192-014-1308-5</a></div></div>
</div>
<div id="ref-o78W9pGh" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">208. </div><div class="csl-right-inline"><strong>A bird’s-eye view of deep learning in bioimage analysis</strong> <div class="csl-block">Erik Meijering</div> <em>Computational and Structural Biotechnology Journal</em> (2020) <a href="https://doi.org/gk5mtd">https://doi.org/gk5mtd</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1016/j.csbj.2020.08.003">10.1016/j.csbj.2020.08.003</a> · PMID: <a href="https://www.ncbi.nlm.nih.gov/pubmed/32994890">32994890</a> · PMCID: <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7494605">PMC7494605</a></div></div>
</div>
<div id="ref-lt4BNUoG" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">209. </div><div class="csl-right-inline"><strong>ImageNet: A large-scale hierarchical image database</strong> <div class="csl-block">Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei</div> <em>2009 IEEE Conference on Computer Vision and Pattern Recognition</em> (2009-06) <a href="https://doi.org/cvc7xp">https://doi.org/cvc7xp</a> <div class="csl-block">DOI: <a href="https://doi.org/10.1109/cvpr.2009.5206848">10.1109/cvpr.2009.5206848</a></div></div>
</div>
<div id="ref-XVMFUrSt" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">210. </div><div class="csl-right-inline"><strong>Training Compute-Optimal Large Language Models</strong> <div class="csl-block">Jordan Hoffmann, Sebastian Borgeaud, Arthur Mensch, Elena Buchatskaya, Trevor Cai, Eliza Rutherford, Diego de Las Casas, Lisa Anne Hendricks, Johannes Welbl, Aidan Clark, … Laurent Sifre</div> <em>arXiv</em> (2022-03-30) <a href="https://arxiv.org/abs/2203.15556">https://arxiv.org/abs/2203.15556</a></div>
</div>
</div>
<!-- default theme -->

<style>
  /* import google fonts */
  @import url("https://fonts.googleapis.com/css?family=Open+Sans:400,600,700");
  @import url("https://fonts.googleapis.com/css?family=Source+Code+Pro");

  /* -------------------------------------------------- */
  /* global */
  /* -------------------------------------------------- */

  /* all elements */
  * {
    /* force sans-serif font unless specified otherwise */
    font-family: "Open Sans", "Helvetica", sans-serif;

    /* prevent text inflation on some mobile browsers */
    -webkit-text-size-adjust: none !important;
    -moz-text-size-adjust: none !important;
    -o-text-size-adjust: none !important;
    text-size-adjust: none !important;
  }

  @media only screen {
    /* "page" element */
    body {
      position: relative;
      box-sizing: border-box;
      font-size: 12pt;
      line-height: 1.5;
      max-width: 8.5in;
      margin: 20px auto;
      padding: 40px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* "page" element */
    body {
      padding: 20px;
      margin: 0;
      border-radius: 0;
      border: none;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05) inset;
      background: none;
    }
  }

  /* -------------------------------------------------- */
  /* headings */
  /* -------------------------------------------------- */

  /* all headings */
  h1,
  h2,
  h3,
  h4,
  h5,
  h6 {
    margin: 20px 0;
    padding: 0;
    font-weight: bold;
  }

  /* biggest heading */
  h1 {
    margin: 40px 0;
    text-align: center;
  }

  /* second biggest heading */
  h2 {
    margin-top: 30px;
    padding-bottom: 5px;
    border-bottom: solid 1px #bdbdbd;
  }

  /* heading font sizes */
  h1 {
    font-size: 2em;
  }
  h2 {
    font-size: 1.5em;
  }
  h3 {
    font-size: 1.35em;
  }
  h4 {
    font-size: 1.25em;
  }
  h5 {
    font-size: 1.15em;
  }
  h6 {
    font-size: 1em;
  }

  /* -------------------------------------------------- */
  /* manuscript header */
  /* -------------------------------------------------- */

  /* manuscript title */
  header > h1 {
    margin: 0;
  }

  /* manuscript title caption text (ie "automatically generated on") */
  header + p {
    text-align: center;
    margin-top: 10px;
  }

  /* -------------------------------------------------- */
  /* text elements */
  /* -------------------------------------------------- */

  /* links */
  a {
    color: #2196f3;
    overflow-wrap: break-word;
  }

  /* superscripts and subscripts */
  sub,
  sup {
    /* prevent from affecting line height */
    line-height: 0;
  }

  /* unordered and ordered lists*/
  ul,
  ol {
    padding-left: 20px;
  }

  /* class for styling text semibold */
  .semibold {
    font-weight: 600;
  }

  /* class for styling elements horizontally left aligned */
  .left {
    display: block;
    text-align: left;
    margin-left: auto;
    margin-right: 0;
    justify-content: left;
  }

  /* class for styling elements horizontally centered */
  .center {
    display: block;
    text-align: center;
    margin-left: auto;
    margin-right: auto;
    justify-content: center;
  }

  /* class for styling elements horizontally right aligned */
  .right {
    display: block;
    text-align: right;
    margin-left: 0;
    margin-right: auto;
    justify-content: right;
  }

  /* -------------------------------------------------- */
  /* section elements */
  /* -------------------------------------------------- */

  /* horizontal divider line */
  hr {
    border: none;
    height: 1px;
    background: #bdbdbd;
  }

  /* paragraphs, horizontal dividers, figures, tables, code */
  p,
  hr,
  figure,
  table,
  pre {
    /* treat all as "paragraphs", with consistent vertical margins */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* figures */
  /* -------------------------------------------------- */

  /* figure */
  figure {
    max-width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure caption */
  figcaption {
    padding: 0;
    padding-top: 10px;
  }

  /* figure image element */
  figure > img,
  figure > svg {
    max-width: 100%;
    display: block;
    margin-left: auto;
    margin-right: auto;
  }

  /* figure auto-number */
  img + figcaption > span:first-of-type,
  svg + figcaption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* tables */
  /* -------------------------------------------------- */

  /* table */
  table {
    border-collapse: collapse;
    border-spacing: 0;
    width: 100%;
    margin-left: auto;
    margin-right: auto;
  }

  /* table cells */
  th,
  td {
    border: solid 1px #bdbdbd;
    padding: 10px;
    /* squash table if too wide for page by forcing line breaks */
    overflow-wrap: break-word;
    word-break: break-word;
  }

  /* header row and even rows */
  th,
  tr:nth-child(2n) {
    background-color: #fafafa;
  }

  /* odd rows */
  tr:nth-child(2n + 1) {
    background-color: #ffffff;
  }

  /* table caption */
  caption {
    text-align: left;
    padding: 0;
    padding-bottom: 10px;
  }

  /* table auto-number */
  table > caption > span:first-of-type {
    font-weight: bold;
    margin-right: 5px;
  }

  /* -------------------------------------------------- */
  /* code */
  /* -------------------------------------------------- */

  /* multi-line code block */
  pre {
    padding: 10px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
    break-inside: avoid;
    text-align: left;
  }

  /* inline code, ie code within normal text */
  :not(pre) > code {
    padding: 0 4px;
    background-color: #eeeeee;
    color: #000000;
    border-radius: 5px;
  }

  /* code text */
  /* apply all children, to reach syntax highlighting sub-elements */
  code,
  code * {
    /* force monospace font */
    font-family: "Source Code Pro", "Courier New", monospace;
  }

  /* -------------------------------------------------- */
  /* quotes */
  /* -------------------------------------------------- */

  /* quoted text */
  blockquote {
    margin: 0;
    padding: 0;
    border-left: 4px solid #bdbdbd;
    padding-left: 16px;
    break-inside: avoid;
  }

  /* -------------------------------------------------- */
  /* banners */
  /* -------------------------------------------------- */

  /* info banners */
  .banner {
    box-sizing: border-box;
    display: block;
    position: relative;
    width: 100%;
    margin-top: 20px;
    margin-bottom: 20px;
    padding: 20px;
    text-align: center;
  }

  /* paragraph in banner */
  .banner > p {
    margin: 0;
  }

  /* -------------------------------------------------- */
  /* highlight colors */
  /* -------------------------------------------------- */

  .white {
    background: #ffffff;
  }
  .lightgrey {
    background: #eeeeee;
  }
  .grey {
    background: #757575;
  }
  .darkgrey {
    background: #424242;
  }
  .black {
    background: #000000;
  }
  .lightred {
    background: #ffcdd2;
  }
  .lightyellow {
    background: #ffecb3;
  }
  .lightgreen {
    background: #dcedc8;
  }
  .lightblue {
    background: #e3f2fd;
  }
  .lightpurple {
    background: #f3e5f5;
  }
  .red {
    background: #f44336;
  }
  .orange {
    background: #ff9800;
  }
  .yellow {
    background: #ffeb3b;
  }
  .green {
    background: #4caf50;
  }
  .blue {
    background: #2196f3;
  }
  .purple {
    background: #9c27b0;
  }
  .white,
  .lightgrey,
  .lightred,
  .lightyellow,
  .lightgreen,
  .lightblue,
  .lightpurple,
  .orange,
  .yellow,
  .white a,
  .lightgrey a,
  .lightred a,
  .lightyellow a,
  .lightgreen a,
  .lightblue a,
  .lightpurple a,
  .orange a,
  .yellow a {
    color: #000000;
  }
  .grey,
  .darkgrey,
  .black,
  .red,
  .green,
  .blue,
  .purple,
  .grey a,
  .darkgrey a,
  .black a,
  .red a,
  .green a,
  .blue a,
  .purple a {
    color: #ffffff;
  }

  /* -------------------------------------------------- */
  /* buttons */
  /* -------------------------------------------------- */

  /* class for styling links like buttons */
  .button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    margin: 5px;
    padding: 10px 20px;
    font-size: 0.75em;
    font-weight: 600;
    text-transform: uppercase;
    text-decoration: none;
    letter-spacing: 1px;
    background: none;
    color: #2196f3;
    border: solid 1px #bdbdbd;
    border-radius: 5px;
  }

  /* buttons when hovered */
  .button:hover:not([disabled]),
  .icon_button:hover:not([disabled]) {
    cursor: pointer;
    background: #f5f5f5;
  }

  /* buttons when disabled */
  .button[disabled],
  .icon_button[disabled] {
    opacity: 0.35;
    pointer-events: none;
  }

  /* class for styling buttons containg only single icon */
  .icon_button {
    display: inline-flex;
    justify-content: center;
    align-items: center;
    text-decoration: none;
    margin: 0;
    padding: 0;
    background: none;
    border-radius: 5px;
    border: none;
    width: 20px;
    height: 20px;
    min-width: 20px;
    min-height: 20px;
  }

  /* icon button inner svg image */
  .icon_button > svg {
    height: 16px;
  }

  /* -------------------------------------------------- */
  /* icons */
  /* -------------------------------------------------- */

  /* class for styling icons inline with text */
  .inline_icon {
    height: 1em;
    position: relative;
    top: 0.125em;
  }

  /* -------------------------------------------------- */
  /* references */
  /* -------------------------------------------------- */

  .csl-entry {
    margin-top: 15px;
    margin-bottom: 15px;
  }

  /* -------------------------------------------------- */
  /* print control */
  /* -------------------------------------------------- */

  @media print {
    @page {
      /* suggested printing margin */
      margin: 0.5in;
    }

    /* document and "page" elements */
    html,
    body {
      margin: 0;
      padding: 0;
      width: 100%;
      height: 100%;
    }

    /* "page" element */
    body {
      font-size: 11pt !important;
      line-height: 1.35;
    }

    /* all headings */
    h1,
    h2,
    h3,
    h4,
    h5,
    h6 {
      margin: 15px 0;
    }

    /* figures and tables */
    figure,
    table {
      font-size: 0.85em;
    }

    /* table cells */
    th,
    td {
      padding: 5px;
    }

    /* shrink font awesome icons */
    i.fas,
    i.fab,
    i.far,
    i.fal {
      transform: scale(0.85);
    }

    /* decrease banner margins */
    .banner {
      margin-top: 15px;
      margin-bottom: 15px;
      padding: 15px;
    }

    /* class for centering an element vertically on its own page */
    .page_center {
      margin: auto;
      width: 100%;
      height: 100%;
      display: flex;
      align-items: center;
      vertical-align: middle;
      break-before: page;
      break-after: page;
    }

    /* always insert a page break before the element */
    .page_break_before {
      break-before: page;
    }

    /* always insert a page break after the element */
    .page_break_after {
      break-after: page;
    }

    /* avoid page break before the element */
    .page_break_before_avoid {
      break-before: avoid;
    }

    /* avoid page break after the element */
    .page_break_after_avoid {
      break-after: avoid;
    }

    /* avoid page break inside the element */
    .page_break_inside_avoid {
      break-inside: avoid;
    }
  }

  /* -------------------------------------------------- */
  /* override pandoc css quirks */
  /* -------------------------------------------------- */

  .sourceCode {
    /* prevent unsightly overflow in wide code blocks */
    overflow: auto !important;
  }

  div.sourceCode {
    /* prevent background fill on top-most code block  container */
    background: none !important;
  }

  .sourceCode * {
    /* force consistent line spacing */
    line-height: 1.5 !important;
  }

  div.sourceCode {
    /* style code block margins same as <pre> element */
    margin-top: 20px;
    margin-bottom: 20px;
  }

  /* -------------------------------------------------- */
  /* tablenos */
  /* -------------------------------------------------- */

  /* tablenos wrapper */
  .tablenos {
    width: 100%;
    margin: 20px 0;
  }

  .tablenos > table {
    /* move margins from table to table_wrapper to allow margin collapsing */
    margin: 0;
  }

  @media only screen {
    /* tablenos wrapper */
    .tablenos {
      /* show scrollbar on tables if necessary to prevent overflow */
      overflow-x: auto !important;
    }

    .tablenos th,
    .tablenos td {
      overflow-wrap: unset !important;
      word-break: unset !important;
    }

    /* table in wrapper */
    .tablenos table,
    .tablenos table * {
      /* don't break table words */
      overflow-wrap: normal !important;
    }
  }
</style>
<!-- 
    Plugin Core

    Functions needed for and shared across all first-party plugins.
-->

<script>
  // get element that is target of hash (from link element or url)
  function getHashTarget(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector(`[id="${id}"]`);
    if (!target) return;

    // if figure or table, modify target to get expected element
    if (id.indexOf("fig:") === 0) target = target.querySelector("figure");
    if (id.indexOf("tbl:") === 0) target = target.querySelector("table");

    return target;
  }

  // get position/dimensions of element or viewport
  function getRectInView(element) {
    let rect = {};
    rect.left = 0;
    rect.top = 0;
    rect.right = document.documentElement.clientWidth;
    rect.bottom = document.documentElement.clientHeight;
    let style = {};

    if (element instanceof HTMLElement) {
      rect = element.getBoundingClientRect();
      style = window.getComputedStyle(element);
    }

    const margin = {};
    margin.left = parseFloat(style.marginLeftWidth) || 0;
    margin.top = parseFloat(style.marginTopWidth) || 0;
    margin.right = parseFloat(style.marginRightWidth) || 0;
    margin.bottom = parseFloat(style.marginBottomWidth) || 0;

    const border = {};
    border.left = parseFloat(style.borderLeftWidth) || 0;
    border.top = parseFloat(style.borderTopWidth) || 0;
    border.right = parseFloat(style.borderRightWidth) || 0;
    border.bottom = parseFloat(style.borderBottomWidth) || 0;

    const newRect = {};
    newRect.left = rect.left + margin.left + border.left;
    newRect.top = rect.top + margin.top + border.top;
    newRect.right = rect.right + margin.right + border.right;
    newRect.bottom = rect.bottom + margin.bottom + border.bottom;
    newRect.width = newRect.right - newRect.left;
    newRect.height = newRect.bottom - newRect.top;

    return newRect;
  }

  // get position of element relative to page
  function getRectInPage(element) {
    const rect = getRectInView(element);
    const body = getRectInView(document.body);

    const newRect = {};
    newRect.left = rect.left - body.left;
    newRect.top = rect.top - body.top;
    newRect.right = rect.right - body.left;
    newRect.bottom = rect.bottom - body.top;
    newRect.width = rect.width;
    newRect.height = rect.height;

    return newRect;
  }

  // get closest element before specified element that matches query
  function firstBefore(element, query) {
    while (element && element !== document.body && !element.matches(query))
      element = element.previousElementSibling || element.parentNode;

    return element;
  }

  // check if element is part of collapsed heading
  function isCollapsed(element) {
    while (element && element !== document.body) {
      if (element.dataset.collapsed === "true") return true;
      element = element.parentNode;
    }
    return false;
  }

  // expand any collapsed parent containers of element if necessary
  function expandElement(element) {
    if (isCollapsed(element)) {
      // accordion plugin
      const heading = firstBefore(element, "h2");
      if (heading) heading.click();
      // details/summary HTML element
      const summary = firstBefore(element, "summary");
      if (summary) summary.click();
    }
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);

    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // get list of elements after a start element up to element matching query
  function nextUntil(element, query, exclude) {
    const elements = [];
    while (((element = element.nextElementSibling), element)) {
      if (element.matches(query)) break;
      if (!element.matches(exclude)) elements.push(element);
    }
    return elements;
  }
</script>
<!--
  Accordion Plugin

  Allows sections of content under h2 headings to be collapsible.
-->

<script type="module">
  // whether to always start expanded ('false'), always start collapsed
  // ('true'), or start collapsed when screen small ('auto')
  const startCollapsed = "auto";

  // start script
  function start() {
    // run through each <h2> heading
    const headings = document.querySelectorAll("h2");
    for (const heading of headings) {
      addArrow(heading);

      // start expanded/collapsed based on option
      if (
        startCollapsed === "true" ||
        (startCollapsed === "auto" && isSmallScreen()) ||
        heading.dataset.collapsed === "true"
      )
        collapseHeading(heading);
      else expandElement(heading);
    }

    // attach hash change listener to window
    window.addEventListener("hashchange", onHashChange);
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) goToElement(target);
  }

  // add arrow to heading
  function addArrow(heading) {
    // add arrow button
    const arrow = document.createElement("button");
    arrow.innerHTML = document.querySelector(".icon_angle_down").innerHTML;
    arrow.classList.add("icon_button", "accordion_arrow");
    heading.insertBefore(arrow, heading.firstChild);

    // attach click listener to heading and button
    heading.addEventListener("click", onHeadingClick);
    arrow.addEventListener("click", onArrowClick);
  }

  // determine if on mobile-like device with small screen
  function isSmallScreen() {
    return Math.min(window.innerWidth, window.innerHeight) < 480;
  }

  // when <h2> heading is clicked
  function onHeadingClick(event) {
    // only collapse if <h2> itself is target of click (eg, user did
    // not click on anchor within <h2>)
    if (event.target === this) toggleCollapse(this);
  }

  // when arrow button is clicked
  function onArrowClick() {
    toggleCollapse(this.parentNode);
  }

  // collapse section if expanded, expand if collapsed
  function toggleCollapse(heading) {
    if (heading.dataset.collapsed === "false") collapseHeading(heading);
    else expandElement(heading);
  }

  // elements to exclude from collapse, such as table of contents panel,
  // hypothesis panel, etc
  const exclude = "#toc_panel, div.annotator-frame, #lightbox_overlay";

  // collapse section
  function collapseHeading(heading) {
    heading.setAttribute("data-collapsed", "true");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "true");
  }

  // expand section
  function expandElement(heading) {
    heading.setAttribute("data-collapsed", "false");
    const children = getChildren(heading);
    for (const child of children) child.setAttribute("data-collapsed", "false");
  }

  // get list of elements between this <h2> and next <h2> or <h1>
  // ("children" of the <h2> section)
  function getChildren(heading) {
    return nextUntil(heading, "h2, h1", exclude);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle down icon -->

<template class="icon_angle_down">
  <!-- modified from: https://fontawesome.com/icons/angle-down -->
  <svg width="16" height="16" viewBox="0 0 448 512">
    <path
      fill="currentColor"
      d="M207.029 381.476L12.686 187.132c-9.373-9.373-9.373-24.569 0-33.941l22.667-22.667c9.357-9.357 24.522-9.375 33.901-.04L224 284.505l154.745-154.021c9.379-9.335 24.544-9.317 33.901.04l22.667 22.667c9.373 9.373 9.373 24.569 0 33.941L240.971 381.476c-9.373 9.372-24.569 9.372-33.942 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* accordion arrow button */
    .accordion_arrow {
      margin-right: 10px;
    }

    /* arrow icon when <h2> data-collapsed attribute true */
    h2[data-collapsed="true"] > .accordion_arrow > svg {
      transform: rotate(-90deg);
    }

    /* all elements (except <h2>'s) when data-collapsed attribute true */
    *:not(h2)[data-collapsed="true"] {
      display: none;
    }

    /* accordion arrow button when hovered and <h2>'s when hovered */
    .accordion_arrow:hover,
    h2[data-collapsed="true"]:hover,
    h2[data-collapsed="false"]:hover {
      cursor: pointer;
    }
  }

  /* always hide accordion arrow button on print */
  @media only print {
    .accordion_arrow {
      display: none;
    }
  }
</style>
<!--
  Anchors Plugin

  Adds an anchor next to each of a certain type of element that provides a
  human-readable url to that specific item/position in the document (e.g.
  "manuscript.html#abstract"). It also makes it such that scrolling out of view
  of a target removes its identifier from the url.
-->

<script type="module">
  // which types of elements to add anchors next to, in "document.querySelector"
  // format
  const typesQuery =
    'h1, h2, h3, div[id^="fig:"], div[id^="tbl:"], span[id^="eq:"]';

  // start script
  function start() {
    // add anchor to each element of specified types
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) addAnchor(element);

    // attach scroll listener to window
    window.addEventListener("scroll", onScroll);
  }

  // when window is scrolled
  function onScroll() {
    // if url has hash and user has scrolled out of view of hash
    // target, remove hash from url
    const tolerance = 100;
    const target = getHashTarget();
    if (target) {
      if (
        target.getBoundingClientRect().top > window.innerHeight + tolerance ||
        target.getBoundingClientRect().bottom < 0 - tolerance
      )
        history.pushState(null, null, " ");
    }
  }

  // add anchor to element
  function addAnchor(element) {
    let addTo; // element to add anchor button to

    // if figure or table, modify withId and addTo to get expected
    // elements
    if (element.id.indexOf("fig:") === 0) {
      addTo = element.querySelector("figcaption");
    } else if (element.id.indexOf("tbl:") === 0) {
      addTo = element.querySelector("caption");
    } else if (element.id.indexOf("eq:") === 0) {
      addTo = element.querySelector(".eqnos-number");
    }

    addTo = addTo || element;
    const id = element.id || null;

    // do not add anchor if element doesn't have assigned id.
    // id is generated by pandoc and is assumed to be unique and
    // human-readable
    if (!id) return;

    // create anchor button
    const anchor = document.createElement("a");
    anchor.innerHTML = document.querySelector(".icon_link").innerHTML;
    anchor.title = "Link to this part of the document";
    anchor.classList.add("icon_button", "anchor");
    anchor.dataset.ignore = "true";
    anchor.href = "#" + id;
    addTo.appendChild(anchor);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- link icon -->

<template class="icon_link">
  <!-- modified from: https://fontawesome.com/icons/link -->
  <svg width="16" height="16" viewBox="0 0 512 512">
    <path
      fill="currentColor"
      d="M326.612 185.391c59.747 59.809 58.927 155.698.36 214.59-.11.12-.24.25-.36.37l-67.2 67.2c-59.27 59.27-155.699 59.262-214.96 0-59.27-59.26-59.27-155.7 0-214.96l37.106-37.106c9.84-9.84 26.786-3.3 27.294 10.606.648 17.722 3.826 35.527 9.69 52.721 1.986 5.822.567 12.262-3.783 16.612l-13.087 13.087c-28.026 28.026-28.905 73.66-1.155 101.96 28.024 28.579 74.086 28.749 102.325.51l67.2-67.19c28.191-28.191 28.073-73.757 0-101.83-3.701-3.694-7.429-6.564-10.341-8.569a16.037 16.037 0 0 1-6.947-12.606c-.396-10.567 3.348-21.456 11.698-29.806l21.054-21.055c5.521-5.521 14.182-6.199 20.584-1.731a152.482 152.482 0 0 1 20.522 17.197zM467.547 44.449c-59.261-59.262-155.69-59.27-214.96 0l-67.2 67.2c-.12.12-.25.25-.36.37-58.566 58.892-59.387 154.781.36 214.59a152.454 152.454 0 0 0 20.521 17.196c6.402 4.468 15.064 3.789 20.584-1.731l21.054-21.055c8.35-8.35 12.094-19.239 11.698-29.806a16.037 16.037 0 0 0-6.947-12.606c-2.912-2.005-6.64-4.875-10.341-8.569-28.073-28.073-28.191-73.639 0-101.83l67.2-67.19c28.239-28.239 74.3-28.069 102.325.51 27.75 28.3 26.872 73.934-1.155 101.96l-13.087 13.087c-4.35 4.35-5.769 10.79-3.783 16.612 5.864 17.194 9.042 34.999 9.69 52.721.509 13.906 17.454 20.446 27.294 10.606l37.106-37.106c59.271-59.259 59.271-155.699.001-214.959z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* anchor button */
    .anchor {
      opacity: 0;
      margin-left: 5px;
    }

    /* anchor buttons within <h2>'s */
    h2 .anchor {
      margin-left: 10px;
    }

    /* anchor buttons when hovered/focused and anything containing an anchor button when hovered */
    *:hover > .anchor,
    .anchor:hover,
    .anchor:focus {
      opacity: 1;
    }

    /* anchor button when hovered */
    .anchor:hover {
      cursor: pointer;
    }
  }

  /* always show anchor button on devices with no mouse/hover ability */
  @media (hover: none) {
    .anchor {
      opacity: 1;
    }
  }

  /* always hide anchor button on print */
  @media only print {
    .anchor {
      display: none;
    }
  }
</style>
<!-- 
    Attributes Plugin

    Allows arbitrary HTML attributes to be attached to (almost) any element.
    Place an HTML comment inside or next to the desired element with the content:
    $attribute="value"
-->

<script type="module">
  // start script
  function start() {
    // get list of comments in document
    const comments = findComments();

    for (const comment of comments)
      if (comment.parentElement)
        addAttributes(comment.parentElement, comment.nodeValue.trim());
  }

  // add html attributes to specified element based on string of
  // html attributes and values
  function addAttributes(element, text) {
    // regex's for finding attribute/value pairs in the format of
    // attribute="value" or attribute='value
    const regex2 = /\$([a-zA-Z\-]+)?=\"(.+?)\"/;
    const regex1 = /\$([a-zA-Z\-]+)?=\'(.+?)\'/;

    // loop through attribute/value pairs
    let match;
    while ((match = text.match(regex2) || text.match(regex1))) {
      // get attribute and value from regex capture groups
      let attribute = match[1];
      let value = match[2];

      // remove from string
      text = text.substring(match.index + match[0].length);

      if (!attribute || !value) break;

      // set attribute of parent element
      try {
        element.setAttribute(attribute, value);
      } catch (error) {
        console.log(error);
      }

      // special case for colspan
      if (attribute === "colspan") removeTableCells(element, value);
    }
  }

  // get list of comment elements in document
  function findComments() {
    const comments = [];

    // iterate over comment nodes in document
    function acceptNode(node) {
      return NodeFilter.FILTER_ACCEPT;
    }
    const iterator = document.createNodeIterator(
      document.body,
      NodeFilter.SHOW_COMMENT,
      acceptNode
    );
    let node;
    while ((node = iterator.nextNode())) comments.push(node);

    return comments;
  }

  // remove certain number of cells after specified cell
  function removeTableCells(cell, number) {
    number = parseInt(number);
    if (!number) return;

    // remove elements
    for (; number > 1; number--) {
      if (cell.nextElementSibling) cell.nextElementSibling.remove();
    }
  }

  // start script on DOMContentLoaded instead of load to ensure this plugins
  // runs before other plugins
  window.addEventListener("DOMContentLoaded", start);
</script>
<!--
  Jump to First Plugin

  Adds a button next to each reference entry, figure, and table that jumps the
  page to the first occurrence of a link to that item in the manuscript.
-->

<script type="module">
  // whether to add buttons next to reference entries
  const references = "true";
  // whether to add buttons next to figures
  const figures = "true";
  // whether to add buttons next to tables
  const tables = "true";

  // start script
  function start() {
    if (references !== "false")
      makeButtons(`div[id^="ref-"]`, ".csl-left-margin", "reference");
    if (figures !== "false")
      makeButtons(`div[id^="fig:"]`, "figcaption", "figure");
    if (tables !== "false") makeButtons(`div[id^="tbl:"]`, "caption", "table");
  }

  // when jump button clicked
  function onButtonClick() {
    const first = getFirstOccurrence(this.dataset.id);
    if (!first) return;

    // update url hash so navigating "back" in history will return user to button
    window.location.hash = this.dataset.id;
    // scroll to link
    const timeout = function () {
      goToElement(first, window.innerHeight * 0.5);
    };
    window.setTimeout(timeout, 0);
  }

  // get first occurrence of link to item in document
  function getFirstOccurrence(id) {
    let query = "a";
    query += '[href="#' + id + '"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelector(query);
  }

  // add button next to each reference entry, figure, or table
  function makeButtons(query, containerQuery, subject) {
    const elements = document.querySelectorAll(query);
    for (const element of elements) {
      const id = element.id;
      const buttonContainer = element.querySelector(containerQuery);
      const first = getFirstOccurrence(id);

      // if can't find link to reference or place to put button, ignore
      if (!first || !buttonContainer) continue;

      // make jump button
      let button = document.createElement("button");
      button.classList.add("icon_button", "jump_arrow");
      button.title = `Jump to the first occurrence of this ${subject} in the document`;
      const icon = document.querySelector(".icon_angle_double_up");
      button.innerHTML = icon.innerHTML;
      button.dataset.id = id;
      button.dataset.ignore = "true";
      button.addEventListener("click", onButtonClick);
      buttonContainer.prepend(button);
    }
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- angle double up icon -->

<template class="icon_angle_double_up">
  <!-- modified from: https://fontawesome.com/icons/angle-double-up -->
  <svg width="16" height="16" viewBox="0 0 320 512">
    <path
      fill="currentColor"
      d="M177 255.7l136 136c9.4 9.4 9.4 24.6 0 33.9l-22.6 22.6c-9.4 9.4-24.6 9.4-33.9 0L160 351.9l-96.4 96.4c-9.4 9.4-24.6 9.4-33.9 0L7 425.7c-9.4-9.4-9.4-24.6 0-33.9l136-136c9.4-9.5 24.6-9.5 34-.1zm-34-192L7 199.7c-9.4 9.4-9.4 24.6 0 33.9l22.6 22.6c9.4 9.4 24.6 9.4 33.9 0l96.4-96.4 96.4 96.4c9.4 9.4 24.6 9.4 33.9 0l22.6-22.6c9.4-9.4 9.4-24.6 0-33.9l-136-136c-9.2-9.4-24.4-9.4-33.8 0z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* jump button */
    .jump_arrow {
      position: relative;
      top: 0.125em;
      margin-right: 5px;
    }
  }

  /* always hide jump button on print */
  @media only print {
    .jump_arrow {
      display: none;
    }
  }
</style>
<!-- 
    Lightbox Plugin

    Makes it such that when a user clicks on an image, the image fills the
    screen and the user can pan/drag/zoom the image and navigate between other
    images in the document.
-->

<script type="module">
  // list of possible zoom/scale factors
  const zooms =
    "0.1, 0.25, 0.333333, 0.5, 0.666666, 0.75, 1, 1.25, 1.5, 1.75, 2, 2.5, 3, 3.5, 4, 5, 6, 7, 8";
  // whether to fit image to view ('fit'), display at 100% and shrink if
  // necessary ('shrink'), or always display at 100% ('100')
  const defaultZoom = "fit";
  // whether to zoom in/out toward center of view ('true') or mouse ('false')
  const centerZoom = "false";

  // start script
  function start() {
    // run through each <img> element
    const imgs = document.querySelectorAll("figure > img");
    let count = 1;
    for (const img of imgs) {
      img.classList.add("lightbox_document_img");
      img.dataset.number = count;
      img.dataset.total = imgs.length;
      img.addEventListener("click", openLightbox);
      count++;
    }

    // attach mouse and key listeners to window
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("keyup", onKeyUp);
  }

  // when mouse is moved anywhere in window
  function onWindowMouseMove(event) {
    window.mouseX = event.clientX;
    window.mouseY = event.clientY;
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("lightbox_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("lightbox_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeLightbox();
        break;
    }
  }

  // open lightbox
  function openLightbox() {
    const lightbox = makeLightbox(this);
    if (!lightbox) return;

    blurBody(lightbox);
    document.body.appendChild(lightbox);
  }

  // make lightbox
  function makeLightbox(img) {
    // delete lightbox if it exists, start fresh
    closeLightbox();

    // create screen overlay containing lightbox
    const overlay = document.createElement("div");
    overlay.id = "lightbox_overlay";

    // create image info boxes
    const numberInfo = document.createElement("div");
    const zoomInfo = document.createElement("div");
    numberInfo.id = "lightbox_number_info";
    zoomInfo.id = "lightbox_zoom_info";

    // create container for image
    const imageContainer = document.createElement("div");
    imageContainer.id = "lightbox_image_container";
    const lightboxImg = makeLightboxImg(
      img,
      imageContainer,
      numberInfo,
      zoomInfo
    );
    imageContainer.appendChild(lightboxImg);

    // create bottom container for caption and navigation buttons
    const bottomContainer = document.createElement("div");
    bottomContainer.id = "lightbox_bottom_container";
    const caption = makeCaption(img);
    const prevButton = makePrevButton(img);
    const nextButton = makeNextButton(img);
    bottomContainer.appendChild(prevButton);
    bottomContainer.appendChild(caption);
    bottomContainer.appendChild(nextButton);

    // attach top middle and bottom to overlay
    overlay.appendChild(numberInfo);
    overlay.appendChild(zoomInfo);
    overlay.appendChild(imageContainer);
    overlay.appendChild(bottomContainer);

    return overlay;
  }

  // make <img> object that is intuitively draggable and zoomable
  function makeLightboxImg(sourceImg, container, numberInfoBox, zoomInfoBox) {
    // create copy of source <img>
    const img = sourceImg.cloneNode(true);
    img.classList.remove("lightbox_document_img");
    img.removeAttribute("id");
    img.removeAttribute("width");
    img.removeAttribute("height");
    img.style.position = "unset";
    img.style.margin = "0";
    img.style.padding = "0";
    img.style.width = "";
    img.style.height = "";
    img.style.minWidth = "";
    img.style.minHeight = "";
    img.style.maxWidth = "";
    img.style.maxHeight = "";
    img.id = "lightbox_img";

    // build sorted list of zoomSteps
    const zoomSteps = zooms.split(/[^0-9.]/).map((step) => parseFloat(step));
    zoomSteps.sort((a, b) => a - b);

    // <img> object property variables
    let zoom = 1;
    let translateX = 0;
    let translateY = 0;
    let clickMouseX = undefined;
    let clickMouseY = undefined;
    let clickTranslateX = undefined;
    let clickTranslateY = undefined;

    updateNumberInfo();

    // update image numbers displayed in info box
    function updateNumberInfo() {
      numberInfoBox.innerHTML =
        sourceImg.dataset.number + " of " + sourceImg.dataset.total;
    }

    // update zoom displayed in info box
    function updateZoomInfo() {
      let zoomInfo = zoom * 100;
      if (!Number.isInteger(zoomInfo)) zoomInfo = zoomInfo.toFixed(2);
      zoomInfoBox.innerHTML = zoomInfo + "%";
    }

    // move to closest zoom step above current zoom
    const zoomIn = function () {
      for (const zoomStep of zoomSteps) {
        if (zoomStep > zoom) {
          zoom = zoomStep;
          break;
        }
      }
      updateTransform();
    };

    // move to closest zoom step above current zoom
    const zoomOut = function () {
      zoomSteps.reverse();
      for (const zoomStep of zoomSteps) {
        if (zoomStep < zoom) {
          zoom = zoomStep;
          break;
        }
      }
      zoomSteps.reverse();

      updateTransform();
    };

    // update display of <img> based on scale/translate properties
    const updateTransform = function () {
      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      // get new width/height after scale
      const rect = img.getBoundingClientRect();
      // limit translate
      translateX = Math.max(translateX, -rect.width / 2);
      translateX = Math.min(translateX, rect.width / 2);
      translateY = Math.max(translateY, -rect.height / 2);
      translateY = Math.min(translateY, rect.height / 2);

      // set transform
      img.style.transform =
        "translate(" +
        (translateX || 0) +
        "px," +
        (translateY || 0) +
        "px) scale(" +
        (zoom || 1) +
        ")";

      updateZoomInfo();
    };

    // fit <img> to container
    const fit = function () {
      // no x/y offset, 100% zoom by default
      translateX = 0;
      translateY = 0;
      zoom = 1;

      // widths of <img> and container
      const imgWidth = img.naturalWidth;
      const imgHeight = img.naturalHeight;
      const containerWidth = parseFloat(
        window.getComputedStyle(container).width
      );
      const containerHeight = parseFloat(
        window.getComputedStyle(container).height
      );

      // how much zooming is needed to fit <img> to container
      const xRatio = imgWidth / containerWidth;
      const yRatio = imgHeight / containerHeight;
      const maxRatio = Math.max(xRatio, yRatio);
      const newZoom = 1 / maxRatio;

      // fit <img> to container according to option
      if (defaultZoom === "shrink") {
        if (maxRatio > 1) zoom = newZoom;
      } else if (defaultZoom === "fit") zoom = newZoom;

      updateTransform();
    };

    // when mouse wheel is rolled anywhere in container
    const onContainerWheel = function (event) {
      if (!event) return;

      // let ctrl + mouse wheel to zoom behave as normal
      if (event.ctrlKey) return;

      // prevent normal scroll behavior
      event.preventDefault();
      event.stopPropagation();

      // point around which to scale img
      const viewRect = container.getBoundingClientRect();
      const viewX = (viewRect.left + viewRect.right) / 2;
      const viewY = (viewRect.top + viewRect.bottom) / 2;
      const originX = centerZoom === "true" ? viewX : mouseX;
      const originY = centerZoom === "true" ? viewY : mouseY;

      // get point on image under origin
      const oldRect = img.getBoundingClientRect();
      const oldPercentX = (originX - oldRect.left) / oldRect.width;
      const oldPercentY = (originY - oldRect.top) / oldRect.height;

      // increment/decrement zoom
      if (event.deltaY < 0) zoomIn();
      if (event.deltaY > 0) zoomOut();

      // get offset between previous image point and origin
      const newRect = img.getBoundingClientRect();
      const offsetX = originX - (newRect.left + newRect.width * oldPercentX);
      const offsetY = originY - (newRect.top + newRect.height * oldPercentY);

      // translate image to keep image point under origin
      translateX += offsetX;
      translateY += offsetY;

      // perform translate
      updateTransform();
    };

    // when container is clicked
    function onContainerClick(event) {
      // if container itself is target of click, and not other
      // element above it
      if (event.target === this) closeLightbox();
    }

    // when mouse button is pressed on image
    const onImageMouseDown = function (event) {
      // store original mouse position relative to image
      clickMouseX = window.mouseX;
      clickMouseY = window.mouseY;
      clickTranslateX = translateX;
      clickTranslateY = translateY;
      event.stopPropagation();
      event.preventDefault();
    };

    // when mouse button is released anywhere in window
    const onWindowMouseUp = function (event) {
      // reset original mouse position
      clickMouseX = undefined;
      clickMouseY = undefined;
      clickTranslateX = undefined;
      clickTranslateY = undefined;

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mouseup", onWindowMouseUp);
    };

    // when mouse is moved anywhere in window
    const onWindowMouseMove = function (event) {
      if (
        clickMouseX === undefined ||
        clickMouseY === undefined ||
        clickTranslateX === undefined ||
        clickTranslateY === undefined
      )
        return;

      // offset image based on original and current mouse position
      translateX = clickTranslateX + window.mouseX - clickMouseX;
      translateY = clickTranslateY + window.mouseY - clickMouseY;
      updateTransform();
      event.preventDefault();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("mousemove", onWindowMouseMove);
    };

    // when window is resized
    const onWindowResize = function (event) {
      fit();

      // remove global listener if lightbox removed from document
      if (!document.body.contains(container))
        window.removeEventListener("resize", onWindowResize);
    };

    // attach the necessary event listeners
    img.addEventListener("dblclick", fit);
    img.addEventListener("mousedown", onImageMouseDown);
    container.addEventListener("wheel", onContainerWheel);
    container.addEventListener("mousedown", onContainerClick);
    container.addEventListener("touchstart", onContainerClick);
    window.addEventListener("mouseup", onWindowMouseUp);
    window.addEventListener("mousemove", onWindowMouseMove);
    window.addEventListener("resize", onWindowResize);

    // run fit() after lightbox atttached to document and <img> Loaded
    // so needed container and img dimensions available
    img.addEventListener("load", fit);

    return img;
  }

  // make caption
  function makeCaption(img) {
    const caption = document.createElement("div");
    caption.id = "lightbox_caption";
    const captionSource = img.nextElementSibling;
    if (captionSource.tagName.toLowerCase() === "figcaption") {
      const captionCopy = makeCopy(captionSource);
      caption.innerHTML = captionCopy.innerHTML;
    }

    caption.addEventListener("touchstart", function (event) {
      event.stopPropagation();
    });

    return caption;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // make button to jump to previous image in document
  function makePrevButton(img) {
    const prevButton = document.createElement("button");
    prevButton.id = "lightbox_prev_button";
    prevButton.title = "Jump to the previous image in the document [←]";
    prevButton.classList.add("icon_button", "lightbox_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;

    // attach click listeners to button
    prevButton.addEventListener("click", function () {
      getPrevImg(img).click();
    });

    return prevButton;
  }

  // make button to jump to next image in document
  function makeNextButton(img) {
    const nextButton = document.createElement("button");
    nextButton.id = "lightbox_next_button";
    nextButton.title = "Jump to the next image in the document [→]";
    nextButton.classList.add("icon_button", "lightbox_button");
    nextButton.innerHTML = document.querySelector(
      ".icon_caret_right"
    ).innerHTML;

    // attach click listeners to button
    nextButton.addEventListener("click", function () {
      getNextImg(img).click();
    });

    return nextButton;
  }

  // get previous image in document
  function getPrevImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if < 1
    if (index - 1 >= 0) index--;
    else index = imgs.length - 1;
    return imgs[index];
  }

  // get next image in document
  function getNextImg(img) {
    const imgs = document.querySelectorAll(".lightbox_document_img");

    // find index of provided img
    let index;
    for (index = 0; index < imgs.length; index++) {
      if (imgs[index] === img) break;
    }

    // wrap index to other side if > total
    if (index + 1 <= imgs.length - 1) index++;
    else index = 0;
    return imgs[index];
  }

  // close lightbox
  function closeLightbox() {
    focusBody();

    const lightbox = document.getElementById("lightbox_overlay");
    if (lightbox) lightbox.remove();
  }

  // make all elements behind lightbox non-focusable
  function blurBody(overlay) {
    const all = document.querySelectorAll("*");
    for (const element of all) element.tabIndex = -1;
    document.body.classList.add("body_no_scroll");
  }

  // make all elements focusable again
  function focusBody() {
    const all = document.querySelectorAll("*");
    for (const element of all) element.removeAttribute("tabIndex");
    document.body.classList.remove("body_no_scroll");
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* regular <img> in document when hovered */
    img.lightbox_document_img:hover {
      cursor: pointer;
    }

    .body_no_scroll {
      overflow: hidden !important;
    }

    /* screen overlay */
    #lightbox_overlay {
      display: flex;
      flex-direction: column;
      position: fixed;
      left: 0;
      top: 0;
      right: 0;
      bottom: 0;
      background: rgba(0, 0, 0, 0.75);
      z-index: 3;
    }

    /* middle area containing lightbox image */
    #lightbox_image_container {
      flex-grow: 1;
      display: flex;
      justify-content: center;
      align-items: center;
      overflow: hidden;
      position: relative;
      padding: 20px;
    }

    /* bottom area containing caption */
    #lightbox_bottom_container {
      display: flex;
      justify-content: center;
      align-items: center;
      height: 100px;
      min-height: 100px;
      max-height: 100px;
      background: rgba(0, 0, 0, 0.5);
    }

    /* image number info text box */
    #lightbox_number_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      left: 2px;
      top: 0;
      z-index: 4;
    }

    /* zoom info text box */
    #lightbox_zoom_info {
      position: absolute;
      color: #ffffff;
      font-weight: 600;
      right: 2px;
      top: 0;
      z-index: 4;
    }

    /* copy of image caption */
    #lightbox_caption {
      box-sizing: border-box;
      display: inline-block;
      width: 100%;
      max-height: 100%;
      padding: 10px 0;
      text-align: center;
      overflow-y: auto;
      color: #ffffff;
    }

    /* navigation previous/next button */
    .lightbox_button {
      width: 100px;
      height: 100%;
      min-width: 100px;
      min-height: 100%;
      color: #ffffff;
    }

    /* navigation previous/next button when hovered */
    .lightbox_button:hover {
      background: none !important;
    }

    /* navigation button icon */
    .lightbox_button > svg {
      height: 25px;
    }

    /* figure auto-number */
    #lightbox_caption > span:first-of-type {
      font-weight: bold;
      margin-right: 5px;
    }

    /* lightbox image when hovered */
    #lightbox_img:hover {
      cursor: grab;
    }

    /* lightbox image when grabbed */
    #lightbox_img:active {
      cursor: grabbing;
    }
  }

  /* when on screen < 480px wide */
  @media only screen and (max-width: 480px) {
    /* make navigation buttons skinnier on small screens to make more room for caption text */
    .lightbox_button {
      width: 50px;
      min-width: 50px;
    }
  }

  /* always hide lightbox on print */
  @media only print {
    #lightbox_overlay {
      display: none;
    }
  }
</style>
<!-- 
  Link Highlight Plugin

  Makes it such that when a user hovers or focuses a link, other links that have
  the same target will be highlighted. It also makes it such that when clicking
  a link, the target of the link (eg reference, figure, table) is briefly
  highlighted.
-->

<script type="module">
  // whether to also highlight links that go to external urls
  const externalLinks = "false";
  // whether user must click off to unhighlight instead of just
  // un-hovering
  const clickUnhighlight = "false";
  // whether to also highlight links that are unique
  const highlightUnique = "true";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach mouse and focus listeners to link
      link.addEventListener("mouseenter", onLinkFocus);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("mouseleave", onLinkUnhover);
    }

    // attach click and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("hashchange", onHashChange);

    // run hash change on window load in case user has navigated
    // directly to hash
    onHashChange();
  }

  // when link is focused (tabbed to) or hovered
  function onLinkFocus() {
    highlight(this);
  }

  // when link is unhovered
  function onLinkUnhover() {
    if (clickUnhighlight !== "true") unhighlightAll();
  }

  // when the mouse is clicked anywhere in window
  function onClick(event) {
    unhighlightAll();
  }

  // when hash (eg manuscript.html#introduction) changes
  function onHashChange() {
    const target = getHashTarget();
    if (target) glowElement(target);
  }

  // start glow sequence on an element
  function glowElement(element) {
    const startGlow = function () {
      onGlowEnd();
      element.dataset.glow = "true";
      element.addEventListener("animationend", onGlowEnd);
    };
    const onGlowEnd = function () {
      element.removeAttribute("data-glow");
      element.removeEventListener("animationend", onGlowEnd);
    };
    startGlow();
  }

  // highlight link and all others with same target
  function highlight(link) {
    // force unhighlight all to start fresh
    unhighlightAll();

    // get links with same target
    if (!link) return;
    const sameLinks = getSameLinks(link);

    // if link unique and option is off, exit and don't highlight
    if (sameLinks.length <= 1 && highlightUnique !== "true") return;

    // highlight all same links, and "select" (special highlight) this
    // one
    for (const sameLink of sameLinks) {
      if (sameLink === link) sameLink.setAttribute("data-selected", "true");
      else sameLink.setAttribute("data-highlighted", "true");
    }
  }

  // unhighlight all links
  function unhighlightAll() {
    const links = getLinks();
    for (const link of links) {
      link.setAttribute("data-selected", "false");
      link.setAttribute("data-highlighted", "false");
    }
  }

  // get links with same target
  function getSameLinks(link) {
    const results = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        results.push(otherLink);
    }
    return results;
  }

  // get all links of types we wish to handle
  function getLinks() {
    let query = "a";
    if (externalLinks !== "true") query += '[href^="#"]';
    // exclude buttons, anchor links, toc links, etc
    query += ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    return document.querySelectorAll(query);
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<style>
  @media only screen {
    /* anything with data-highlighted attribute true */
    [data-highlighted="true"] {
      background: #ffeb3b;
    }

    /* anything with data-selected attribute true */
    [data-selected="true"] {
      background: #ff8a65 !important;
    }

    /* animation definition for glow */
    @keyframes highlight_glow {
      0% {
        background: none;
      }
      10% {
        background: #bbdefb;
      }
      100% {
        background: none;
      }
    }

    /* anything with data-glow attribute true */
    [data-glow="true"] {
      animation: highlight_glow 2s;
    }
  }
</style>
<!--
  Table of Contents Plugin

  Provides a "table of contents" (toc) panel on the side of the document that
  allows the user to conveniently navigate between sections of the document.
-->

<script type="module">
  // which types of elements to add links for, in "document.querySelector" format
  const typesQuery = "h1, h2, h3";
  // whether toc starts open. use 'true' or 'false', or 'auto' to
  // use 'true' behavior when screen wide enough and 'false' when not
  const startOpen = "false";
  // whether toc closes when clicking on toc link. use 'true' or
  // 'false', or 'auto' to use 'false' behavior when screen wide
  // enough and 'true' when not
  const clickClose = "auto";
  // if list item is more than this many characters, text will be
  // truncated
  const charLimit = "50";
  // whether or not to show bullets next to each toc item
  const bullets = "false";

  // start script
  function start() {
    // make toc panel and populate with entries (links to document
    // sections)
    const panel = makePanel();
    if (!panel) return;
    makeEntries(panel);
    // attach panel to document after making entries, so 'toc' heading
    // in panel isn't included in toc
    document.body.insertBefore(panel, document.body.firstChild);

    // initial panel state
    if (startOpen === "true" || (startOpen === "auto" && !isSmallScreen()))
      openPanel();
    else closePanel();

    // attach click, scroll, and hash change listeners to window
    window.addEventListener("click", onClick);
    window.addEventListener("scroll", onScroll);
    window.addEventListener("hashchange", onScroll);
    window.addEventListener("keyup", onKeyUp);
    onScroll();

    // add class to push document body down out of way of toc button
    document.body.classList.add("toc_body_nudge");
  }

  // determine if screen wide enough to fit toc panel
  function isSmallScreen() {
    // in default theme:
    // 816px = 8.5in = width of "page" (<body>) element
    // 260px = min width of toc panel (*2 for both sides of <body>)
    return window.innerWidth < 816 + 260 * 2;
  }

  // when mouse is clicked anywhere in window
  function onClick() {
    if (isSmallScreen()) closePanel();
  }

  // when window is scrolled or hash changed
  function onScroll() {
    highlightViewed();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    // close on esc
    if (event.key === "Escape") closePanel();
  }

  // find entry of currently viewed document section in toc and highlight
  function highlightViewed() {
    const firstId = getFirstInView(typesQuery);

    // get toc entries (links), unhighlight all, then highlight viewed
    const list = document.getElementById("toc_list");
    if (!firstId || !list) return;
    const links = list.querySelectorAll("a");
    for (const link of links) link.dataset.viewing = "false";
    const link = list.querySelector('a[href="#' + firstId + '"]');
    if (!link) return;
    link.dataset.viewing = "true";
  }

  // get first or previous toc listed element in top half of view
  function getFirstInView(query) {
    // get all elements matching query and with id
    const elements = document.querySelectorAll(query);
    const elementsWithIds = [];
    for (const element of elements) {
      if (element.id) elementsWithIds.push(element);
    }

    // get first or previous element in top half of view
    for (let i = 0; i < elementsWithIds.length; i++) {
      const element = elementsWithIds[i];
      const prevElement = elementsWithIds[Math.max(0, i - 1)];
      if (element.getBoundingClientRect().top >= 0) {
        if (element.getBoundingClientRect().top < window.innerHeight / 2)
          return element.id;
        else return prevElement.id;
      }
    }
  }

  // make panel
  function makePanel() {
    // create panel
    const panel = document.createElement("div");
    panel.id = "toc_panel";
    if (bullets === "true") panel.dataset.bullets = "true";

    // create header
    const header = document.createElement("div");
    header.id = "toc_header";

    // create toc button
    const button = document.createElement("button");
    button.id = "toc_button";
    button.innerHTML = document.querySelector(".icon_th_list").innerHTML;
    button.title = "Table of Contents";
    button.classList.add("icon_button");

    // create header text
    const text = document.createElement("h4");
    text.innerHTML = "Table of Contents";

    // create container for toc list
    const list = document.createElement("div");
    list.id = "toc_list";

    // attach click listeners
    panel.addEventListener("click", onPanelClick);
    header.addEventListener("click", onHeaderClick);
    button.addEventListener("click", onButtonClick);

    // attach elements
    header.appendChild(button);
    header.appendChild(text);
    panel.appendChild(header);
    panel.appendChild(list);

    return panel;
  }

  // create toc entries (links) to each element of the specified types
  function makeEntries(panel) {
    const elements = document.querySelectorAll(typesQuery);
    for (const element of elements) {
      // do not add link if element doesn't have assigned id
      if (!element.id) continue;

      // create link/list item
      const link = document.createElement("a");
      link.classList.add("toc_link");
      switch (element.tagName.toLowerCase()) {
        case "h1":
          link.dataset.level = "1";
          break;
        case "h2":
          link.dataset.level = "2";
          break;
        case "h3":
          link.dataset.level = "3";
          break;
        case "h4":
          link.dataset.level = "4";
          break;
      }
      link.title = element.innerText;
      let text = element.innerText;
      if (text.length > charLimit) text = text.slice(0, charLimit) + "...";
      link.innerHTML = text;
      link.href = "#" + element.id;
      link.addEventListener("click", onLinkClick);

      // attach link
      panel.querySelector("#toc_list").appendChild(link);
    }
  }

  // when panel is clicked
  function onPanelClick(event) {
    // stop click from propagating to window/document and closing panel
    event.stopPropagation();
  }

  // when header itself is clicked
  function onHeaderClick(event) {
    togglePanel();
  }

  // when button is clicked
  function onButtonClick(event) {
    togglePanel();
    // stop header underneath button from also being clicked
    event.stopPropagation();
  }

  // when link is clicked
  function onLinkClick(event) {
    if (clickClose === "true" || (clickClose === "auto" && isSmallScreen()))
      closePanel();
    else openPanel();
  }

  // open panel if closed, close if opened
  function togglePanel() {
    const panel = document.getElementById("toc_panel");
    if (!panel) return;

    if (panel.dataset.open === "true") closePanel();
    else openPanel();
  }

  // open panel
  function openPanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "true";
  }

  // close panel
  function closePanel() {
    const panel = document.getElementById("toc_panel");
    if (panel) panel.dataset.open = "false";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- th list icon -->

<template class="icon_th_list">
  <!-- modified from: https://fontawesome.com/icons/th-list -->
  <svg width="16" height="16" viewBox="0 0 512 512" tabindex="-1">
    <path
      fill="currentColor"
      d="M96 96c0 26.51-21.49 48-48 48S0 122.51 0 96s21.49-48 48-48 48 21.49 48 48zM48 208c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm0 160c-26.51 0-48 21.49-48 48s21.49 48 48 48 48-21.49 48-48-21.49-48-48-48zm96-236h352c8.837 0 16-7.163 16-16V76c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16zm0 160h352c8.837 0 16-7.163 16-16v-40c0-8.837-7.163-16-16-16H144c-8.837 0-16 7.163-16 16v40c0 8.837 7.163 16 16 16z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* toc panel */
    #toc_panel {
      box-sizing: border-box;
      position: fixed;
      top: 0;
      left: 0;
      background: #ffffff;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      z-index: 2;
    }

    /* toc panel when closed */
    #toc_panel[data-open="false"] {
      min-width: 60px;
      width: 60px;
      height: 60px;
      border-right: solid 1px #bdbdbd;
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc panel when open */
    #toc_panel[data-open="true"] {
      min-width: 260px;
      max-width: 480px;
      /* keep panel edge consistent distance away from "page" edge */
      width: calc(((100vw - 8.5in) / 2) - 30px - 40px);
      bottom: 0;
      border-right: solid 1px #bdbdbd;
    }

    /* toc panel header */
    #toc_header {
      box-sizing: border-box;
      display: flex;
      flex-direction: row;
      align-items: center;
      height: 60px;
      margin: 0;
      padding: 20px;
    }

    /* toc panel header when hovered */
    #toc_header:hover {
      cursor: pointer;
    }

    /* toc panel header when panel open */
    #toc_panel[data-open="true"] > #toc_header {
      border-bottom: solid 1px #bdbdbd;
    }

    /* toc open/close header button */
    #toc_button {
      margin-right: 20px;
    }

    /* hide toc list and header text when closed */
    #toc_panel[data-open="false"] > #toc_header > *:not(#toc_button),
    #toc_panel[data-open="false"] > #toc_list {
      display: none;
    }

    /* toc list of entries */
    #toc_list {
      box-sizing: border-box;
      width: 100%;
      padding: 20px;
      position: absolute;
      top: calc(60px + 1px);
      bottom: 0;
      overflow: auto;
    }

    /* toc entry, link to section in document */
    .toc_link {
      display: block;
      padding: 5px;
      position: relative;
      font-weight: 600;
      text-decoration: none;
    }

    /* toc entry when hovered or when "viewed" */
    .toc_link:hover,
    .toc_link[data-viewing="true"] {
      background: #f5f5f5;
    }

    /* toc entry, level 1 indentation */
    .toc_link[data-level="1"] {
      margin-left: 0;
    }

    /* toc entry, level 2 indentation */
    .toc_link[data-level="2"] {
      margin-left: 20px;
    }

    /* toc entry, level 3 indentation */
    .toc_link[data-level="3"] {
      margin-left: 40px;
    }

    /* toc entry, level 4 indentation */
    .toc_link[data-level="4"] {
      margin-left: 60px;
    }

    /* toc entry bullets */
    #toc_panel[data-bullets="true"] .toc_link[data-level]:before {
      position: absolute;
      left: -15px;
      top: -1px;
      font-size: 1.5em;
    }

    /* toc entry, level 2 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="2"]:before {
      content: "\2022";
    }

    /* toc entry, level 3 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="3"]:before {
      content: "\25AB";
    }

    /* toc entry, level 4 bullet */
    #toc_panel[data-bullets="true"] .toc_link[data-level="4"]:before {
      content: "-";
    }
  }

  /* when on screen < 8.5in wide */
  @media only screen and (max-width: 8.5in) {
    /* push <body> ("page") element down to make room for toc icon */
    .toc_body_nudge {
      padding-top: 60px;
    }

    /* toc icon when panel closed and not hovered */
    #toc_panel[data-open="false"]:not(:hover) {
      background: rgba(255, 255, 255, 0.75);
    }
  }

  /* always hide toc panel on print */
  @media only print {
    #toc_panel {
      display: none;
    }
  }
</style>
<!-- 
  Tooltips Plugin

  Makes it such that when the user hovers or focuses a link to a citation or
  figure, a tooltip appears with a preview of the reference content, along with
  arrows to navigate between instances of the same reference in the document.
-->

<script type="module">
  // whether user must click off to close tooltip instead of just un-hovering
  const clickClose = "false";
  // delay (in ms) between opening and closing tooltip
  const delay = "100";

  // start script
  function start() {
    const links = getLinks();
    for (const link of links) {
      // attach hover and focus listeners to link
      link.addEventListener("mouseover", onLinkHover);
      link.addEventListener("mouseleave", onLinkUnhover);
      link.addEventListener("focus", onLinkFocus);
      link.addEventListener("touchend", onLinkTouch);
    }

    // attach mouse, key, and resize listeners to window
    window.addEventListener("mousedown", onClick);
    window.addEventListener("touchstart", onClick);
    window.addEventListener("keyup", onKeyUp);
    window.addEventListener("resize", onResize);
  }

  // when link is hovered
  function onLinkHover() {
    // function to open tooltip
    const delayOpenTooltip = function () {
      openTooltip(this);
    }.bind(this);

    // run open function after delay
    this.openTooltipTimer = window.setTimeout(delayOpenTooltip, delay);
  }

  // when mouse leaves link
  function onLinkUnhover() {
    // cancel opening tooltip
    window.clearTimeout(this.openTooltipTimer);

    // don't close on unhover if option specifies
    if (clickClose === "true") return;

    // function to close tooltip
    const delayCloseTooltip = function () {
      // if tooltip open and if mouse isn't over tooltip, close
      const tooltip = document.getElementById("tooltip");
      if (tooltip && !tooltip.matches(":hover")) closeTooltip();
    };

    // run close function after delay
    this.closeTooltipTimer = window.setTimeout(delayCloseTooltip, delay);
  }

  // when link is focused (tabbed to)
  function onLinkFocus(event) {
    openTooltip(this);
  }

  // when link is touched on touch screen
  function onLinkTouch(event) {
    // attempt to force hover state on first tap always, and trigger
    // regular link click (and navigation) on second tap
    if (event.target === document.activeElement) event.target.click();
    else {
      document.activeElement.blur();
      event.target.focus();
    }
    if (event.cancelable) event.preventDefault();
    event.stopPropagation();
    return false;
  }

  // when mouse is clicked anywhere in window
  function onClick(event) {
    closeTooltip();
  }

  // when key pressed
  function onKeyUp(event) {
    if (!event || !event.key) return;

    switch (event.key) {
      // trigger click of prev button
      case "ArrowLeft":
        const prevButton = document.getElementById("tooltip_prev_button");
        if (prevButton) prevButton.click();
        break;
      // trigger click of next button
      case "ArrowRight":
        const nextButton = document.getElementById("tooltip_next_button");
        if (nextButton) nextButton.click();
        break;
      // close on esc
      case "Escape":
        closeTooltip();
        break;
    }
  }

  // when window is resized or zoomed
  function onResize() {
    closeTooltip();
  }

  // get all links of types we wish to handle
  function getLinks() {
    const queries = [];
    // exclude buttons, anchor links, toc links, etc
    const exclude =
      ":not(.button):not(.icon_button):not(.anchor):not(.toc_link)";
    queries.push('a[href^="#ref-"]' + exclude); // citation links
    queries.push('a[href^="#fig:"]' + exclude); // figure links
    const query = queries.join(", ");
    return document.querySelectorAll(query);
  }

  // get links with same target, get index of link in set, get total
  // same links
  function getSameLinks(link) {
    const sameLinks = [];
    const links = getLinks();
    for (const otherLink of links) {
      if (otherLink.getAttribute("href") === link.getAttribute("href"))
        sameLinks.push(otherLink);
    }

    return {
      elements: sameLinks,
      index: sameLinks.indexOf(link),
      total: sameLinks.length,
    };
  }

  // open tooltip
  function openTooltip(link) {
    // delete tooltip if it exists, start fresh
    closeTooltip();

    // make tooltip element
    const tooltip = makeTooltip(link);

    // if source couldn't be found and tooltip not made, exit
    if (!tooltip) return;

    // make navbar elements
    const navBar = makeNavBar(link);
    if (navBar) tooltip.firstElementChild.appendChild(navBar);

    // attach tooltip to page
    document.body.appendChild(tooltip);

    // position tooltip
    const position = function () {
      positionTooltip(link);
    };
    position();

    // if tooltip contains images, position again after they've loaded
    const imgs = tooltip.querySelectorAll("img");
    for (const img of imgs) img.addEventListener("load", position);
  }

  // close (delete) tooltip
  function closeTooltip() {
    const tooltip = document.getElementById("tooltip");
    if (tooltip) tooltip.remove();
  }

  // make tooltip
  function makeTooltip(link) {
    // get target element that link points to
    const source = getSource(link);

    // if source can't be found, exit
    if (!source) return;

    // create new tooltip
    const tooltip = document.createElement("div");
    tooltip.id = "tooltip";
    const tooltipContent = document.createElement("div");
    tooltipContent.id = "tooltip_content";
    tooltip.appendChild(tooltipContent);

    // make copy of source node and put in tooltip
    const sourceCopy = makeCopy(source);
    tooltipContent.appendChild(sourceCopy);

    // attach mouse event listeners
    tooltip.addEventListener("click", onTooltipClick);
    tooltip.addEventListener("mousedown", onTooltipClick);
    tooltip.addEventListener("touchstart", onTooltipClick);
    tooltip.addEventListener("mouseleave", onTooltipUnhover);

    // (for interaction with lightbox plugin)
    // transfer click on tooltip copied img to original img
    const sourceImg = source.querySelector("img");
    const sourceCopyImg = sourceCopy.querySelector("img");
    if (sourceImg && sourceCopyImg) {
      const clickImg = function () {
        sourceImg.click();
        closeTooltip();
      };
      sourceCopyImg.addEventListener("click", clickImg);
    }

    return tooltip;
  }

  // make carbon copy of html dom element
  function makeCopy(source) {
    const sourceCopy = source.cloneNode(true);

    // delete elements marked with ignore (eg anchor and jump buttons)
    const deleteFromCopy = sourceCopy.querySelectorAll('[data-ignore="true"]');
    for (const element of deleteFromCopy) element.remove();

    // delete certain element attributes
    const attributes = [
      "id",
      "data-collapsed",
      "data-selected",
      "data-highlighted",
      "data-glow",
      "class",
    ];
    for (const attribute of attributes) {
      sourceCopy.removeAttribute(attribute);
      const elements = sourceCopy.querySelectorAll("[" + attribute + "]");
      for (const element of elements) element.removeAttribute(attribute);
    }

    return sourceCopy;
  }

  // when tooltip is clicked
  function onTooltipClick(event) {
    // when user clicks on tooltip, stop click from transferring
    // outside of tooltip (eg, click off to close tooltip, or eg click
    // off to unhighlight same refs)
    event.stopPropagation();
  }

  // when tooltip is unhovered
  function onTooltipUnhover(event) {
    if (clickClose === "true") return;

    // make sure new mouse/touch/focus no longer over tooltip or any
    // element within it
    const tooltip = document.getElementById("tooltip");
    if (!tooltip) return;
    if (this.contains(event.relatedTarget)) return;

    closeTooltip();
  }

  // make nav bar to go betwen prev/next instances of same reference
  function makeNavBar(link) {
    // find other links to the same source
    const sameLinks = getSameLinks(link);

    // don't show nav bar when singular reference
    if (sameLinks.total <= 1) return;

    // find prev/next links with same target
    const prevLink = getPrevLink(link, sameLinks);
    const nextLink = getNextLink(link, sameLinks);

    // create nav bar
    const navBar = document.createElement("div");
    navBar.id = "tooltip_nav_bar";
    const text = sameLinks.index + 1 + " of " + sameLinks.total;

    // create nav bar prev/next buttons
    const prevButton = document.createElement("button");
    const nextButton = document.createElement("button");
    prevButton.id = "tooltip_prev_button";
    nextButton.id = "tooltip_next_button";
    prevButton.title =
      "Jump to the previous occurence of this item in the document [←]";
    nextButton.title =
      "Jump to the next occurence of this item in the document [→]";
    prevButton.classList.add("icon_button");
    nextButton.classList.add("icon_button");
    prevButton.innerHTML = document.querySelector(".icon_caret_left").innerHTML;
    nextButton.innerHTML =
      document.querySelector(".icon_caret_right").innerHTML;
    navBar.appendChild(prevButton);
    navBar.appendChild(document.createTextNode(text));
    navBar.appendChild(nextButton);

    // attach click listeners to buttons
    prevButton.addEventListener("click", function () {
      onPrevNextClick(link, prevLink);
    });
    nextButton.addEventListener("click", function () {
      onPrevNextClick(link, nextLink);
    });

    return navBar;
  }

  // get previous link with same target
  function getPrevLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if < 1
    let index;
    if (sameLinks.index - 1 >= 0) index = sameLinks.index - 1;
    else index = sameLinks.total - 1;
    return sameLinks.elements[index];
  }

  // get next link with same target
  function getNextLink(link, sameLinks) {
    if (!sameLinks) sameLinks = getSameLinks(link);
    // wrap index to other side if > total
    let index;
    if (sameLinks.index + 1 <= sameLinks.total - 1) index = sameLinks.index + 1;
    else index = 0;
    return sameLinks.elements[index];
  }

  // get element that is target of link or url hash
  function getSource(link) {
    const hash = link ? link.hash : window.location.hash;
    const id = hash.slice(1);
    let target = document.querySelector('[id="' + id + '"]');
    if (!target) return;

    // if ref or figure, modify target to get expected element
    if (id.indexOf("ref-") === 0) target = target.querySelector(":nth-child(2)");
    else if (id.indexOf("fig:") === 0) target = target.querySelector("figure");

    return target;
  }

  // when prev/next arrow button is clicked
  function onPrevNextClick(link, prevNextLink) {
    if (link && prevNextLink)
      goToElement(prevNextLink, window.innerHeight * 0.5);
  }

  // scroll to and focus element
  function goToElement(element, offset) {
    // expand accordion section if collapsed
    expandElement(element);
    const y =
      getRectInView(element).top -
      getRectInView(document.documentElement).top -
      (offset || 0);
    // trigger any function listening for "onscroll" event
    window.dispatchEvent(new Event("scroll"));
    window.scrollTo(0, y);
    document.activeElement.blur();
    element.focus();
  }

  // determine position to place tooltip based on link position in
  // viewport and tooltip size
  function positionTooltip(link, left, top) {
    const tooltipElement = document.getElementById("tooltip");
    if (!tooltipElement) return;

    // get convenient vars for position/dimensions of
    // link/tooltip/page/view
    link = getRectInPage(link);
    const tooltip = getRectInPage(tooltipElement);
    const view = getRectInPage();

    // horizontal positioning
    if (left)
      // use explicit value
      left = left;
    else if (link.left + tooltip.width < view.right)
      // fit tooltip to right of link
      left = link.left;
    else if (link.right - tooltip.width > view.left)
      // fit tooltip to left of link
      left = link.right - tooltip.width;
    // center tooltip in view
    else left = (view.right - view.left) / 2 - tooltip.width / 2;

    // vertical positioning
    if (top)
      // use explicit value
      top = top;
    else if (link.top - tooltip.height > view.top)
      // fit tooltip above link
      top = link.top - tooltip.height;
    else if (link.bottom + tooltip.height < view.bottom)
      // fit tooltip below link
      top = link.bottom;
    else {
      // center tooltip in view
      top = view.top + view.height / 2 - tooltip.height / 2;
      // nudge off of link to left/right if possible
      if (link.right + tooltip.width < view.right) left = link.right;
      else if (link.left - tooltip.width > view.left)
        left = link.left - tooltip.width;
    }

    tooltipElement.style.left = left + "px";
    tooltipElement.style.top = top + "px";
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- caret left icon -->

<template class="icon_caret_left">
  <!-- modified from: https://fontawesome.com/icons/caret-left -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M192 127.338v257.324c0 17.818-21.543 26.741-34.142 14.142L29.196 270.142c-7.81-7.81-7.81-20.474 0-28.284l128.662-128.662c12.599-12.6 34.142-3.676 34.142 14.142z"
    ></path>
  </svg>
</template>

<!-- caret right icon -->

<template class="icon_caret_right">
  <!-- modified from: https://fontawesome.com/icons/caret-right -->
  <svg width="16" height="16" viewBox="0 0 192 512">
    <path
      fill="currentColor"
      d="M0 384.662V127.338c0-17.818 21.543-26.741 34.142-14.142l128.662 128.662c7.81 7.81 7.81 20.474 0 28.284L34.142 398.804C21.543 411.404 0 402.48 0 384.662z"
    ></path>
  </svg>
</template>

<style>
  @media only screen {
    /* tooltip container */
    #tooltip {
      position: absolute;
      width: 50%;
      min-width: 240px;
      max-width: 75%;
      z-index: 1;
    }

    /* tooltip content */
    #tooltip_content {
      margin-bottom: 5px;
      padding: 20px;
      border-radius: 5px;
      border: solid 1px #bdbdbd;
      box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
      background: #ffffff;
      overflow-wrap: break-word;
    }

    /* tooltip copy of paragraphs and figures */
    #tooltip_content > p,
    #tooltip_content > figure {
      margin: 0;
      max-height: 320px;
      overflow-y: auto;
    }

    /* tooltip copy of <img> */
    #tooltip_content > figure > img,
    #tooltip_content > figure > svg {
      max-height: 260px;
    }

    /* navigation bar */
    #tooltip_nav_bar {
      margin-top: 10px;
      text-align: center;
    }

    /* navigation bar previous/next buton */
    #tooltip_nav_bar > .icon_button {
      position: relative;
      top: 3px;
    }

    /* navigation bar previous button */
    #tooltip_nav_bar > .icon_button:first-of-type {
      margin-right: 5px;
    }

    /* navigation bar next button */
    #tooltip_nav_bar > .icon_button:last-of-type {
      margin-left: 5px;
    }
  }

  /* always hide tooltip on print */
  @media only print {
    #tooltip {
      display: none;
    }
  }
</style>
<!--
  Analytics Plugin (third-party) 
  
  Copy and paste code from Google Analytics or similar service here.
-->
<!-- 
  Annotations Plugin

  Allows public annotation of the  manuscript. See https://web.hypothes.is/.
-->

<script type="module">
  // configuration
  window.hypothesisConfig = function () {
    return {
      branding: {
        accentColor: "#2196f3",
        appBackgroundColor: "#f8f8f8",
        ctaBackgroundColor: "#f8f8f8",
        ctaTextColor: "#000000",
        selectionFontFamily: "Open Sans, Helvetica, sans serif",
        annotationFontFamily: "Open Sans, Helvetica, sans serif",
      },
    };
  };

  // hypothesis client script
  const embed = "https://hypothes.is/embed.js";
  // hypothesis annotation count query url
  const query = "https://api.hypothes.is/api/search?limit=0&url=";

  // start script
  function start() {
    const button = makeButton();
    document.body.insertBefore(button, document.body.firstChild);
    insertCount(button);
  }

  // make button
  function makeButton() {
    // create button
    const button = document.createElement("button");
    button.id = "hypothesis_button";
    button.innerHTML = document.querySelector(".icon_hypothesis").innerHTML;
    button.title = "Hypothesis annotations";
    button.classList.add("icon_button");

    function onClick(event) {
      onButtonClick(event, button);
    }

    // attach click listeners
    button.addEventListener("click", onClick);

    return button;
  }

  // insert annotations count
  async function insertCount(button) {
    // get annotation count from Hypothesis based on url
    let count = "-";
    try {
      const canonical = document.querySelector('link[rel="canonical"]');
      const location = window.location;
      const url = encodeURIComponent((canonical || location).href);
      const response = await fetch(query + url);
      const json = await response.json();
      count = json.total || "-";
    } catch (error) {
      console.log(error);
    }

    // put count into button
    const counter = document.createElement("span");
    counter.id = "hypothesis_count";
    counter.innerHTML = count;
    button.title = "View " + count + " Hypothesis annotations";
    button.append(counter);
  }

  // when button is clicked
  function onButtonClick(event, button) {
    const script = document.createElement("script");
    script.src = embed;
    document.body.append(script);
    button.remove();
  }

  // start script when document is finished loading
  window.addEventListener("load", start);
</script>

<!-- hypothesis icon -->

<template class="icon_hypothesis">
  <!-- modified from: https://simpleicons.org/icons/hypothesis.svg / https://git.io/Jf1VB -->
  <svg width="16" height="16" viewBox="0 0 24 24" tabindex="-1">
    <path
      fill="currentColor"
      d="M3.43 0C2.5 0 1.72 .768 1.72 1.72V18.86C1.72 19.8 2.5 20.57 3.43 20.57H9.38L12 24L14.62 20.57H20.57C21.5 20.57 22.29 19.8 22.29 18.86V1.72C22.29 .77 21.5 0 20.57 0H3.43M5.14 3.43H7.72V9.43S8.58 7.72 10.28 7.72C12 7.72 13.74 8.57 13.74 11.24V17.14H11.16V12C11.16 10.61 10.28 10.07 9.43 10.29C8.57 10.5 7.72 11.41 7.72 13.29V17.14H5.14V3.43M18 13.72C18.95 13.72 19.72 14.5 19.72 15.42A1.71 1.71 0 0 1 18 17.13A1.71 1.71 0 0 1 16.29 15.42C16.29 14.5 17.05 13.71 18 13.71Z"
      tabindex="-1"
    ></path>
  </svg>
</template>

<style>
  /* hypothesis activation button */
  #hypothesis_button {
    box-sizing: border-box;
    position: fixed;
    top: 0;
    right: 0;
    width: 60px;
    height: 60px;
    background: #ffffff;
    border-radius: 0;
    border-left: solid 1px #bdbdbd;
    border-bottom: solid 1px #bdbdbd;
    box-shadow: 0 0 20px rgba(0, 0, 0, 0.05);
    z-index: 2;
  }

  /* hypothesis button svg */
  #hypothesis_button > svg {
    position: relative;
    top: -4px;
  }

  /* hypothesis annotation count */
  #hypothesis_count {
    position: absolute;
    left: 0;
    right: 0;
    bottom: 5px;
  }

  /* side panel */
  .annotator-frame {
    width: 280px !important;
  }

  /* match highlight color to rest of theme */
  .annotator-highlights-always-on .annotator-hl {
    background-color: #ffeb3b !important;
  }

  /* match focused color to rest of theme */
  .annotator-hl.annotator-hl-focused {
    background-color: #ff8a65 !important;
  }

  /* match bucket bar color to rest of theme */
  .annotator-bucket-bar {
    background: #f5f5f5 !important;
  }

  /* always hide button, toolbar, and tooltip on print */
  @media only print {
    #hypothesis_button {
      display: none;
    }

    .annotator-frame {
      display: none !important;
    }

    hypothesis-adder {
      display: none !important;
    }
  }
</style>
<!-- 
  Mathjax Plugin (third-party) 

  Allows the proper rendering of math/equations written in LaTeX.
  See https://www.mathjax.org/.
-->

<script type="text/x-mathjax-config">
  // configuration
  MathJax.Hub.Config({
    "CommonHTML": { linebreaks: { automatic: true } },
    "HTML-CSS": { linebreaks: { automatic: true } },
    "SVG": { linebreaks: { automatic: true } },
    "fast-preview": { disabled: true }
  });
</script>

<script
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"
  integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A=="
  crossorigin="anonymous"
></script>

<style>
  /* mathjax containers */
  .math.display > span:not(.MathJax_Preview) {
    /* turn inline element (no dimensions) into block (allows fixed width and thus scrolling) */
    display: flex !important;
    overflow-x: auto !important;
    overflow-y: hidden !important;
    justify-content: center;
    align-items: center;
    margin: 0 !important;
  }

  /* right click menu */
  .MathJax_Menu {
    border-radius: 5px !important;
    border: solid 1px #bdbdbd !important;
    box-shadow: none !important;
  }

  /* equation auto-number */
  span[id^="eq:"] > span.math.display + span {
    font-weight: 600;
  }

  /* equation */
  span[id^="eq:"] > span.math.display > span {
    /* nudge to make room for equation auto-number and anchor */
    margin-right: 60px !important;
  }
</style>
</body>
</html>
